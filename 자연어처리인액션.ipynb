{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaekyoungkim/nlp_in_action/blob/main/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC%EC%9D%B8%EC%95%A1%EC%85%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DM17p2KE3Gl",
        "outputId": "c7985924-29eb-45b2-9baa-69333fedd132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nlpia' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/totalgood/nlpia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZXLrCDZPvjU",
        "outputId": "0141a742-a7e1-4169-fb42-c91c0e67dd53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UflWSmumDUu",
        "outputId": "ca32b8e4-f3f9-4b58-b324-7aebb3df561e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nlpia in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.16.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nlpia) (2019.12.20)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.1.0)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.1)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.7/dist-packages (from nlpia) (2020.1.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nlpia) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.2.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.11.2)\n",
            "Requirement already satisfied: pugnlp in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.2.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nlpia) (4.2.6)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.6.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from nlpia) (5.5.0)\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.9.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.3.5)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.12.2)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.7.5)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.8.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.8.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.2.5)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.21.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->nlpia) (1.5.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->nlpia) (0.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.3.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (7.7.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.5.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (1.1.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (3.6.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (5.3.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (2.15.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.9.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.1.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (5.6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (3.8.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (0.13.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->nlpia) (22.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->nlpia) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->nlpia) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->nlpia) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (0.11.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (5.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlpia) (2018.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader->nlpia) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (1.24.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->nlpia) (8.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (0.37.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (21.1.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (6.1.1)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (3.7.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (0.18.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->pugnlp->nlpia) (1.3)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nlpia) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter->nlpia) (21.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nlpia) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nlpia) (1.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (0.9.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (3.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (13.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (3.17.3)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.24.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.1.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->nlpia) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nlpia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w02UuNpRqkSq"
      },
      "source": [
        "# ch01. 사고의 단위 : nlp개요 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqInIFhnqndP"
      },
      "outputs": [],
      "source": [
        "# 정규식\n",
        "import re  # regex/re 두개 있음 \n",
        "r = \"(hi|hello|hey)[ ] *([a-z]*)\" # a-z에 포함하는 글자가 임의의 횟수로 나타날수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUMzjwQtrEky",
        "outputId": "3105b686-2b50-43ef-d220-fae45cbbd533"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 10), match='hello rosa'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "re.match(r, \"hello rosa\", flags= re.IGNORECASE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow7MRVOYrFU8",
        "outputId": "c3b876c4-ecc4-4fec-a444-98d255056227"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 5), match='hi ho'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "re.match(r, \"hi ho, hiho, it's off to work ...\", flags= re.IGNORECASE) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMR19i5erGF4",
        "outputId": "33b4843f-8da9-4783-854c-4ab0859e7da6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 8), match='hey what'>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "re.match(r, \"hey what's up.\", flags= re.IGNORECASE)  # 대소문자 구분 무시함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT-HOeDvq7Si"
      },
      "outputs": [],
      "source": [
        "# code error \n",
        "# r = r'[^a-z]*([y]o|[h']?ello|ok|hey|(good[ ])?(morn[gin']{0,3}|'\\r'afternoon|even[gin']{0,3}))[\\s.;:]{1,3}([a-z]{1,20})'\n",
        "# r' : 정규 표현식 아니라 원시 문자열을 뜻함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m9dV-Jwt27O"
      },
      "outputs": [],
      "source": [
        "re_greeting = re.compile(r, flags =re.IGNORECASE) # compile 메서드로 정규표현식을 미리 컴파일해두면 정규식을 적용할때마다 옵션을 지정할 필요 없음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp3Y9utluTe6",
        "outputId": "da8707ca-0407-402b-ea2a-387f647eed7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 10), match='Hello Rosa'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "re_greeting.match('Hello Rosa') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uMLmOyRuXqY"
      },
      "outputs": [],
      "source": [
        "re_greeting.match('Good moring Rosa') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp1jFLgPubo9"
      },
      "outputs": [],
      "source": [
        "re_greeting.match('good evening rosa parks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMAMVY2V0WFe",
        "outputId": "d17c5f1c-2a3f-4a3b-dbf1-6124f002b098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello rosa\n",
            "hi  how are you?\n"
          ]
        }
      ],
      "source": [
        "my_names = set(['rosa','rose','chatty','chatbot','bot','chatterbot'])\n",
        "curt_names = set(['hal','you','u']) \n",
        "greeter_name ='' #아직 챗봇은 대화상대가 누군지 모름\n",
        "match = re_greeting.match(input())\n",
        "if match:\n",
        "  at_name = match.groups()[-1]\n",
        "  if at_name in curt_names:\n",
        "    print('good one')\n",
        "  elif at_name.lower() in my_names: \n",
        "    print('hi {} how are you?'.format(greeter_name)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEnEZoXF5LtK",
        "outputId": "f77cc635-0927-476a-d4a9-3bb05001b901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello you\n",
            "good one\n"
          ]
        }
      ],
      "source": [
        "my_names = set(['rosa','rose','chatty','chatbot','bot','chatterbot'])\n",
        "curt_names = set(['hal','you','u']) \n",
        "greeter_name ='' #아직 챗봇은 대화상대가 누군지 모름\n",
        "match = re_greeting.match(input())\n",
        "if match:\n",
        "  at_name = match.groups()[-1]\n",
        "  if at_name in curt_names:\n",
        "    print('good one')\n",
        "  elif at_name.lower() in my_names: \n",
        "    print('hi {} how are you?'.format(greeter_name)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCd0tViO5ULF"
      },
      "outputs": [],
      "source": [
        "# 부록b의 정규식\n",
        "# 프로그램 언어로 이루어진 하나의 작은 프로그램\n",
        "# 문자열을  컴파일해서 하나의 작은 프로그램을 만들고 그것을 다른 문자열들에 대해 실행함으로써 패턴 부합을 수행\n",
        "# | or\n",
        "# () 그룹묶기\n",
        "# [] 문자부류\n",
        "# \\s \\b \\d \\w  흔히쓰이는 문자 부류들의 단축표기\n",
        "# * ? + 반복횟수 지정\n",
        "# {7,10} : 반복횟수를 좀더 구체적으로 지정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-EqQ4hz8fw7",
        "outputId": "a246152a-94bd-45ef-bdeb-e8b6292fb131"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hobson', 'Cole', 'Hannes']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re \n",
        "re.findall(r'Hannes|Hobson|Cole', 'Hobson lane, Cole Howard, and Hannes Max Hapke') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaCioZZV8wUT",
        "outputId": "4eaa5e44-dceb-48a0-be89-c38fe4067642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['H', 'Cole', 'H', 'H', 'H']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re.findall(r'H|Hobson|Cole', 'Hobson lane, Cole Howard, and Hannes Max Hapke')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ope3YSZU89y-"
      },
      "outputs": [],
      "source": [
        "# () 그룹묶기\n",
        "# r'(kitt|dogg)y\n",
        "match = re.match(r'(kitt|dogg)y' , \"doggy\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zohrxK6l9a-i",
        "outputId": "fcface68-2983-461c-b374-02e228ad8b2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'doggy'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "match.group()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JeUWCIoH9cGo",
        "outputId": "14e2ad19-7edb-4d1e-9102-f1c351f8f830"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'doggy'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "match.group(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IViMlgrg9ehj",
        "outputId": "12bf2e0f-306d-4aa9-85b3-11129c073b5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('dogg',)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "match.groups()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAdn53Tq9f8f"
      },
      "outputs": [],
      "source": [
        "match = re.match(r'((kitt|dogg)(y))',  \"doggy\") # 괄호를 더 추가해서 전체 부합과 접미사도 개별적인 그룹으로 묶기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWGQnBFb9o7o",
        "outputId": "3bb5b0aa-ce60-4474-da48-38240811d3cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('doggy', 'dogg', 'y')"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "match.groups()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e7yEjhfg9s3G",
        "outputId": "1fed5a54-3be9-4e34-8aea-d765895e9eec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'y'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "match.group(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvHhdPM99zL_"
      },
      "outputs": [],
      "source": [
        "# [ ] 문자부류\n",
        "# [abcd] : a or b or c or d\n",
        "# [a-d] : a-d\n",
        "# [a-c1-3] : [abc123] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT6jBBul_DAp",
        "outputId": "bc93b397-8f7d-4941-d3c8-b06ef6dc4b3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'guten': 1, 'morgen': 1, 'rosa': 1})"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter  # counter : 토큰들을 각각의 통으로 분류하고 그 개수를 세는 기능 제공 \n",
        "Counter('guten morgen rosa'.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RKZOfzG_IA6",
        "outputId": "98c0f51e-37ad-42a8-e83b-f297e73a5ba9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['good morning rosa!',\n",
              " 'good rosa! morning',\n",
              " 'morning good rosa!',\n",
              " 'morning rosa! good',\n",
              " 'rosa! good morning',\n",
              " 'rosa! morning good']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from itertools import permutations\n",
        "[\" \".join(combo) for combo in permutations(\"good morning rosa!\".split(),3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7dhQUv_GKSB",
        "outputId": "1b87de12-552c-4cea-d33e-a386e5d903de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  단어 순서가 중요한 좀더 길고 복잡한 문장\n",
        "s = \"\"\"find textbooks with titles containing nlp or natural and language or computational and linguistics.\"\"\"\n",
        "len(set(s.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ypi3-lxGgSP",
        "outputId": "f91ccfaf-d9e7-4b69-9815-86f2337ab603"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.arange(1, 12+1).prod()  # factorial(12)\n",
        "# sapcy, syntaxnet: 자연어 문장에서 구문적, 놀리적 관계를 추출하게 해줌\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqBQtqqrHDsy"
      },
      "outputs": [],
      "source": [
        "# 챗봇을 만들기 위한 알고리즘\n",
        "# 1. 파싱 :텍스트에서 특징들과 구조적 수치자료를 추출\n",
        "# 2. 분석 : 정서, 문법성, 으미론에 대한 평점\n",
        "# 3. 생성 : 적절한 응답문 작성\n",
        "# 4, 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQypiRxuGkEj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az-xXqq3IhrF"
      },
      "source": [
        "# ch02. 나만의 어취 구축 : 단어 토큰화 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI3GSx_nIk6F"
      },
      "outputs": [],
      "source": [
        "# 토큰 : 문자열을 개별적인 의미 단위들로 분할하는 방법을 적용한 단위 \n",
        "# we'll -> we will로 구분할 수 있어야함\n",
        "# 토큰생성기를 이용한 어휘구축\n",
        "# 컴퓨터 언어로된 소스코드를 토크화하는데 쓰이는 토큰 생성기 :  스캐너, 렉서(lexical analyzer) \n",
        "# 어휘집 , 파서(컴파일러), 토큰, 용어, 단어, n그램 등의 용어들이 사용됨\n",
        "# 토큰화는 구조가 없는 자료인 자연어 텍스트를 정보 조각들로 분할함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y8cGYiBKg0G",
        "outputId": "40874d31-f733-4027-d9a8-296650b95b35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thomas',\n",
              " 'jefferson',\n",
              " 'began',\n",
              " 'building',\n",
              " 'monticello',\n",
              " 'at',\n",
              " 'the',\n",
              " 'age',\n",
              " 'of',\n",
              " '26.']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = '''thomas jefferson began building monticello at the age of 26.'''\n",
        "sentence.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN0W4DdvKnlu",
        "outputId": "e5d08a43-6174-40cf-f757-4d6888c33acc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thomas',\n",
              " 'jefferson',\n",
              " 'began',\n",
              " 'building',\n",
              " 'monticello',\n",
              " 'at',\n",
              " 'the',\n",
              " 'age',\n",
              " 'of',\n",
              " '26.']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str.split(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w47F5YHLKqi4",
        "outputId": "47594ffc-a6a5-4d2b-9e70-f2a683c263c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'26., age, at, began, building, jefferson, monticello, of, the, thomas'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_sequence = str.split(sentence)\n",
        "vocab = sorted(set(token_sequence))\n",
        "', '.join(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KIg3o2fLMtW",
        "outputId": "6d941e0c-710b-47fa-90f2-d58608a17afb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_tokens = len(token_sequence) ;num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIWKU25hLPmc",
        "outputId": "d2826b4d-ccc5-422d-ff0e-375030e034e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(vocab) ; vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dpjr9BXLYxY",
        "outputId": "661d5f59-f6dc-4cc5-d685-4c4242cbac48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "onehot_vectors = np.zeros((num_tokens, vocab_size), int) ;onehot_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuXb8PgRLfXX"
      },
      "outputs": [],
      "source": [
        "for i , word in enumerate(token_sequence):\n",
        "  onehot_vectors[i, vocab.index(word)] = 1\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mzt7afeRL1xt",
        "outputId": "b6ca1508-a3e4-4044-d59a-63fe1f944613"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'26. age at began building jefferson monticello of the thomas'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "' '.join(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwaGS3p8L3uK",
        "outputId": "f118c2c4-5ff0-4cd2-c24b-08c967e57255"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "onehot_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6OGEEO8UL9F3",
        "outputId": "882ad496-471c-4e26-bd02-8c6f8dd317dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f8ea0a47-ddd5-417a-b1a1-7dc65845ae91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>26.</th>\n",
              "      <th>age</th>\n",
              "      <th>at</th>\n",
              "      <th>began</th>\n",
              "      <th>building</th>\n",
              "      <th>jefferson</th>\n",
              "      <th>monticello</th>\n",
              "      <th>of</th>\n",
              "      <th>the</th>\n",
              "      <th>thomas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8ea0a47-ddd5-417a-b1a1-7dc65845ae91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8ea0a47-ddd5-417a-b1a1-7dc65845ae91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8ea0a47-ddd5-417a-b1a1-7dc65845ae91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   26.  age  at  began  building  jefferson  monticello  of  the  thomas\n",
              "0    0    0   0      0         0          0           0   0    0       1\n",
              "1    0    0   0      0         0          1           0   0    0       0\n",
              "2    0    0   0      1         0          0           0   0    0       0\n",
              "3    0    0   0      0         1          0           0   0    0       0\n",
              "4    0    0   0      0         0          0           1   0    0       0\n",
              "5    0    0   1      0         0          0           0   0    0       0\n",
              "6    0    0   0      0         0          0           0   0    1       0\n",
              "7    0    1   0      0         0          0           0   0    0       0\n",
              "8    0    0   0      0         0          0           0   1    0       0\n",
              "9    1    0   0      0         0          0           0   0    0       0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(onehot_vectors, columns = vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ynpgOWRMBRP"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(onehot_vectors, columns = vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tC8XxhQMSB3"
      },
      "outputs": [],
      "source": [
        "df[df==0] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "G-zgEa4WMUZg",
        "outputId": "e5eecc98-ce4f-426e-cb43-9144b3a6f437"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2afb5b80-612c-4571-a0a8-178e6a34fe3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>26.</th>\n",
              "      <th>age</th>\n",
              "      <th>at</th>\n",
              "      <th>began</th>\n",
              "      <th>building</th>\n",
              "      <th>jefferson</th>\n",
              "      <th>monticello</th>\n",
              "      <th>of</th>\n",
              "      <th>the</th>\n",
              "      <th>thomas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2afb5b80-612c-4571-a0a8-178e6a34fe3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2afb5b80-612c-4571-a0a8-178e6a34fe3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2afb5b80-612c-4571-a0a8-178e6a34fe3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  26. age at began building jefferson monticello of the thomas\n",
              "0                                                            1\n",
              "1                                   1                         \n",
              "2                1                                            \n",
              "3                         1                                   \n",
              "4                                              1              \n",
              "5          1                                                  \n",
              "6                                                     1       \n",
              "7       1                                                     \n",
              "8                                                 1           \n",
              "9   1                                                         "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjGRFIXsMUkS"
      },
      "outputs": [],
      "source": [
        "# 장점은 어떤 정보도 소실되지 않지만 복원할때도 완벽함\n",
        "# 원문의 모든 세부사항을 유지함, 컴퓨터가 이해할 수 있는 수치자료의 형태임\n",
        "# 단어 모음 벡터(빈도벡터) : 단어의 순서 안나타나기때문에 복원 불가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4gUEH2s-GsQ"
      },
      "outputs": [],
      "source": [
        "sentence_bow = {}\n",
        "for token in sentence.split():\n",
        "  sentence_bow[token] = 1\n",
        "  sorted(sentence_bow.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHY52vQi-Wnd",
        "outputId": "5e03573e-151d-427e-a1ff-a7799c6ce279"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'26.': 1,\n",
              " 'age': 1,\n",
              " 'at': 1,\n",
              " 'began': 1,\n",
              " 'building': 1,\n",
              " 'jefferson': 1,\n",
              " 'monticello': 1,\n",
              " 'of': 1,\n",
              " 'the': 1,\n",
              " 'thomas': 1}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbATAlnK-ZK4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame( pd.Series(dict([(token,1) for token in sentence.split()])), columns=['sent']).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYNoQ_v1-uD3",
        "outputId": "38f4fb31-5237-4849-f0f3-9678bb93b574"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('thomas', 1),\n",
              " ('jefferson', 1),\n",
              " ('began', 1),\n",
              " ('building', 1),\n",
              " ('monticello', 1),\n",
              " ('at', 1),\n",
              " ('the', 1),\n",
              " ('age', 1),\n",
              " ('of', 1),\n",
              " ('26.', 1)]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(token,1) for token in sentence.split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "3Wa6mUDB-9pG",
        "outputId": "71ad9a9f-49f0-4fe3-f541-a38710003190"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ff3f88e3-15d3-473d-9d7c-e684e1c32394\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thomas</th>\n",
              "      <th>jefferson</th>\n",
              "      <th>began</th>\n",
              "      <th>building</th>\n",
              "      <th>monticello</th>\n",
              "      <th>at</th>\n",
              "      <th>the</th>\n",
              "      <th>age</th>\n",
              "      <th>of</th>\n",
              "      <th>26.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sent</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff3f88e3-15d3-473d-9d7c-e684e1c32394')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff3f88e3-15d3-473d-9d7c-e684e1c32394 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff3f88e3-15d3-473d-9d7c-e684e1c32394');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      thomas  jefferson  began  building  monticello  at  the  age  of  26.\n",
              "sent       1          1      1         1           1   1    1    1   1    1"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh-42TdpBgTy",
        "outputId": "4e597a30-73b6-4c66-e4ad-7d16978d26fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "thomas jefferson began building moticello at the age of 26.\n",
            "construction was done mostly by local masons and carpenters.\n",
            "he moved into the south pavilion in 1770.\n",
            "turning moticello into a neoclassical masterpiece was jefferson's obsession.\n"
          ]
        }
      ],
      "source": [
        "sentences = \"\"\"thomas jefferson began building moticello at the age of 26.\\n\"\"\"\n",
        "sentences += \"\"\"construction was done mostly by local masons and carpenters.\\n\"\"\"\n",
        "sentences += \"\"\"he moved into the south pavilion in 1770.\\n\"\"\"\n",
        "sentences += \"\"\"turning moticello into a neoclassical masterpiece was jefferson's obsession.\"\"\"\n",
        "corpus ={}\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fNCfWEvCGHk"
      },
      "outputs": [],
      "source": [
        "for i, sent in enumerate(sentences.split('\\n')):\n",
        "  corpus['sent{}'.format(i)] = dict((tok,1) for tok in sent.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSRhl3TiESnc",
        "outputId": "cf4b29dc-6062-47be-a55b-ea1eb8f29078"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sent0': {'26.': 1,\n",
              "  'age': 1,\n",
              "  'at': 1,\n",
              "  'began': 1,\n",
              "  'building': 1,\n",
              "  'jefferson': 1,\n",
              "  'moticello': 1,\n",
              "  'of': 1,\n",
              "  'the': 1,\n",
              "  'thomas': 1},\n",
              " 'sent1': {'and': 1,\n",
              "  'by': 1,\n",
              "  'carpenters.': 1,\n",
              "  'construction': 1,\n",
              "  'done': 1,\n",
              "  'local': 1,\n",
              "  'masons': 1,\n",
              "  'mostly': 1,\n",
              "  'was': 1},\n",
              " 'sent2': {'1770.': 1,\n",
              "  'he': 1,\n",
              "  'in': 1,\n",
              "  'into': 1,\n",
              "  'moved': 1,\n",
              "  'pavilion': 1,\n",
              "  'south': 1,\n",
              "  'the': 1},\n",
              " 'sent3': {'a': 1,\n",
              "  'into': 1,\n",
              "  \"jefferson's\": 1,\n",
              "  'masterpiece': 1,\n",
              "  'moticello': 1,\n",
              "  'neoclassical': 1,\n",
              "  'obsession.': 1,\n",
              "  'turning': 1,\n",
              "  'was': 1}}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "nvsYeaWuCZQA",
        "outputId": "fa8fb351-7ee6-4b53-8e6b-5703cc536493"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7bf433a1-ea99-48bd-83c5-5e7206a94c09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thomas</th>\n",
              "      <th>jefferson</th>\n",
              "      <th>began</th>\n",
              "      <th>building</th>\n",
              "      <th>moticello</th>\n",
              "      <th>at</th>\n",
              "      <th>the</th>\n",
              "      <th>age</th>\n",
              "      <th>of</th>\n",
              "      <th>26.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sent0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bf433a1-ea99-48bd-83c5-5e7206a94c09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bf433a1-ea99-48bd-83c5-5e7206a94c09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bf433a1-ea99-48bd-83c5-5e7206a94c09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       thomas  jefferson  began  building  moticello  at  the  age  of  26.\n",
              "sent0       1          1      1         1          1   1    1    1   1    1\n",
              "sent1       0          0      0         0          0   0    0    0   0    0\n",
              "sent2       0          0      0         0          0   0    1    0   0    0\n",
              "sent3       0          0      0         0          1   0    0    0   0    0"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df =pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
        "df[df.columns[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5rKi9h0ChjK",
        "outputId": "fdd78474-b093-4631-f100-66cf19698ab3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 내적\n",
        "v1 = pd.np.array([1,2,3]) \n",
        "v2 = pd.np.array([2,3,4]) \n",
        "(v1*v2).sum() # 굉장히 효율적인 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahQqP-qSEQvw",
        "outputId": "18487c8e-ea85-4fcb-95e5-3ff3ca66acbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum([x1 * x2 for x1, x2 in zip(v1,v2)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDyuH2VCFD-Q",
        "outputId": "5fa3574f-186e-4ad6-cfab-493b3e36ecc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVO8FpESEpo3",
        "outputId": "4b77b20e-4e52-4e64-cf9b-dbef9d4825ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1.reshape(-1,1).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud-C6CyeE314",
        "outputId": "3c9fb13d-3a1c-45c9-8e0f-74964242b74b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2],\n",
              "       [3],\n",
              "       [4]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v2.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQvO0PITE7Qz",
        "outputId": "cb14cb63-c6ec-486a-d96a-83679fb2f133"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[20]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v1.reshape(-1,1).T@v2.reshape(-1,1) # @ : 행렬곱 연산자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBXQyprtE83z",
        "outputId": "3563bf2b-552c-4232-875a-6543439cc0a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 중복단어 개수세기\n",
        "df = df.T\n",
        "df.sent0.dot(df.sent1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKZyoGu7FRau",
        "outputId": "da4bf735-830a-41f7-b6ef-f7ed1a429786"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sent0.dot(df.sent2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD73SG6IFSUz",
        "outputId": "aa105eab-7d22-4e65-d0c8-de523ac53524"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sent0.dot(df.sent3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjm2QM7YFTVp",
        "outputId": "cc4820ed-c055-439a-fb4d-9ffa7ebf6328"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('moticello', 1)]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 내적이 1이되게한 단어를 찾기\n",
        "[(k,v) for (k,v) in (df.sent0 & df.sent3).items() if v] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHtA77UTFme4",
        "outputId": "0d1b79c5-c068-47f9-96ec-198bc382bb64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<zip at 0x7fce22d36fa0>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df.sent0 & df.sent3).items() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2dJOb54FoFD",
        "outputId": "7e982a80-7b66-49da-c029-56b10be46782"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "thomas          0\n",
              "jefferson       0\n",
              "began           0\n",
              "building        0\n",
              "moticello       1\n",
              "at              0\n",
              "the             0\n",
              "age             0\n",
              "of              0\n",
              "26.             0\n",
              "construction    0\n",
              "was             0\n",
              "done            0\n",
              "mostly          0\n",
              "by              0\n",
              "local           0\n",
              "masons          0\n",
              "and             0\n",
              "carpenters.     0\n",
              "he              0\n",
              "moved           0\n",
              "into            0\n",
              "south           0\n",
              "pavilion        0\n",
              "in              0\n",
              "1770.           0\n",
              "turning         0\n",
              "a               0\n",
              "neoclassical    0\n",
              "masterpiece     0\n",
              "jefferson's     0\n",
              "obsession.      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(df.sent0 & df.sent3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4--ixYWFr7B",
        "outputId": "1009b335-a2ac-4439-b910-4f3b347c9300"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thomas',\n",
              " 'jefferson',\n",
              " 'began',\n",
              " 'building',\n",
              " 'moticello',\n",
              " 'at',\n",
              " 'the',\n",
              " 'age',\n",
              " 'of',\n",
              " '26',\n",
              " '']"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re \n",
        "sentence = \"\"\"thomas jefferson began building moticello at the age of 26.\"\"\"\n",
        "tokens = re.split(r'[-\\s.,;!?]+' , sentence) # 공백이나 몇가지 문장부호를 기준으로 분할함\n",
        "tokens\n",
        "\n",
        "#  정규식 파헤치기\n",
        "# [] : 대괄호는 주어진 텍스트가 부합해야할 문자들의 집합을 지정함\n",
        "# + : []다음 나오는 + , 주어진 문자 부류의 문자들이 하나이상 부합해야함을 뜻함\n",
        "# \\s : \\\\t\\n\\r\\f\\v 등의 공백문자들을 대표함\n",
        "# \\t 탭\n",
        "# \\r 캐리지 리턴\n",
        "# \\n 새줄\n",
        "# \\f 폼피드\n",
        "# \\v 수직탭 문자\n",
        "# r'[a-z] , r'[0-9], r'[_a-zA-Z] : 밑줄문자나 영문소문자, 대문자와 부합함\n",
        "# [-] : 정규 표현식의 까다로운 규칙에 해당함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InMP5PNCGQTB",
        "outputId": "281a9132-83ba-4e19-bd5d-0c414c025c73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' ', 'the', ' ', 'age', ' ', 'of', ' ', '26', '.', '']"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 단어 분리를 위한 정규 표현식 개선\n",
        "pattern = re.compile(r'([-\\s.,;:!?])+')\n",
        "tokens = pattern.split(sentence) \n",
        "tokens[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEqyFcCeKyVM",
        "outputId": "cc943e93-eb39-44ac-c3f0-10bb30cb6b2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thomas',\n",
              " 'jefferson',\n",
              " 'began',\n",
              " 'building',\n",
              " 'moticello',\n",
              " 'at',\n",
              " 'the',\n",
              " 'age',\n",
              " 'of',\n",
              " '26']"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence = \"\"\"thomas jefferson began building moticello at the age of 26.\"\"\"\n",
        "pattern = re.compile(r'([-\\s.,;:!?])+')\n",
        "tokens = pattern.split(sentence) \n",
        "[x for x in tokens if x and x not in '- \\t\\n.,;!?']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bypE0I_gLGgA"
      },
      "outputs": [],
      "source": [
        "# regex : 부합집합중첩, 다중 스레드 적용 유니코드 완벽지원, 근사 정규 표현식 부합, 더큰  maxcache(500개)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOO1HSDWLdnA"
      },
      "outputs": [],
      "source": [
        "# 주요 토큰화 라이브러리 \n",
        "# spacy : 정확,유연, 빠름, 파이썬\n",
        "# coreNLP : 스탠퍼드, 더욱 정확하지만 덜 유연, 빠름, JAVA8에 의존\n",
        "# NLTK : 표준 라이브러리, 유명, 파이썬\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_P8pZ8vLw4C",
        "outputId": "6a3dce32-e78b-4994-e390-eaf0f1fe126e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thomas',\n",
              " 'jefferson',\n",
              " 'began',\n",
              " 'building',\n",
              " 'moticello',\n",
              " 'at',\n",
              " 'the',\n",
              " 'age',\n",
              " 'of',\n",
              " '26',\n",
              " '.']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import RegexpTokenizer \n",
        "tokenizer = RegexpTokenizer(r'\\w+|$[0-9.]+|\\S+')\n",
        "tokenizer.tokenize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2W2W1_3MII5"
      },
      "outputs": [],
      "source": [
        "# 좀더 강력한 토큰화 함수 :  treebandwordtokenizer, 소숫점, 축양형도 토큰화 가능\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "sentence = \"\"\"Monticello wasn't designated as UNESCO World heritage site until 1987.\"\"\"\n",
        "tokenizer = TreebankWordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZr0fo_FMyFI",
        "outputId": "600943de-2354-49ff-e384-6e1da10f644d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Monticello',\n",
              " 'was',\n",
              " \"n't\",\n",
              " 'designated',\n",
              " 'as',\n",
              " 'UNESCO',\n",
              " 'World',\n",
              " 'heritage',\n",
              " 'site',\n",
              " 'until',\n",
              " '1987',\n",
              " '.']"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.tokenize(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKksSJbuM2QQ"
      },
      "outputs": [],
      "source": [
        "# n-gram을 활용한 어휘 확장\n",
        "#tokenize_2grams(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIuW2fYANqQc",
        "outputId": "607c6ad7-fbdb-40be-919f-d7d373580cc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('thomas', 'jefferson'),\n",
              " ('jefferson', 'began'),\n",
              " ('began', 'building'),\n",
              " ('building', 'moticello'),\n",
              " ('moticello', 'at'),\n",
              " ('at', 'the'),\n",
              " ('the', 'age'),\n",
              " ('age', 'of'),\n",
              " ('of', '26')]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "tokens = [x for x in tokens if x and x not in '= \\t\\n.,;:!?']\n",
        "\n",
        "list(ngrams(tokens,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT0PJRCCOt46",
        "outputId": "aa74f1c3-9e60-4188-dd1d-e7bf06b10f73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('thomas', 'jefferson', 'began'),\n",
              " ('jefferson', 'began', 'building'),\n",
              " ('began', 'building', 'moticello'),\n",
              " ('building', 'moticello', 'at'),\n",
              " ('moticello', 'at', 'the'),\n",
              " ('at', 'the', 'age'),\n",
              " ('the', 'age', 'of'),\n",
              " ('age', 'of', '26')]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(ngrams(tokens,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq7RidEkOwvZ",
        "outputId": "6e50e453-406e-43b6-aa4c-247157592274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['thomas jefferson',\n",
              " 'jefferson began',\n",
              " 'began building',\n",
              " 'building moticello',\n",
              " 'moticello at',\n",
              " 'at the',\n",
              " 'the age',\n",
              " 'age of',\n",
              " 'of 26']"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "two_grams = list(ngrams(tokens,2))\n",
        "[\" \".join(x) for x in two_grams]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI_2B0AiPDiK",
        "outputId": "926462e7-6d33-4685-af41-3f2f6bda3d8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['house', 'fire']"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words = ['a','an','the','on','of','off','this','is']\n",
        "tokens = ['the','house','is','on','fire'] \n",
        "tokens_without_stopwords = [x for x in tokens if x not in stop_words] \n",
        "tokens_without_stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBcwFUeNQuom",
        "outputId": "f7d99bf0-10f2-4928-de91-444b809460f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# nltk의 불용어 목록\n",
        "import nltk\n",
        "nltk.download('stopwords') \n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "len(stop_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3AOKwQUQ4rj",
        "outputId": "c27ce3e7-ad40-4114-b152-40ca691d8421"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours']"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words[:7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sGmQvlWQ6kg",
        "outputId": "5a8ca418-f956-4550-80be-299c509c540f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "318"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 여러 불용어 집합을 같이 사용하기\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words \n",
        "len(sklearn_stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip4wz1pzRVWv",
        "outputId": "cd565c4f-e2b3-45cc-a7af-ae3332a62ce6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrbzpDNVRXKP"
      },
      "outputs": [],
      "source": [
        "# len(stop_words.union(sklearn_stop_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHpEvcqDRam1"
      },
      "outputs": [],
      "source": [
        "# len(stop_words.intersection(sklearn_stop_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktGYRHzWRlxc",
        "outputId": "9a13f851-6ee5-4382-fce7-a6159389755d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['house', 'visitors', 'center']\n"
          ]
        }
      ],
      "source": [
        "tokens = ['House','Visitors','Center'] \n",
        "normalized_tokens = [x.lower() for x in tokens] \n",
        "print(normalized_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yToGQyheSj0d"
      },
      "outputs": [],
      "source": [
        "# 정규화 : 재현율을 높여주지만, 정밀도를 낮춤\n",
        "# 별로 관심없는 문서들이 검색결과에 포함될 가능성 생김\n",
        "# 검색엔진을 위한 파이프라인을 구축할때는 두종류의 검색어에 맞는 두종류의 색인을 구축 (정규화 o/x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svNJPxrzTvLO"
      },
      "outputs": [],
      "source": [
        "# 어간 추출(stemming)\n",
        "# 영어의 어간추출은 단어들에서 접미사를 제거함으로써 의미가 비슷한 단어들을 하나의 공통어간으로 묶음\n",
        "# 어간이 반드시 영어사전에 나오는 정확한 철자의 단어일 필요없음\n",
        "# 어간추출은 문서에 담긴 정보와 의미를 최대한 유지하면서 어휘의 크기를 줄이는 방법\n",
        "def stem(phrase):\n",
        "  return ' '.join([re.findall('^(.*ss|.*?)(s)?$', word)[0][0].strip(\"'\") for word in phrase.lower().split()])\n",
        "\n",
        "  # 만일 단어가 하나의 s로 끝나면 어간은 단어에서 s를 제외한 부분이고 접미사는 S이다\n",
        "  # 만일 단어가 s로 끝나지 않으면 어간은 그 단어 자체이고 접미사는 없다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Me_RtmuFXfwX",
        "outputId": "5b337e95-e498-4a9a-ac9e-ad32c8092ed5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'house'"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stem('houses')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SJG_L_ABXhJP",
        "outputId": "dbb32afd-148d-4f21-f9fd-627ec0a401a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'doctor house call'"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stem(\"Doctor House's calls\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WaVrn1yZXpEd",
        "outputId": "205f095a-a331-4676-88fe-99771554d508"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dish washer wash dish'"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 어간추출기\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "stemmer = PorterStemmer() \n",
        "' '.join([stemmer.stem(w).strip(\"'\") for w in \"dish washer's washed dishes\".split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rgNcgV6YfpW"
      },
      "outputs": [],
      "source": [
        "# 표제어 추출 (lemmatization) \n",
        "# 어근수준으로 내려가서 정규화하는것\n",
        "# 차원축소를 하게 하지만 모형이 덜 정확해지는 단점이 있음\n",
        "# 뿌리가 같지만 의미가 완전히 같지는 않은 여러 철자변형을 모두 같은 단어로 간주함\n",
        "# chat, chatter, chatty, chatting을 똑같이 취급\n",
        "# 단어의 의미를 고려해서 단어들을 정규화한다는 점에서 표제어 추출은 어간추출이나 대소문자 정규화보다 좀더 정확한 정규화 방법이라 할 수있음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "egbjPhUjZwMS",
        "outputId": "b1068237-4ab1-4d10-e53e-8a04431223dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'better'"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizer.lemmatize(\"better\")  # 명사로 판단"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "duCEhKtPZ8bS",
        "outputId": "fe82ea1d-b61e-487c-f672-c9299b3a03f2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'good'"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"better\",pos=\"a\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dSGkt5wBaA6J",
        "outputId": "b6e6780f-1ed1-4463-df7a-fffb62da45eb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'good'"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"goods\", pos=\"n\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nwX7gUUKaKGi",
        "outputId": "1c3d1d7c-f407-4c4e-80af-d26133cfa3ba"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'goods'"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"goods\", pos=\"a\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6LPPqPY-aMSs",
        "outputId": "326f1b94-489d-4b33-bda7-bc93094f6d93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'best'"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatizer.lemmatize(\"best\", pos=\"a\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVIPjR5JaOF8"
      },
      "outputs": [],
      "source": [
        "# 일반적으로 어간 추출이 표제어 추출보다 더 빠르고 필요한 코드와 자료집합도 덜 복잡함\n",
        "# 둘다 어휘의 크기를 줄이는 대신 텍스트의 중의성을 높인다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu3yVoWGcIiK",
        "outputId": "49b00d2d-7438-4df7-ecad-a71cb7c84457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "# 감정분석\n",
        "# VADER알고리즘이 사용되곤함\n",
        "# 규칙 기반 감정 분석기\n",
        "# Valence aware dictionary for sentiment reasoning \n",
        "# nltk.sentiment.vader 로 사용가능함\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIjmbuVncJg9"
      },
      "outputs": [],
      "source": [
        "sa = SentimentIntensityAnalyzer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2YDwPi2-8Vf",
        "outputId": "5f224560-924a-4f83-eb1b-a2a8d83b49cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'$:': -1.5,\n",
              " '%)': -0.4,\n",
              " '%-)': -1.5,\n",
              " '&-:': -0.4,\n",
              " '&:': -0.7,\n",
              " \"( '}{' )\": 1.6,\n",
              " '(%': -0.9,\n",
              " \"('-:\": 2.2,\n",
              " \"(':\": 2.3,\n",
              " '((-:': 2.1,\n",
              " '(*': 1.1,\n",
              " '(-%': -0.7,\n",
              " '(-*': 1.3,\n",
              " '(-:': 1.6,\n",
              " '(-:0': 2.8,\n",
              " '(-:<': -0.4,\n",
              " '(-:o': 1.5,\n",
              " '(-:O': 1.5,\n",
              " '(-:{': -0.1,\n",
              " '(-:|>*': 1.9,\n",
              " '(-;': 1.3,\n",
              " '(-;|': 2.1,\n",
              " '(8': 2.6,\n",
              " '(:': 2.2,\n",
              " '(:0': 2.4,\n",
              " '(:<': -0.2,\n",
              " '(:o': 2.5,\n",
              " '(:O': 2.5,\n",
              " '(;': 1.1,\n",
              " '(;<': 0.3,\n",
              " '(=': 2.2,\n",
              " '(?:': 2.1,\n",
              " '(^:': 1.5,\n",
              " '(^;': 1.5,\n",
              " '(^;0': 2.0,\n",
              " '(^;o': 1.9,\n",
              " '(o:': 1.6,\n",
              " \")':\": -2.0,\n",
              " \")-':\": -2.1,\n",
              " ')-:': -2.1,\n",
              " ')-:<': -2.2,\n",
              " ')-:{': -2.1,\n",
              " '):': -1.8,\n",
              " '):<': -1.9,\n",
              " '):{': -2.3,\n",
              " ');<': -2.6,\n",
              " '*)': 0.6,\n",
              " '*-)': 0.3,\n",
              " '*-:': 2.1,\n",
              " '*-;': 2.4,\n",
              " '*:': 1.9,\n",
              " '*<|:-)': 1.6,\n",
              " '*\\\\0/*': 2.3,\n",
              " '*^:': 1.6,\n",
              " ',-:': 1.2,\n",
              " \"---'-;-{@\": 2.3,\n",
              " '--<--<@': 2.2,\n",
              " '.-:': -1.2,\n",
              " '..###-:': -1.7,\n",
              " '..###:': -1.9,\n",
              " '/-:': -1.3,\n",
              " '/:': -1.3,\n",
              " '/:<': -1.4,\n",
              " '/=': -0.9,\n",
              " '/^:': -1.0,\n",
              " '/o:': -1.4,\n",
              " '0-8': 0.1,\n",
              " '0-|': -1.2,\n",
              " '0:)': 1.9,\n",
              " '0:-)': 1.4,\n",
              " '0:-3': 1.5,\n",
              " '0:03': 1.9,\n",
              " '0;^)': 1.6,\n",
              " '0_o': -0.3,\n",
              " '10q': 2.1,\n",
              " '1337': 2.1,\n",
              " '143': 3.2,\n",
              " '1432': 2.6,\n",
              " '14aa41': 2.4,\n",
              " '182': -2.9,\n",
              " '187': -3.1,\n",
              " '2g2b4g': 2.8,\n",
              " '2g2bt': -0.1,\n",
              " '2qt': 2.1,\n",
              " '3:(': -2.2,\n",
              " '3:)': 0.5,\n",
              " '3:-(': -2.3,\n",
              " '3:-)': -1.4,\n",
              " '4col': -2.2,\n",
              " '4q': -3.1,\n",
              " '5fs': 1.5,\n",
              " '8)': 1.9,\n",
              " '8-d': 1.7,\n",
              " '8-o': -0.3,\n",
              " '86': -1.6,\n",
              " '8d': 2.9,\n",
              " ':###..': -2.4,\n",
              " ':$': -0.2,\n",
              " ':&': -0.6,\n",
              " \":'(\": -2.2,\n",
              " \":')\": 2.3,\n",
              " \":'-(\": -2.4,\n",
              " \":'-)\": 2.7,\n",
              " ':(': -1.9,\n",
              " ':)': 2.0,\n",
              " ':*': 2.5,\n",
              " ':-###..': -2.5,\n",
              " ':-&': -0.5,\n",
              " ':-(': -1.5,\n",
              " ':-)': 1.3,\n",
              " ':-))': 2.8,\n",
              " ':-*': 1.7,\n",
              " ':-,': 1.1,\n",
              " ':-.': -0.9,\n",
              " ':-/': -1.2,\n",
              " ':-<': -1.5,\n",
              " ':-d': 2.3,\n",
              " ':-D': 2.3,\n",
              " ':-o': 0.1,\n",
              " ':-p': 1.5,\n",
              " ':-[': -1.6,\n",
              " ':-\\\\': -0.9,\n",
              " ':-c': -1.3,\n",
              " ':-|': -0.7,\n",
              " ':-||': -2.5,\n",
              " ':-Þ': 0.9,\n",
              " ':/': -1.4,\n",
              " ':3': 2.3,\n",
              " ':<': -2.1,\n",
              " ':>': 2.1,\n",
              " ':?)': 1.3,\n",
              " ':?c': -1.6,\n",
              " ':@': -2.5,\n",
              " ':d': 2.3,\n",
              " ':D': 2.3,\n",
              " ':l': -1.7,\n",
              " ':o': -0.4,\n",
              " ':p': 1.0,\n",
              " ':s': -1.2,\n",
              " ':[': -2.0,\n",
              " ':\\\\': -1.3,\n",
              " ':]': 2.2,\n",
              " ':^)': 2.1,\n",
              " ':^*': 2.6,\n",
              " ':^/': -1.2,\n",
              " ':^\\\\': -1.0,\n",
              " ':^|': -1.0,\n",
              " ':c': -2.1,\n",
              " ':c)': 2.0,\n",
              " ':o)': 2.1,\n",
              " ':o/': -1.4,\n",
              " ':o\\\\': -1.1,\n",
              " ':o|': -0.6,\n",
              " ':P': 1.4,\n",
              " ':{': -1.9,\n",
              " ':|': -0.4,\n",
              " ':}': 2.1,\n",
              " ':Þ': 1.1,\n",
              " ';)': 0.9,\n",
              " ';-)': 1.0,\n",
              " ';-*': 2.2,\n",
              " ';-]': 0.7,\n",
              " ';d': 0.8,\n",
              " ';D': 0.8,\n",
              " ';]': 0.6,\n",
              " ';^)': 1.4,\n",
              " '</3': -3.0,\n",
              " '<3': 1.9,\n",
              " '<:': 2.1,\n",
              " '<:-|': -1.4,\n",
              " '=)': 2.2,\n",
              " '=-3': 2.0,\n",
              " '=-d': 2.4,\n",
              " '=-D': 2.4,\n",
              " '=/': -1.4,\n",
              " '=3': 2.1,\n",
              " '=d': 2.3,\n",
              " '=D': 2.3,\n",
              " '=l': -1.2,\n",
              " '=\\\\': -1.2,\n",
              " '=]': 1.6,\n",
              " '=p': 1.3,\n",
              " '=|': -0.8,\n",
              " '>-:': -2.0,\n",
              " '>.<': -1.3,\n",
              " '>:': -2.1,\n",
              " '>:(': -2.7,\n",
              " '>:)': 0.4,\n",
              " '>:-(': -2.7,\n",
              " '>:-)': -0.4,\n",
              " '>:/': -1.6,\n",
              " '>:o': -1.2,\n",
              " '>:p': 1.0,\n",
              " '>:[': -2.1,\n",
              " '>:\\\\': -1.7,\n",
              " '>;(': -2.9,\n",
              " '>;)': 0.1,\n",
              " '>_>^': 2.1,\n",
              " '@:': -2.1,\n",
              " '@>-->--': 2.1,\n",
              " \"@}-;-'---\": 2.2,\n",
              " 'aas': 2.5,\n",
              " 'aayf': 2.7,\n",
              " 'afu': -2.9,\n",
              " 'alol': 2.8,\n",
              " 'ambw': 2.9,\n",
              " 'aml': 3.4,\n",
              " 'atab': -1.9,\n",
              " 'awol': -1.3,\n",
              " 'ayc': 0.2,\n",
              " 'ayor': -1.2,\n",
              " 'aug-00': 0.3,\n",
              " 'bfd': -2.7,\n",
              " 'bfe': -2.6,\n",
              " 'bff': 2.9,\n",
              " 'bffn': 1.0,\n",
              " 'bl': 2.3,\n",
              " 'bsod': -2.2,\n",
              " 'btd': -2.1,\n",
              " 'btdt': -0.1,\n",
              " 'bz': 0.4,\n",
              " 'b^d': 2.6,\n",
              " 'cwot': -2.3,\n",
              " \"d-':\": -2.5,\n",
              " 'd8': -3.2,\n",
              " 'd:': 1.2,\n",
              " 'd:<': -3.2,\n",
              " 'd;': -2.9,\n",
              " 'd=': 1.5,\n",
              " 'doa': -2.3,\n",
              " 'dx': -3.0,\n",
              " 'ez': 1.5,\n",
              " 'fav': 2.0,\n",
              " 'fcol': -1.8,\n",
              " 'ff': 1.8,\n",
              " 'ffs': -2.8,\n",
              " 'fkm': -2.4,\n",
              " 'foaf': 1.8,\n",
              " 'ftw': 2.0,\n",
              " 'fu': -3.7,\n",
              " 'fubar': -3.0,\n",
              " 'fwb': 2.5,\n",
              " 'fyi': 0.8,\n",
              " 'fysa': 0.4,\n",
              " 'g1': 1.4,\n",
              " 'gg': 1.2,\n",
              " 'gga': 1.7,\n",
              " 'gigo': -0.6,\n",
              " 'gj': 2.0,\n",
              " 'gl': 1.3,\n",
              " 'gla': 2.5,\n",
              " 'gn': 1.2,\n",
              " 'gr8': 2.7,\n",
              " 'grrr': -0.4,\n",
              " 'gt': 1.1,\n",
              " 'h&k': 2.3,\n",
              " 'hagd': 2.2,\n",
              " 'hagn': 2.2,\n",
              " 'hago': 1.2,\n",
              " 'hak': 1.9,\n",
              " 'hand': 2.2,\n",
              " 'heart': 3.2,\n",
              " 'hearts': 3.3,\n",
              " 'hho1/2k': 1.4,\n",
              " 'hhoj': 2.0,\n",
              " 'hhok': 0.9,\n",
              " 'hugz': 2.0,\n",
              " 'hi5': 1.9,\n",
              " 'idk': -0.4,\n",
              " 'ijs': 0.7,\n",
              " 'ilu': 3.4,\n",
              " 'iluaaf': 2.7,\n",
              " 'ily': 3.4,\n",
              " 'ily2': 2.6,\n",
              " 'iou': 0.7,\n",
              " 'iyq': 2.3,\n",
              " 'j/j': 2.0,\n",
              " 'j/k': 1.6,\n",
              " 'j/p': 1.4,\n",
              " 'j/t': -0.2,\n",
              " 'j/w': 1.0,\n",
              " 'j4f': 1.4,\n",
              " 'j4g': 1.7,\n",
              " 'jho': 0.8,\n",
              " 'jhomf': 1.0,\n",
              " 'jj': 1.0,\n",
              " 'jk': 0.9,\n",
              " 'jp': 0.8,\n",
              " 'jt': 0.9,\n",
              " 'jw': 1.6,\n",
              " 'jealz': -1.2,\n",
              " 'k4y': 2.3,\n",
              " 'kfy': 2.3,\n",
              " 'kia': -3.2,\n",
              " 'kk': 1.5,\n",
              " 'kmuf': 2.2,\n",
              " 'l': 2.0,\n",
              " 'l&r': 2.2,\n",
              " 'laoj': 1.3,\n",
              " 'lmao': 2.9,\n",
              " 'lmbao': 1.8,\n",
              " 'lmfao': 2.5,\n",
              " 'lmso': 2.7,\n",
              " 'lol': 1.8,\n",
              " 'lolz': 2.7,\n",
              " 'lts': 1.6,\n",
              " 'ly': 2.6,\n",
              " 'ly4e': 2.7,\n",
              " 'lya': 3.3,\n",
              " 'lyb': 3.0,\n",
              " 'lyl': 3.1,\n",
              " 'lylab': 2.7,\n",
              " 'lylas': 2.6,\n",
              " 'lylb': 1.6,\n",
              " 'm8': 1.4,\n",
              " 'mia': -1.2,\n",
              " 'mml': 2.0,\n",
              " 'mofo': -2.4,\n",
              " 'muah': 2.3,\n",
              " 'mubar': -1.0,\n",
              " 'musm': 0.9,\n",
              " 'mwah': 2.5,\n",
              " 'n1': 1.9,\n",
              " 'nbd': 1.3,\n",
              " 'nbif': -0.5,\n",
              " 'nfc': -2.7,\n",
              " 'nfw': -2.4,\n",
              " 'nh': 2.2,\n",
              " 'nimby': -0.8,\n",
              " 'nimjd': -0.7,\n",
              " 'nimq': -0.2,\n",
              " 'nimy': -1.4,\n",
              " 'nitl': -1.5,\n",
              " 'nme': -2.1,\n",
              " 'noyb': -0.7,\n",
              " 'np': 1.4,\n",
              " 'ntmu': 1.4,\n",
              " 'o-8': -0.5,\n",
              " 'o-:': -0.3,\n",
              " 'o-|': -1.1,\n",
              " 'o.o': -0.8,\n",
              " 'O.o': -0.6,\n",
              " 'o.O': -0.6,\n",
              " 'o:': -0.2,\n",
              " 'o:)': 1.5,\n",
              " 'o:-)': 2.0,\n",
              " 'o:-3': 2.2,\n",
              " 'o:3': 2.3,\n",
              " 'o:<': -0.3,\n",
              " 'o;^)': 1.6,\n",
              " 'ok': 1.2,\n",
              " 'o_o': -0.5,\n",
              " 'O_o': -0.5,\n",
              " 'o_O': -0.5,\n",
              " 'pita': -2.4,\n",
              " 'pls': 0.3,\n",
              " 'plz': 0.3,\n",
              " 'pmbi': 0.8,\n",
              " 'pmfji': 0.3,\n",
              " 'pmji': 0.7,\n",
              " 'po': -2.6,\n",
              " 'ptl': 2.6,\n",
              " 'pu': -1.1,\n",
              " 'qq': -2.2,\n",
              " 'qt': 1.8,\n",
              " 'r&r': 2.4,\n",
              " 'rofl': 2.7,\n",
              " 'roflmao': 2.5,\n",
              " 'rotfl': 2.6,\n",
              " 'rotflmao': 2.8,\n",
              " 'rotflmfao': 2.5,\n",
              " 'rotflol': 3.0,\n",
              " 'rotgl': 2.9,\n",
              " 'rotglmao': 1.8,\n",
              " 's:': -1.1,\n",
              " 'sapfu': -1.1,\n",
              " 'sete': 2.8,\n",
              " 'sfete': 2.7,\n",
              " 'sgtm': 2.4,\n",
              " 'slap': 0.6,\n",
              " 'slaw': 2.1,\n",
              " 'smh': -1.3,\n",
              " 'snafu': -2.5,\n",
              " 'sob': -1.0,\n",
              " 'swak': 2.3,\n",
              " 'tgif': 2.3,\n",
              " 'thks': 1.4,\n",
              " 'thx': 1.5,\n",
              " 'tia': 2.3,\n",
              " 'tmi': -0.3,\n",
              " 'tnx': 1.1,\n",
              " 'true': 1.8,\n",
              " 'tx': 1.5,\n",
              " 'txs': 1.1,\n",
              " 'ty': 1.6,\n",
              " 'tyvm': 2.5,\n",
              " 'urw': 1.9,\n",
              " 'vbg': 2.1,\n",
              " 'vbs': 3.1,\n",
              " 'vip': 2.3,\n",
              " 'vwd': 2.6,\n",
              " 'vwp': 2.1,\n",
              " 'wag': -0.2,\n",
              " 'wd': 2.7,\n",
              " 'wilco': 0.9,\n",
              " 'wp': 1.0,\n",
              " 'wtf': -2.8,\n",
              " 'wtg': 2.1,\n",
              " 'wth': -2.4,\n",
              " 'x-d': 2.6,\n",
              " 'x-p': 1.7,\n",
              " 'xd': 2.8,\n",
              " 'xlnt': 3.0,\n",
              " 'xoxo': 3.0,\n",
              " 'xoxozzz': 2.3,\n",
              " 'xp': 1.6,\n",
              " 'xqzt': 1.6,\n",
              " 'xtc': 0.8,\n",
              " 'yolo': 1.1,\n",
              " 'yoyo': 0.4,\n",
              " 'yvw': 1.6,\n",
              " 'yw': 1.8,\n",
              " 'ywia': 2.5,\n",
              " 'zzz': -1.2,\n",
              " '[-;': 0.5,\n",
              " '[:': 1.3,\n",
              " '[;': 1.0,\n",
              " '[=': 1.7,\n",
              " '\\\\-:': -1.0,\n",
              " '\\\\:': -1.0,\n",
              " '\\\\:<': -1.7,\n",
              " '\\\\=': -1.1,\n",
              " '\\\\^:': -1.3,\n",
              " '\\\\o/': 2.2,\n",
              " '\\\\o:': -1.2,\n",
              " ']-:': -2.1,\n",
              " ']:': -1.6,\n",
              " ']:<': -2.5,\n",
              " '^<_<': 1.4,\n",
              " '^urs': -2.8,\n",
              " 'abandon': -1.9,\n",
              " 'abandoned': -2.0,\n",
              " 'abandoner': -1.9,\n",
              " 'abandoners': -1.9,\n",
              " 'abandoning': -1.6,\n",
              " 'abandonment': -2.4,\n",
              " 'abandonments': -1.7,\n",
              " 'abandons': -1.3,\n",
              " 'abducted': -2.3,\n",
              " 'abduction': -2.8,\n",
              " 'abductions': -2.0,\n",
              " 'abhor': -2.0,\n",
              " 'abhorred': -2.4,\n",
              " 'abhorrent': -3.1,\n",
              " 'abhors': -2.9,\n",
              " 'abilities': 1.0,\n",
              " 'ability': 1.3,\n",
              " 'aboard': 0.1,\n",
              " 'absentee': -1.1,\n",
              " 'absentees': -0.8,\n",
              " 'absolve': 1.2,\n",
              " 'absolved': 1.5,\n",
              " 'absolves': 1.3,\n",
              " 'absolving': 1.6,\n",
              " 'abuse': -3.2,\n",
              " 'abused': -2.3,\n",
              " 'abuser': -2.6,\n",
              " 'abusers': -2.6,\n",
              " 'abuses': -2.6,\n",
              " 'abusing': -2.0,\n",
              " 'abusive': -3.2,\n",
              " 'abusively': -2.8,\n",
              " 'abusiveness': -2.5,\n",
              " 'abusivenesses': -3.0,\n",
              " 'accept': 1.6,\n",
              " 'acceptabilities': 1.6,\n",
              " 'acceptability': 1.1,\n",
              " 'acceptable': 1.3,\n",
              " 'acceptableness': 1.3,\n",
              " 'acceptably': 1.5,\n",
              " 'acceptance': 2.0,\n",
              " 'acceptances': 1.7,\n",
              " 'acceptant': 1.6,\n",
              " 'acceptation': 1.3,\n",
              " 'acceptations': 0.9,\n",
              " 'accepted': 1.1,\n",
              " 'accepting': 1.6,\n",
              " 'accepts': 1.3,\n",
              " 'accident': -2.1,\n",
              " 'accidental': -0.3,\n",
              " 'accidentally': -1.4,\n",
              " 'accidents': -1.3,\n",
              " 'accomplish': 1.8,\n",
              " 'accomplished': 1.9,\n",
              " 'accomplishes': 1.7,\n",
              " 'accusation': -1.0,\n",
              " 'accusations': -1.3,\n",
              " 'accuse': -0.8,\n",
              " 'accused': -1.2,\n",
              " 'accuses': -1.4,\n",
              " 'accusing': -0.7,\n",
              " 'ache': -1.6,\n",
              " 'ached': -1.6,\n",
              " 'aches': -1.0,\n",
              " 'achievable': 1.3,\n",
              " 'aching': -2.2,\n",
              " 'acquit': 0.8,\n",
              " 'acquits': 0.1,\n",
              " 'acquitted': 1.0,\n",
              " 'acquitting': 1.3,\n",
              " 'acrimonious': -1.7,\n",
              " 'active': 1.7,\n",
              " 'actively': 1.3,\n",
              " 'activeness': 0.6,\n",
              " 'activenesses': 0.8,\n",
              " 'actives': 1.1,\n",
              " 'adequate': 0.9,\n",
              " 'admirability': 2.4,\n",
              " 'admirable': 2.6,\n",
              " 'admirableness': 2.2,\n",
              " 'admirably': 2.5,\n",
              " 'admiral': 1.3,\n",
              " 'admirals': 1.5,\n",
              " 'admiralties': 1.6,\n",
              " 'admiralty': 1.2,\n",
              " 'admiration': 2.5,\n",
              " 'admirations': 1.6,\n",
              " 'admire': 2.1,\n",
              " 'admired': 2.3,\n",
              " 'admirer': 1.8,\n",
              " 'admirers': 1.7,\n",
              " 'admires': 1.5,\n",
              " 'admiring': 1.6,\n",
              " 'admiringly': 2.3,\n",
              " 'admit': 0.8,\n",
              " 'admits': 1.2,\n",
              " 'admitted': 0.4,\n",
              " 'admonished': -1.9,\n",
              " 'adopt': 0.7,\n",
              " 'adopts': 0.7,\n",
              " 'adorability': 2.2,\n",
              " 'adorable': 2.2,\n",
              " 'adorableness': 2.5,\n",
              " 'adorably': 2.1,\n",
              " 'adoration': 2.9,\n",
              " 'adorations': 2.2,\n",
              " 'adore': 2.6,\n",
              " 'adored': 1.8,\n",
              " 'adorer': 1.7,\n",
              " 'adorers': 2.1,\n",
              " 'adores': 1.6,\n",
              " 'adoring': 2.6,\n",
              " 'adoringly': 2.4,\n",
              " 'adorn': 0.9,\n",
              " 'adorned': 0.8,\n",
              " 'adorner': 1.3,\n",
              " 'adorners': 0.9,\n",
              " 'adorning': 1.0,\n",
              " 'adornment': 1.3,\n",
              " 'adornments': 0.8,\n",
              " 'adorns': 0.5,\n",
              " 'advanced': 1.0,\n",
              " 'advantage': 1.0,\n",
              " 'advantaged': 1.4,\n",
              " 'advantageous': 1.5,\n",
              " 'advantageously': 1.9,\n",
              " 'advantageousness': 1.6,\n",
              " 'advantages': 1.5,\n",
              " 'advantaging': 1.6,\n",
              " 'adventure': 1.3,\n",
              " 'adventured': 1.3,\n",
              " 'adventurer': 1.2,\n",
              " 'adventurers': 0.9,\n",
              " 'adventures': 1.4,\n",
              " 'adventuresome': 1.7,\n",
              " 'adventuresomeness': 1.3,\n",
              " 'adventuress': 0.8,\n",
              " 'adventuresses': 1.4,\n",
              " 'adventuring': 2.3,\n",
              " 'adventurism': 1.5,\n",
              " 'adventurist': 1.4,\n",
              " 'adventuristic': 1.7,\n",
              " 'adventurists': 1.2,\n",
              " 'adventurous': 1.4,\n",
              " 'adventurously': 1.3,\n",
              " 'adventurousness': 1.8,\n",
              " 'adversarial': -1.5,\n",
              " 'adversaries': -1.0,\n",
              " 'adversary': -0.8,\n",
              " 'adversative': -1.2,\n",
              " 'adversatively': -0.1,\n",
              " 'adversatives': -1.0,\n",
              " 'adverse': -1.5,\n",
              " 'adversely': -0.8,\n",
              " 'adverseness': -0.6,\n",
              " 'adversities': -1.5,\n",
              " 'adversity': -1.8,\n",
              " 'affected': -0.6,\n",
              " 'affection': 2.4,\n",
              " 'affectional': 1.9,\n",
              " 'affectionally': 1.5,\n",
              " 'affectionate': 1.9,\n",
              " 'affectionately': 2.2,\n",
              " 'affectioned': 1.8,\n",
              " 'affectionless': -2.0,\n",
              " 'affections': 1.5,\n",
              " 'afflicted': -1.5,\n",
              " 'affronted': 0.2,\n",
              " 'aggravate': -2.5,\n",
              " 'aggravated': -1.9,\n",
              " 'aggravates': -1.9,\n",
              " 'aggravating': -1.2,\n",
              " 'aggress': -1.3,\n",
              " 'aggressed': -1.4,\n",
              " 'aggresses': -0.5,\n",
              " 'aggressing': -0.6,\n",
              " 'aggression': -1.2,\n",
              " 'aggressions': -1.3,\n",
              " 'aggressive': -0.6,\n",
              " 'aggressively': -1.3,\n",
              " 'aggressiveness': -1.8,\n",
              " 'aggressivities': -1.4,\n",
              " 'aggressivity': -0.6,\n",
              " 'aggressor': -0.8,\n",
              " 'aggressors': -0.9,\n",
              " 'aghast': -1.9,\n",
              " 'agitate': -1.7,\n",
              " 'agitated': -2.0,\n",
              " 'agitatedly': -1.6,\n",
              " 'agitates': -1.4,\n",
              " 'agitating': -1.8,\n",
              " 'agitation': -1.0,\n",
              " 'agitational': -1.2,\n",
              " 'agitations': -1.3,\n",
              " 'agitative': -1.3,\n",
              " 'agitato': -0.1,\n",
              " 'agitator': -1.4,\n",
              " 'agitators': -2.1,\n",
              " 'agog': 1.9,\n",
              " 'agonise': -2.1,\n",
              " 'agonised': -2.3,\n",
              " 'agonises': -2.4,\n",
              " 'agonising': -1.5,\n",
              " 'agonize': -2.3,\n",
              " 'agonized': -2.2,\n",
              " 'agonizes': -2.3,\n",
              " 'agonizing': -2.7,\n",
              " 'agonizingly': -2.3,\n",
              " 'agony': -1.8,\n",
              " 'agree': 1.5,\n",
              " 'agreeability': 1.9,\n",
              " 'agreeable': 1.8,\n",
              " 'agreeableness': 1.8,\n",
              " 'agreeablenesses': 1.3,\n",
              " 'agreeably': 1.6,\n",
              " 'agreed': 1.1,\n",
              " 'agreeing': 1.4,\n",
              " 'agreement': 2.2,\n",
              " 'agreements': 1.1,\n",
              " 'agrees': 0.8,\n",
              " 'alarm': -1.4,\n",
              " 'alarmed': -1.4,\n",
              " 'alarming': -0.5,\n",
              " 'alarmingly': -2.6,\n",
              " 'alarmism': -0.3,\n",
              " 'alarmists': -1.1,\n",
              " 'alarms': -1.1,\n",
              " 'alas': -1.1,\n",
              " 'alert': 1.2,\n",
              " 'alienation': -1.1,\n",
              " 'alive': 1.6,\n",
              " 'allergic': -1.2,\n",
              " 'allow': 0.9,\n",
              " 'alone': -1.0,\n",
              " 'alright': 1.0,\n",
              " 'amaze': 2.5,\n",
              " 'amazed': 2.2,\n",
              " 'amazedly': 2.1,\n",
              " 'amazement': 2.5,\n",
              " 'amazements': 2.2,\n",
              " 'amazes': 2.2,\n",
              " 'amazing': 2.8,\n",
              " 'amazon': 0.7,\n",
              " 'amazonite': 0.2,\n",
              " 'amazons': -0.1,\n",
              " 'amazonstone': 1.0,\n",
              " 'amazonstones': 0.2,\n",
              " 'ambitious': 2.1,\n",
              " 'ambivalent': 0.5,\n",
              " 'amor': 3.0,\n",
              " 'amoral': -1.6,\n",
              " 'amoralism': -0.7,\n",
              " 'amoralisms': -0.7,\n",
              " 'amoralities': -1.2,\n",
              " 'amorality': -1.5,\n",
              " 'amorally': -1.0,\n",
              " 'amoretti': 0.2,\n",
              " 'amoretto': 0.6,\n",
              " 'amorettos': 0.3,\n",
              " 'amorino': 1.2,\n",
              " 'amorist': 1.6,\n",
              " 'amoristic': 1.0,\n",
              " 'amorists': 0.1,\n",
              " 'amoroso': 2.3,\n",
              " 'amorous': 1.8,\n",
              " 'amorously': 2.3,\n",
              " 'amorousness': 2.0,\n",
              " 'amorphous': -0.2,\n",
              " 'amorphously': 0.1,\n",
              " 'amorphousness': 0.3,\n",
              " 'amort': -2.1,\n",
              " 'amortise': 0.5,\n",
              " 'amortised': -0.2,\n",
              " 'amortises': 0.1,\n",
              " 'amortizable': 0.5,\n",
              " 'amortization': 0.6,\n",
              " 'amortizations': 0.2,\n",
              " 'amortize': -0.1,\n",
              " 'amortized': 0.8,\n",
              " 'amortizes': 0.6,\n",
              " 'amortizing': 0.8,\n",
              " 'amusable': 0.7,\n",
              " 'amuse': 1.7,\n",
              " 'amused': 1.8,\n",
              " 'amusedly': 2.2,\n",
              " 'amusement': 1.5,\n",
              " 'amusements': 1.5,\n",
              " 'amuser': 1.1,\n",
              " 'amusers': 1.3,\n",
              " 'amuses': 1.7,\n",
              " 'amusia': 0.3,\n",
              " 'amusias': -0.4,\n",
              " 'amusing': 1.6,\n",
              " 'amusingly': 0.8,\n",
              " 'amusingness': 1.8,\n",
              " 'amusive': 1.7,\n",
              " 'anger': -2.7,\n",
              " 'angered': -2.3,\n",
              " 'angering': -2.2,\n",
              " 'angerly': -1.9,\n",
              " 'angers': -2.3,\n",
              " 'angrier': -2.3,\n",
              " 'angriest': -3.1,\n",
              " 'angrily': -1.8,\n",
              " 'angriness': -1.7,\n",
              " 'angry': -2.3,\n",
              " 'anguish': -2.9,\n",
              " 'anguished': -1.8,\n",
              " 'anguishes': -2.1,\n",
              " 'anguishing': -2.7,\n",
              " 'animosity': -1.9,\n",
              " 'annoy': -1.9,\n",
              " 'annoyance': -1.3,\n",
              " 'annoyances': -1.8,\n",
              " 'annoyed': -1.6,\n",
              " 'annoyer': -2.2,\n",
              " 'annoyers': -1.5,\n",
              " 'annoying': -1.7,\n",
              " 'annoys': -1.8,\n",
              " 'antagonism': -1.9,\n",
              " 'antagonisms': -1.2,\n",
              " 'antagonist': -1.9,\n",
              " 'antagonistic': -1.7,\n",
              " 'antagonistically': -2.2,\n",
              " 'antagonists': -1.7,\n",
              " 'antagonize': -2.0,\n",
              " 'antagonized': -1.4,\n",
              " 'antagonizes': -0.5,\n",
              " 'antagonizing': -2.7,\n",
              " 'anti': -1.3,\n",
              " 'anticipation': 0.4,\n",
              " 'anxieties': -0.6,\n",
              " 'anxiety': -0.7,\n",
              " 'anxious': -1.0,\n",
              " 'anxiously': -0.9,\n",
              " 'anxiousness': -1.0,\n",
              " 'aok': 2.0,\n",
              " 'apathetic': -1.2,\n",
              " 'apathetically': -0.4,\n",
              " 'apathies': -0.6,\n",
              " 'apathy': -1.2,\n",
              " 'apeshit': -0.9,\n",
              " 'apocalyptic': -3.4,\n",
              " 'apologise': 1.6,\n",
              " 'apologised': 0.4,\n",
              " 'apologises': 0.8,\n",
              " 'apologising': 0.2,\n",
              " 'apologize': 0.4,\n",
              " 'apologized': 1.3,\n",
              " 'apologizes': 1.5,\n",
              " 'apologizing': -0.3,\n",
              " 'apology': 0.2,\n",
              " 'appall': -2.4,\n",
              " 'appalled': -2.0,\n",
              " 'appalling': -1.5,\n",
              " 'appallingly': -2.0,\n",
              " 'appalls': -1.9,\n",
              " 'appease': 1.1,\n",
              " 'appeased': 0.9,\n",
              " 'appeases': 0.9,\n",
              " 'appeasing': 1.0,\n",
              " 'applaud': 2.0,\n",
              " 'applauded': 1.5,\n",
              " 'applauding': 2.1,\n",
              " 'applauds': 1.4,\n",
              " 'applause': 1.8,\n",
              " 'appreciate': 1.7,\n",
              " 'appreciated': 2.3,\n",
              " 'appreciates': 2.3,\n",
              " 'appreciating': 1.9,\n",
              " 'appreciation': 2.3,\n",
              " 'appreciations': 1.7,\n",
              " 'appreciative': 2.6,\n",
              " 'appreciatively': 1.8,\n",
              " 'appreciativeness': 1.6,\n",
              " 'appreciator': 2.6,\n",
              " 'appreciators': 1.5,\n",
              " 'appreciatory': 1.7,\n",
              " 'apprehensible': 1.1,\n",
              " 'apprehensibly': -0.2,\n",
              " 'apprehension': -2.1,\n",
              " 'apprehensions': -0.9,\n",
              " 'apprehensively': -0.3,\n",
              " 'apprehensiveness': -0.7,\n",
              " 'approval': 2.1,\n",
              " 'approved': 1.8,\n",
              " 'approves': 1.7,\n",
              " 'ardent': 2.1,\n",
              " 'arguable': -1.0,\n",
              " 'arguably': -1.0,\n",
              " 'argue': -1.4,\n",
              " 'argued': -1.5,\n",
              " 'arguer': -1.6,\n",
              " 'arguers': -1.4,\n",
              " 'argues': -1.6,\n",
              " 'arguing': -2.0,\n",
              " 'argument': -1.5,\n",
              " 'argumentative': -1.5,\n",
              " 'argumentatively': -1.8,\n",
              " 'argumentive': -1.5,\n",
              " 'arguments': -1.7,\n",
              " 'arrest': -1.4,\n",
              " 'arrested': -2.1,\n",
              " 'arrests': -1.9,\n",
              " 'arrogance': -2.4,\n",
              " 'arrogances': -1.9,\n",
              " 'arrogant': -2.2,\n",
              " 'arrogantly': -1.8,\n",
              " 'ashamed': -2.1,\n",
              " 'ashamedly': -1.7,\n",
              " 'ass': -2.5,\n",
              " 'assassination': -2.9,\n",
              " 'assassinations': -2.7,\n",
              " 'assault': -2.8,\n",
              " 'assaulted': -2.4,\n",
              " 'assaulting': -2.3,\n",
              " 'assaultive': -2.8,\n",
              " 'assaults': -2.5,\n",
              " 'asset': 1.5,\n",
              " 'assets': 0.7,\n",
              " 'assfucking': -2.5,\n",
              " 'assholes': -2.8,\n",
              " 'assurance': 1.4,\n",
              " 'assurances': 1.4,\n",
              " 'assure': 1.4,\n",
              " 'assured': 1.5,\n",
              " 'assuredly': 1.6,\n",
              " 'assuredness': 1.4,\n",
              " 'assurer': 0.9,\n",
              " 'assurers': 1.1,\n",
              " 'assures': 1.3,\n",
              " 'assurgent': 1.3,\n",
              " 'assuring': 1.6,\n",
              " 'assuror': 0.5,\n",
              " 'assurors': 0.7,\n",
              " 'astonished': 1.6,\n",
              " 'astound': 1.7,\n",
              " 'astounded': 1.8,\n",
              " 'astounding': 1.8,\n",
              " 'astoundingly': 2.1,\n",
              " 'astounds': 2.1,\n",
              " 'attachment': 1.2,\n",
              " 'attachments': 1.1,\n",
              " 'attack': -2.1,\n",
              " 'attacked': -2.0,\n",
              " 'attacker': -2.7,\n",
              " 'attackers': -2.7,\n",
              " 'attacking': -2.0,\n",
              " 'attacks': -1.9,\n",
              " 'attract': 1.5,\n",
              " 'attractancy': 0.9,\n",
              " 'attractant': 1.3,\n",
              " 'attractants': 1.4,\n",
              " 'attracted': 1.8,\n",
              " 'attracting': 2.1,\n",
              " 'attraction': 2.0,\n",
              " 'attractions': 1.8,\n",
              " 'attractive': 1.9,\n",
              " 'attractively': 2.2,\n",
              " 'attractiveness': 1.8,\n",
              " 'attractivenesses': 2.1,\n",
              " 'attractor': 1.2,\n",
              " 'attractors': 1.2,\n",
              " 'attracts': 1.7,\n",
              " 'audacious': 0.9,\n",
              " 'authority': 0.3,\n",
              " 'aversion': -1.9,\n",
              " 'aversions': -1.1,\n",
              " 'aversive': -1.6,\n",
              " 'aversively': -0.8,\n",
              " 'avert': -0.7,\n",
              " 'averted': -0.3,\n",
              " 'averts': -0.4,\n",
              " 'avid': 1.2,\n",
              " 'avoid': -1.2,\n",
              " 'avoidance': -1.7,\n",
              " 'avoidances': -1.1,\n",
              " 'avoided': -1.4,\n",
              " 'avoider': -1.8,\n",
              " 'avoiders': -1.4,\n",
              " 'avoiding': -1.4,\n",
              " 'avoids': -0.7,\n",
              " 'await': 0.4,\n",
              " 'awaited': -0.1,\n",
              " 'awaits': 0.3,\n",
              " 'award': 2.5,\n",
              " 'awardable': 2.4,\n",
              " 'awarded': 1.7,\n",
              " 'awardee': 1.8,\n",
              " 'awardees': 1.2,\n",
              " 'awarder': 0.9,\n",
              " 'awarders': 1.3,\n",
              " 'awarding': 1.9,\n",
              " 'awards': 2.0,\n",
              " 'awesome': 3.1,\n",
              " 'awful': -2.0,\n",
              " 'awkward': -0.6,\n",
              " 'awkwardly': -1.3,\n",
              " 'awkwardness': -0.7,\n",
              " 'axe': -0.4,\n",
              " 'axed': -1.3,\n",
              " 'backed': 0.1,\n",
              " 'backing': 0.1,\n",
              " 'backs': -0.2,\n",
              " 'bad': -2.5,\n",
              " 'badass': 1.4,\n",
              " 'badly': -2.1,\n",
              " 'bailout': -0.4,\n",
              " 'bamboozle': -1.5,\n",
              " 'bamboozled': -1.5,\n",
              " 'bamboozles': -1.5,\n",
              " 'ban': -2.6,\n",
              " 'banish': -1.9,\n",
              " 'bankrupt': -2.6,\n",
              " 'bankster': -2.1,\n",
              " 'banned': -2.0,\n",
              " 'bargain': 0.8,\n",
              " 'barrier': -0.5,\n",
              " 'bashful': -0.1,\n",
              " 'bashfully': 0.2,\n",
              " 'bashfulness': -0.8,\n",
              " 'bastard': -2.5,\n",
              " 'bastardies': -1.8,\n",
              " 'bastardise': -2.1,\n",
              " 'bastardised': -2.3,\n",
              " 'bastardises': -2.3,\n",
              " 'bastardising': -2.6,\n",
              " 'bastardization': -2.4,\n",
              " 'bastardizations': -2.1,\n",
              " 'bastardize': -2.4,\n",
              " 'bastardized': -2.0,\n",
              " 'bastardizes': -1.8,\n",
              " 'bastardizing': -2.3,\n",
              " 'bastardly': -2.7,\n",
              " 'bastards': -3.0,\n",
              " 'bastardy': -2.7,\n",
              " 'battle': -1.6,\n",
              " 'battled': -1.2,\n",
              " 'battlefield': -1.6,\n",
              " 'battlefields': -0.9,\n",
              " 'battlefront': -1.2,\n",
              " 'battlefronts': -0.8,\n",
              " 'battleground': -1.7,\n",
              " 'battlegrounds': -0.6,\n",
              " 'battlement': -0.4,\n",
              " 'battlements': -0.4,\n",
              " 'battler': -0.8,\n",
              " 'battlers': -0.2,\n",
              " 'battles': -1.6,\n",
              " 'battleship': -0.1,\n",
              " 'battleships': -0.5,\n",
              " 'battlewagon': -0.3,\n",
              " 'battlewagons': -0.5,\n",
              " 'battling': -1.1,\n",
              " 'beaten': -1.8,\n",
              " 'beatific': 1.8,\n",
              " 'beating': -2.0,\n",
              " 'beaut': 1.6,\n",
              " 'beauteous': 2.5,\n",
              " 'beauteously': 2.6,\n",
              " ...}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sa.lexicon # 토큰 감정 점수 쌍들이 들어있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apWcT8A8cJkV",
        "outputId": "767d2886-9e9e-4916-e007-56dfd558fa62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sa.polarity_scores(text={':(': -1.9, ':)': 2.0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xufCpoNXcJme",
        "outputId": "090c2dc2-d20d-43b6-d7e5-299a8bbaed7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(\"( '}{' )\", 1.6),\n",
              " (\"can't stand\", -2.0),\n",
              " ('fed up', -1.8),\n",
              " ('screwed up', -1.5)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(tok, score) for tok, score in sa.lexicon.items() if \" \" in tok] # 7500개 정의된것 중에서 빈칸이 포함된것은 세개뿐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uuj_gXOrcJou",
        "outputId": "8e1c15fd-9104-4c13-a263-a385eec6a3cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'compound': 0.6249, 'neg': 0.0, 'neu': 0.661, 'pos': 0.339}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sa.polarity_scores(text=\"python is very readable and it's great for NLP.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE-ftJumcJrz",
        "outputId": "c7bccee9-4929-467f-be7d-10626f4daab6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'compound': 0.431, 'neg': 0.0, 'neu': 0.737, 'pos': 0.263}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sa.polarity_scores(text=\"Python is not a bad choice for most applications\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSYoCZuqAC3W",
        "outputId": "a9f0f295-fb8e-4300-dd87-01eb6304e0f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+0.9368:absolutely perfect love it :-) :-) :-)\n",
            "-0.8768:horrible! completely useless. :(\n",
            "+0.1531:it was ok some good and some bad things\n"
          ]
        }
      ],
      "source": [
        "corpus = [\"absolutely perfect love it :-) :-) :-)\",\n",
        "          \"horrible! completely useless. :(\",\n",
        "          \"it was ok some good and some bad things\"\n",
        "          ]\n",
        "for doc in corpus:\n",
        "  scores=sa.polarity_scores(doc)\n",
        "  print('{:+}:{}'.format(scores['compound'], doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92vAPSetAC7L"
      },
      "outputs": [],
      "source": [
        "# vader의 단점은 모든 단어가 아니라 약 7500개 단어만 고려한다는것\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM9sd-8BBoFc"
      },
      "outputs": [],
      "source": [
        "# 단순 베이즈 모\n",
        "# 감정 분석의 경우 목표변수는 평가하고자 하는 감정\n",
        "# VADER처럼 규칙기반 감정분석기와는 달리 사람이 개별 단어들에 대해 일일이 감정 점수를 지정해 둘 필요가 없음\n",
        "# 임의의 문제에 대해 최선의 감정점수를 찾아냄\n",
        "# 언어모델을 사용해 문장생성을 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jep7bgGFC18A",
        "outputId": "ae0a7e23-841c-47c8-9db8-d6d10305403d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n"
          ]
        }
      ],
      "source": [
        "from nlpia.loaders import get_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "9Pv4WeXMAC-1",
        "outputId": "9d4f510d-c37f-428e-a2cd-721268d48c13"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a6a7760b-58ef-401c-9cc9-ed83ae0ee201\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.27</td>\n",
              "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.53</td>\n",
              "      <td>The gorgeously elaborate continuation of ''The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.60</td>\n",
              "      <td>Effective but too tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.47</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.73</td>\n",
              "      <td>Emerges as something rare, an issue movie that...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6a7760b-58ef-401c-9cc9-ed83ae0ee201')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6a7760b-58ef-401c-9cc9-ed83ae0ee201 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6a7760b-58ef-401c-9cc9-ed83ae0ee201');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    sentiment                                               text\n",
              "id                                                              \n",
              "1        2.27  The Rock is destined to be the 21st Century's ...\n",
              "2        3.53  The gorgeously elaborate continuation of ''The...\n",
              "3       -0.60                     Effective but too tepid biopic\n",
              "4        1.47  If you sometimes like to go to the movies to h...\n",
              "5        1.73  Emerges as something rare, an issue movie that..."
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies =get_data(\"hutto_movies\")\n",
        "movies.head().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpNg7qh6HlxW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.width', 75)  # dataframe의 내용이 좀더 보기좋게 변함\n",
        "from nltk.tokenize import casual_tokenize # 이모티콘과 비표준적인 문장부호, 비속어를 더 잘처리함\n",
        "bags_of_words = []\n",
        "from collections import Counter\n",
        "for text in movies.text:\n",
        "  bags_of_words.append(Counter(casual_tokenize(text))) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McTVoSKaHl5U"
      },
      "outputs": [],
      "source": [
        "df_bows = pd.DataFrame.from_records(bags_of_words) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-0jyvvHIH-c",
        "outputId": "973ec712-b693-4218-9669-ccb3760f7e87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10605, 20756)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_bows = df_bows.fillna(0).astype(int)\n",
        "\n",
        "df_bows.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "h3Y1WveQIIWU",
        "outputId": "1ba8312e-c95a-4ddf-de62-6f964b627cd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-13f7f796-27e4-4add-82ce-181184d049f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>Rock</th>\n",
              "      <th>is</th>\n",
              "      <th>destined</th>\n",
              "      <th>to</th>\n",
              "      <th>be</th>\n",
              "      <th>the</th>\n",
              "      <th>21st</th>\n",
              "      <th>Century's</th>\n",
              "      <th>new</th>\n",
              "      <th>...</th>\n",
              "      <th>Ill</th>\n",
              "      <th>slummer</th>\n",
              "      <th>Rashomon</th>\n",
              "      <th>dipsticks</th>\n",
              "      <th>Bearable</th>\n",
              "      <th>Staggeringly</th>\n",
              "      <th>’</th>\n",
              "      <th>ve</th>\n",
              "      <th>muttering</th>\n",
              "      <th>dissing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 20756 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13f7f796-27e4-4add-82ce-181184d049f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13f7f796-27e4-4add-82ce-181184d049f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13f7f796-27e4-4add-82ce-181184d049f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  Ill  \\\n",
              "0    1     1   1         1   2   1    1     1          1    1  ...    0   \n",
              "1    2     0   1         0   0   0    1     0          0    0  ...    0   \n",
              "2    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
              "3    0     0   1         0   4   0    1     0          0    0  ...    0   \n",
              "4    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
              "\n",
              "   slummer  Rashomon  dipsticks  Bearable  Staggeringly  ’  ve  \\\n",
              "0        0         0          0         0             0  0   0   \n",
              "1        0         0          0         0             0  0   0   \n",
              "2        0         0          0         0             0  0   0   \n",
              "3        0         0          0         0             0  0   0   \n",
              "4        0         0          0         0             0  0   0   \n",
              "\n",
              "   muttering  dissing  \n",
              "0          0        0  \n",
              "1          0        0  \n",
              "2          0        0  \n",
              "3          0        0  \n",
              "4          0        0  \n",
              "\n",
              "[5 rows x 20756 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_bows.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "doScJFB-IIZb",
        "outputId": "666dc9e6-46ad-4c9b-e8ff-b82a7e8870ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0657f918-10b5-40aa-9c1a-ed90900ace69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>Rock</th>\n",
              "      <th>is</th>\n",
              "      <th>destined</th>\n",
              "      <th>to</th>\n",
              "      <th>be</th>\n",
              "      <th>the</th>\n",
              "      <th>21st</th>\n",
              "      <th>Century's</th>\n",
              "      <th>new</th>\n",
              "      <th>...</th>\n",
              "      <th>Schwarzenegger</th>\n",
              "      <th>,</th>\n",
              "      <th>Jean</th>\n",
              "      <th>Claud</th>\n",
              "      <th>Van</th>\n",
              "      <th>Damme</th>\n",
              "      <th>or</th>\n",
              "      <th>Steven</th>\n",
              "      <th>Segal</th>\n",
              "      <th>.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0657f918-10b5-40aa-9c1a-ed90900ace69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0657f918-10b5-40aa-9c1a-ed90900ace69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0657f918-10b5-40aa-9c1a-ed90900ace69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  \\\n",
              "0    1     1   1         1   2   1    1     1          1    1  ...   \n",
              "1    2     0   1         0   0   0    1     0          0    0  ...   \n",
              "2    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "3    0     0   1         0   4   0    1     0          0    0  ...   \n",
              "4    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "\n",
              "   Schwarzenegger  ,  Jean  Claud  Van  Damme  or  Steven  Segal  .  \n",
              "0               1  1     1      1    1      1   1       1      1  1  \n",
              "1               0  0     0      0    0      0   0       0      0  4  \n",
              "2               0  0     0      0    0      0   0       0      0  0  \n",
              "3               0  1     0      0    0      0   0       0      0  1  \n",
              "4               0  1     0      0    0      0   0       0      0  1  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_bows.head()[list(bags_of_words[0].keys())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eomXzKomIgOr",
        "outputId": "c0bb7e37-6698-4f60-fb13-2cd4ffce7ce0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 베이즈 모델을 활용한 감정분석\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "nb = MultinomialNB()\n",
        "nb = nb.fit(df_bows, movies.sentiment > 0) \n",
        "nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6n20_1XLQU6",
        "outputId": "27f68d77-3e8b-4809-9a25-77132c1ed252"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id\n",
              "1         True\n",
              "2         True\n",
              "3        False\n",
              "4         True\n",
              "5         True\n",
              "         ...  \n",
              "10601    False\n",
              "10602    False\n",
              "10603    False\n",
              "10604     True\n",
              "10605    False\n",
              "Name: sentiment, Length: 10605, dtype: bool"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies.sentiment > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "CSb8AMklJhUK",
        "outputId": "84742c3a-ee49-4a46-96a0-74d67f3ed1e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cc4354eb-d7be-4bf1-b44b-d324be6bb0c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.266667</td>\n",
              "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.533333</td>\n",
              "      <td>The gorgeously elaborate continuation of ''The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.600000</td>\n",
              "      <td>Effective but too tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.466667</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.733333</td>\n",
              "      <td>Emerges as something rare, an issue movie that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10601</th>\n",
              "      <td>-0.062500</td>\n",
              "      <td>Well made but mush hearted.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10602</th>\n",
              "      <td>-1.500000</td>\n",
              "      <td>A real snooze.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10603</th>\n",
              "      <td>-0.625000</td>\n",
              "      <td>No surprises.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10604</th>\n",
              "      <td>1.437500</td>\n",
              "      <td>We’ve seen the hippie turned yuppie plot befor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10605</th>\n",
              "      <td>-1.812500</td>\n",
              "      <td>Her fans walked out muttering words like ''hor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10605 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc4354eb-d7be-4bf1-b44b-d324be6bb0c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc4354eb-d7be-4bf1-b44b-d324be6bb0c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc4354eb-d7be-4bf1-b44b-d324be6bb0c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       sentiment                                               text\n",
              "id                                                                 \n",
              "1       2.266667  The Rock is destined to be the 21st Century's ...\n",
              "2       3.533333  The gorgeously elaborate continuation of ''The...\n",
              "3      -0.600000                     Effective but too tepid biopic\n",
              "4       1.466667  If you sometimes like to go to the movies to h...\n",
              "5       1.733333  Emerges as something rare, an issue movie that...\n",
              "...          ...                                                ...\n",
              "10601  -0.062500                        Well made but mush hearted.\n",
              "10602  -1.500000                                     A real snooze.\n",
              "10603  -0.625000                                      No surprises.\n",
              "10604   1.437500  We’ve seen the hippie turned yuppie plot befor...\n",
              "10605  -1.812500  Her fans walked out muttering words like ''hor...\n",
              "\n",
              "[10605 rows x 2 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ysDr5TxCJlmN",
        "outputId": "660e314a-91df-4c3e-ce90-ac2988aaf7e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eca2da9f-d77d-4934-8543-496e9a70038e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>Rock</th>\n",
              "      <th>is</th>\n",
              "      <th>destined</th>\n",
              "      <th>to</th>\n",
              "      <th>be</th>\n",
              "      <th>the</th>\n",
              "      <th>21st</th>\n",
              "      <th>Century's</th>\n",
              "      <th>new</th>\n",
              "      <th>...</th>\n",
              "      <th>Ill</th>\n",
              "      <th>slummer</th>\n",
              "      <th>Rashomon</th>\n",
              "      <th>dipsticks</th>\n",
              "      <th>Bearable</th>\n",
              "      <th>Staggeringly</th>\n",
              "      <th>’</th>\n",
              "      <th>ve</th>\n",
              "      <th>muttering</th>\n",
              "      <th>dissing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10600</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10601</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10602</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10603</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10604</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10605 rows × 20756 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eca2da9f-d77d-4934-8543-496e9a70038e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eca2da9f-d77d-4934-8543-496e9a70038e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eca2da9f-d77d-4934-8543-496e9a70038e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       The  Rock  is  destined  to  be  the  21st  Century's  new  ...  \\\n",
              "0        1     1   1         1   2   1    1     1          1    1  ...   \n",
              "1        2     0   1         0   0   0    1     0          0    0  ...   \n",
              "2        0     0   0         0   0   0    0     0          0    0  ...   \n",
              "3        0     0   1         0   4   0    1     0          0    0  ...   \n",
              "4        0     0   0         0   0   0    0     0          0    0  ...   \n",
              "...    ...   ...  ..       ...  ..  ..  ...   ...        ...  ...  ...   \n",
              "10600    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "10601    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "10602    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "10603    0     0   0         0   0   0    2     0          0    0  ...   \n",
              "10604    0     0   0         0   0   0    2     0          0    0  ...   \n",
              "\n",
              "       Ill  slummer  Rashomon  dipsticks  Bearable  Staggeringly  ’  ve  \\\n",
              "0        0        0         0          0         0             0  0   0   \n",
              "1        0        0         0          0         0             0  0   0   \n",
              "2        0        0         0          0         0             0  0   0   \n",
              "3        0        0         0          0         0             0  0   0   \n",
              "4        0        0         0          0         0             0  0   0   \n",
              "...    ...      ...       ...        ...       ...           ... ..  ..   \n",
              "10600    0        0         0          0         0             0  0   0   \n",
              "10601    0        0         0          0         0             0  0   0   \n",
              "10602    0        0         0          0         0             0  0   0   \n",
              "10603    0        0         0          0         0             0  2   1   \n",
              "10604    0        0         0          0         0             0  0   0   \n",
              "\n",
              "       muttering  dissing  \n",
              "0              0        0  \n",
              "1              0        0  \n",
              "2              0        0  \n",
              "3              0        0  \n",
              "4              0        0  \n",
              "...          ...      ...  \n",
              "10600          0        0  \n",
              "10601          0        0  \n",
              "10602          0        0  \n",
              "10603          0        0  \n",
              "10604          1        1  \n",
              "\n",
              "[10605 rows x 20756 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_bows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YObhIA1JJaZe"
      },
      "outputs": [],
      "source": [
        "movies['predicted_sentiment'] = nb.predict_proba(df_bows)[:,1] * 8 -4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SHIlsHlJx7G",
        "outputId": "a639c33f-1946-4bdc-eb3a-3cc9829da4fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-2.51151475,  2.51151475],\n",
              "       [-3.9999042 ,  3.9999042 ],\n",
              "       [ 3.655976  , -3.655976  ],\n",
              "       ...,\n",
              "       [ 1.48144924, -1.48144924],\n",
              "       [-3.98898791,  3.98898791],\n",
              "       [ 3.99795422, -3.99795422]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nb.predict_proba(df_bows) * 8 -4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "S9tj0wqdKMtc",
        "outputId": "ce6b379a-9c0c-4e26-b58e-9282d8db8ed9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b457db08-f3c5-4a9f-a16c-0981ebba7356\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>predicted_sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.266667</td>\n",
              "      <td>The Rock is destined to be the 21st Century's ...</td>\n",
              "      <td>2.511515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.533333</td>\n",
              "      <td>The gorgeously elaborate continuation of ''The...</td>\n",
              "      <td>3.999904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.600000</td>\n",
              "      <td>Effective but too tepid biopic</td>\n",
              "      <td>-3.655976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.466667</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>1.940954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.733333</td>\n",
              "      <td>Emerges as something rare, an issue movie that...</td>\n",
              "      <td>3.910373</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b457db08-f3c5-4a9f-a16c-0981ebba7356')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b457db08-f3c5-4a9f-a16c-0981ebba7356 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b457db08-f3c5-4a9f-a16c-0981ebba7356');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    sentiment                                               text  \\\n",
              "id                                                                 \n",
              "1    2.266667  The Rock is destined to be the 21st Century's ...   \n",
              "2    3.533333  The gorgeously elaborate continuation of ''The...   \n",
              "3   -0.600000                     Effective but too tepid biopic   \n",
              "4    1.466667  If you sometimes like to go to the movies to h...   \n",
              "5    1.733333  Emerges as something rare, an issue movie that...   \n",
              "\n",
              "    predicted_sentiment  \n",
              "id                       \n",
              "1              2.511515  \n",
              "2              3.999904  \n",
              "3             -3.655976  \n",
              "4              1.940954  \n",
              "5              3.910373  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlUXES3TJPKU"
      },
      "outputs": [],
      "source": [
        "movies['error'] = (movies.predicted_sentiment - movies.sentiment).abs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifk6mtz1IgSa",
        "outputId": "fb71f01c-4026-41fa-b944-3f4a05f2464d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.869883754974617"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies.error.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "ehNfwGCsKY3f",
        "outputId": "334353dc-476b-4ba6-9433-0f985a1de8ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-80f65ded-15c9-41d1-a55c-6d977b17c2d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>predicted_sentiment</th>\n",
              "      <th>sentiment_ispositive</th>\n",
              "      <th>predicted_ispositive</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.266667</td>\n",
              "      <td>2.511515</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.533333</td>\n",
              "      <td>3.999904</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-3.655976</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.466667</td>\n",
              "      <td>1.940954</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.733333</td>\n",
              "      <td>3.910373</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.533333</td>\n",
              "      <td>3.995188</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.466667</td>\n",
              "      <td>3.960466</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.266667</td>\n",
              "      <td>-1.918701</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80f65ded-15c9-41d1-a55c-6d977b17c2d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80f65ded-15c9-41d1-a55c-6d977b17c2d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80f65ded-15c9-41d1-a55c-6d977b17c2d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    sentiment  predicted_sentiment  sentiment_ispositive  \\\n",
              "id                                                         \n",
              "1    2.266667             2.511515                     1   \n",
              "2    3.533333             3.999904                     1   \n",
              "3   -0.600000            -3.655976                     0   \n",
              "4    1.466667             1.940954                     1   \n",
              "5    1.733333             3.910373                     1   \n",
              "6    2.533333             3.995188                     1   \n",
              "7    2.466667             3.960466                     1   \n",
              "8    1.266667            -1.918701                     1   \n",
              "\n",
              "    predicted_ispositive  \n",
              "id                        \n",
              "1                      1  \n",
              "2                      1  \n",
              "3                      0  \n",
              "4                      1  \n",
              "5                      1  \n",
              "6                      1  \n",
              "7                      1  \n",
              "8                      0  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies['sentiment_ispositive'] = (movies.sentiment>0).astype(int) \n",
        "movies['predicted_ispositive'] = (movies.predicted_sentiment >0).astype(int)\n",
        "movies['''sentiment predicted_sentiment sentiment_ispositive predicted_ispositive'''.split()].head(8) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PITJZksK9G5",
        "outputId": "2153e976-432c-47bb-984f-5787cecbcd7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9344648750589345"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(movies.predicted_ispositive == movies.sentiment_ispositive).sum() / len(movies)\n",
        "# 긍정적 추천평가는 93%경우에 정확"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdyT2L0EMGRu"
      },
      "outputs": [],
      "source": [
        "products = get_data(\"hutto_products\")\n",
        "bags_of_words = []\n",
        "for text in products.text:\n",
        "  bags_of_words.append(Counter(casual_tokenize(text)))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPy3WrLVMcHP"
      },
      "outputs": [],
      "source": [
        "df_product_bows = pd.DataFrame.from_records(bags_of_words) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnxmbST4Mh-x"
      },
      "outputs": [],
      "source": [
        "df_product_bows = df_product_bows.fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6TN6w03YMpZA",
        "outputId": "a2a5f5da-d147-455a-8797-c2eb8f5af3e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb5f8f88-7824-45d4-bcf9-dc50e9a68c24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>troubleshooting</th>\n",
              "      <th>ad</th>\n",
              "      <th>-</th>\n",
              "      <th>2500</th>\n",
              "      <th>and</th>\n",
              "      <th>2600</th>\n",
              "      <th>no</th>\n",
              "      <th>picture</th>\n",
              "      <th>scrolling</th>\n",
              "      <th>b</th>\n",
              "      <th>...</th>\n",
              "      <th>undone</th>\n",
              "      <th>warrranty</th>\n",
              "      <th>expire</th>\n",
              "      <th>expired</th>\n",
              "      <th>voids</th>\n",
              "      <th>develops</th>\n",
              "      <th>soldier</th>\n",
              "      <th>serving</th>\n",
              "      <th>baghdad</th>\n",
              "      <th>harddisk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3543</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3544</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3545</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3546 rows × 5687 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb5f8f88-7824-45d4-bcf9-dc50e9a68c24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb5f8f88-7824-45d4-bcf9-dc50e9a68c24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb5f8f88-7824-45d4-bcf9-dc50e9a68c24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      troubleshooting  ad  -  2500  and  2600  no  picture  scrolling  b  \\\n",
              "0                   1   2  2     1    1     1   1        1          1  1   \n",
              "1                   0   0  0     0    0     0   0        0          0  0   \n",
              "2                   0   0  0     0    0     0   0        0          0  0   \n",
              "3                   0   0  0     0    2     0   0        0          1  0   \n",
              "4                   1   0  0     0    0     0   0        0          0  0   \n",
              "...               ...  .. ..   ...  ...   ...  ..      ...        ... ..   \n",
              "3541                0   0  0     0    1     0   0        0          0  0   \n",
              "3542                0   0  0     0    0     0   0        0          0  0   \n",
              "3543                0   0  0     0    2     0   0        0          0  0   \n",
              "3544                0   0  0     0    0     0   0        0          0  0   \n",
              "3545                0   0  0     0    2     0   0        0          0  0   \n",
              "\n",
              "      ...  undone  warrranty  expire  expired  voids  develops  soldier  \\\n",
              "0     ...       0          0       0        0      0         0        0   \n",
              "1     ...       0          0       0        0      0         0        0   \n",
              "2     ...       0          0       0        0      0         0        0   \n",
              "3     ...       0          0       0        0      0         0        0   \n",
              "4     ...       0          0       0        0      0         0        0   \n",
              "...   ...     ...        ...     ...      ...    ...       ...      ...   \n",
              "3541  ...       0          0       0        0      0         0        0   \n",
              "3542  ...       0          0       0        0      0         0        0   \n",
              "3543  ...       0          0       0        0      0         0        0   \n",
              "3544  ...       0          0       0        0      0         0        0   \n",
              "3545  ...       0          0       0        0      0         0        0   \n",
              "\n",
              "      serving  baghdad  harddisk  \n",
              "0           0        0         0  \n",
              "1           0        0         0  \n",
              "2           0        0         0  \n",
              "3           0        0         0  \n",
              "4           0        0         0  \n",
              "...       ...      ...       ...  \n",
              "3541        0        0         0  \n",
              "3542        0        0         1  \n",
              "3543        0        0         0  \n",
              "3544        0        0         0  \n",
              "3545        0        0         0  \n",
              "\n",
              "[3546 rows x 5687 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_product_bows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "upjm5RBEMGgF",
        "outputId": "cfc4bb71-a017-467d-80d9-2721195c250b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7dfe95b5-3da6-408f-baa9-8c2c66cfd5c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>Rock</th>\n",
              "      <th>is</th>\n",
              "      <th>destined</th>\n",
              "      <th>to</th>\n",
              "      <th>be</th>\n",
              "      <th>the</th>\n",
              "      <th>21st</th>\n",
              "      <th>Century's</th>\n",
              "      <th>new</th>\n",
              "      <th>...</th>\n",
              "      <th>sligtly</th>\n",
              "      <th>owner</th>\n",
              "      <th>81</th>\n",
              "      <th>defectively</th>\n",
              "      <th>warrranty</th>\n",
              "      <th>expire</th>\n",
              "      <th>expired</th>\n",
              "      <th>voids</th>\n",
              "      <th>baghdad</th>\n",
              "      <th>harddisk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3543</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3544</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3545</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14151 rows × 23302 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dfe95b5-3da6-408f-baa9-8c2c66cfd5c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7dfe95b5-3da6-408f-baa9-8c2c66cfd5c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7dfe95b5-3da6-408f-baa9-8c2c66cfd5c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      The  Rock  is  destined  to  be  the  21st  Century's  new  ...  \\\n",
              "0     1.0   1.0   1       1.0   2   1    1     1        1.0    1  ...   \n",
              "1     2.0   0.0   1       0.0   0   0    1     0        0.0    0  ...   \n",
              "2     0.0   0.0   0       0.0   0   0    0     0        0.0    0  ...   \n",
              "3     0.0   0.0   1       0.0   4   0    1     0        0.0    0  ...   \n",
              "4     0.0   0.0   0       0.0   0   0    0     0        0.0    0  ...   \n",
              "...   ...   ...  ..       ...  ..  ..  ...   ...        ...  ...  ...   \n",
              "3541  NaN   NaN   0       NaN   1   0    1     0        NaN    0  ...   \n",
              "3542  NaN   NaN   0       NaN   0   0    0     0        NaN    0  ...   \n",
              "3543  NaN   NaN   0       NaN   0   0    2     0        NaN    0  ...   \n",
              "3544  NaN   NaN   0       NaN   0   0    0     0        NaN    0  ...   \n",
              "3545  NaN   NaN   0       NaN   0   0    0     0        NaN    0  ...   \n",
              "\n",
              "      sligtly  owner   81  defectively  warrranty  expire  expired  \\\n",
              "0         NaN    NaN  NaN          NaN        NaN     NaN      NaN   \n",
              "1         NaN    NaN  NaN          NaN        NaN     NaN      NaN   \n",
              "2         NaN    NaN  NaN          NaN        NaN     NaN      NaN   \n",
              "3         NaN    NaN  NaN          NaN        NaN     NaN      NaN   \n",
              "4         NaN    NaN  NaN          NaN        NaN     NaN      NaN   \n",
              "...       ...    ...  ...          ...        ...     ...      ...   \n",
              "3541      0.0    0.0  0.0          0.0        0.0     0.0      0.0   \n",
              "3542      0.0    0.0  0.0          0.0        0.0     0.0      0.0   \n",
              "3543      0.0    0.0  0.0          0.0        0.0     0.0      0.0   \n",
              "3544      0.0    0.0  0.0          0.0        0.0     0.0      0.0   \n",
              "3545      0.0    0.0  0.0          0.0        0.0     0.0      0.0   \n",
              "\n",
              "      voids  baghdad  harddisk  \n",
              "0       NaN      NaN       NaN  \n",
              "1       NaN      NaN       NaN  \n",
              "2       NaN      NaN       NaN  \n",
              "3       NaN      NaN       NaN  \n",
              "4       NaN      NaN       NaN  \n",
              "...     ...      ...       ...  \n",
              "3541    0.0      0.0       0.0  \n",
              "3542    0.0      0.0       1.0  \n",
              "3543    0.0      0.0       0.0  \n",
              "3544    0.0      0.0       0.0  \n",
              "3545    0.0      0.0       0.0  \n",
              "\n",
              "[14151 rows x 23302 columns]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_bows = df_bows.append(df_product_bows); df_all_bows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn_49OHzMskp",
        "outputId": "99764fdb-0cd7-4d0a-d15b-87d676ca6065"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st',\n",
              "       'Century's', 'new',\n",
              "       ...\n",
              "       'sligtly', 'owner', '81', 'defectively', 'warrranty', 'expire',\n",
              "       'expired', 'voids', 'baghdad', 'harddisk'],\n",
              "      dtype='object', length=23302)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_all_bows.columns # 영화평 말뭉치를 상품평에 적용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRLJOGTQPn6W"
      },
      "outputs": [],
      "source": [
        "df_all_bows= df_all_bows.fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoMIGNKTMst-"
      },
      "outputs": [],
      "source": [
        "df_products_bows = df_all_bows.iloc[len(movies):][df_bows.columns] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cRJkKmRBNChO",
        "outputId": "81b164b1-61da-4b9d-e292-359d872ecbdd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e5ef9585-0d0d-4876-bef1-46a453550d9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>The</th>\n",
              "      <th>Rock</th>\n",
              "      <th>is</th>\n",
              "      <th>destined</th>\n",
              "      <th>to</th>\n",
              "      <th>be</th>\n",
              "      <th>the</th>\n",
              "      <th>21st</th>\n",
              "      <th>Century's</th>\n",
              "      <th>new</th>\n",
              "      <th>...</th>\n",
              "      <th>Ill</th>\n",
              "      <th>slummer</th>\n",
              "      <th>Rashomon</th>\n",
              "      <th>dipsticks</th>\n",
              "      <th>Bearable</th>\n",
              "      <th>Staggeringly</th>\n",
              "      <th>’</th>\n",
              "      <th>ve</th>\n",
              "      <th>muttering</th>\n",
              "      <th>dissing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3543</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3544</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3545</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3546 rows × 20756 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5ef9585-0d0d-4876-bef1-46a453550d9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5ef9585-0d0d-4876-bef1-46a453550d9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5ef9585-0d0d-4876-bef1-46a453550d9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      The  Rock  is  destined  to  be  the  21st  Century's  new  ...  \\\n",
              "0       0     0   0         0   0   0    0     0          0    0  ...   \n",
              "1       0     0   0         0   0   0    0     0          0    0  ...   \n",
              "2       0     0   0         0   0   0    0     0          0    0  ...   \n",
              "3       0     0   0         0   0   0    0     0          0    0  ...   \n",
              "4       0     0   0         0   1   0    2     0          0    0  ...   \n",
              "...   ...   ...  ..       ...  ..  ..  ...   ...        ...  ...  ...   \n",
              "3541    0     0   0         0   1   0    1     0          0    0  ...   \n",
              "3542    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "3543    0     0   0         0   0   0    2     0          0    0  ...   \n",
              "3544    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "3545    0     0   0         0   0   0    0     0          0    0  ...   \n",
              "\n",
              "      Ill  slummer  Rashomon  dipsticks  Bearable  Staggeringly  ’  ve  \\\n",
              "0       0        0         0          0         0             0  0   0   \n",
              "1       0        0         0          0         0             0  0   0   \n",
              "2       0        0         0          0         0             0  0   0   \n",
              "3       0        0         0          0         0             0  0   0   \n",
              "4       0        0         0          0         0             0  0   0   \n",
              "...   ...      ...       ...        ...       ...           ... ..  ..   \n",
              "3541    0        0         0          0         0             0  0   0   \n",
              "3542    0        0         0          0         0             0  0   0   \n",
              "3543    0        0         0          0         0             0  0   0   \n",
              "3544    0        0         0          0         0             0  0   0   \n",
              "3545    0        0         0          0         0             0  0   0   \n",
              "\n",
              "      muttering  dissing  \n",
              "0             0        0  \n",
              "1             0        0  \n",
              "2             0        0  \n",
              "3             0        0  \n",
              "4             0        0  \n",
              "...         ...      ...  \n",
              "3541          0        0  \n",
              "3542          0        0  \n",
              "3543          0        0  \n",
              "3544          0        0  \n",
              "3545          0        0  \n",
              "\n",
              "[3546 rows x 20756 columns]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_products_bows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY5EIs5rNDmc",
        "outputId": "1900178b-c08f-4be9-faa4-08b97aed468c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3546, 20756)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_products_bows.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "U8vNWMxBNGAT",
        "outputId": "b7297f0b-a2f5-468c-9f44-0c82259ac125"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f4325eb3-4ac7-46b6-bee2-88d14d8e39f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>ispos</th>\n",
              "      <th>predicted_ispositive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_1</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>troubleshooting ad-2500 and ad-2600 no picture...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_2</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>repost from january 13, 2004 with a better fit...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_3</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>does your apex dvd player only play dvd audio ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_4</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>or does it play audio and video but scrolling ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_5</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>before you try to return the player or waste h...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4325eb3-4ac7-46b6-bee2-88d14d8e39f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4325eb3-4ac7-46b6-bee2-88d14d8e39f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4325eb3-4ac7-46b6-bee2-88d14d8e39f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    id  sentiment                                               text  \\\n",
              "0  1_1      -0.90  troubleshooting ad-2500 and ad-2600 no picture...   \n",
              "1  1_2      -0.15  repost from january 13, 2004 with a better fit...   \n",
              "2  1_3      -0.20  does your apex dvd player only play dvd audio ...   \n",
              "3  1_4      -0.10  or does it play audio and video but scrolling ...   \n",
              "4  1_5      -0.50  before you try to return the player or waste h...   \n",
              "\n",
              "   ispos  predicted_ispositive  \n",
              "0      0                     0  \n",
              "1      0                     0  \n",
              "2      0                     0  \n",
              "3      0                     0  \n",
              "4      0                     0  "
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "products['ispos'] = (products.sentiment > 0).astype(int) \n",
        "products['predicted_ispositive'] = nb.predict(df_products_bows.values).astype(int) \n",
        "products.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys5jo1HINZ9U",
        "outputId": "0ed246f4-5471-46ea-cfca-16148de2aa42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 2, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_product_bows.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UQzuUD5RP4_0",
        "outputId": "953ed4b5-3b84-411f-9a40-9f052fdfcfa0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c57ed83-886b-4ae3-8ddb-3e4338e34597\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>ispos</th>\n",
              "      <th>predicted_ispositive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_1</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>troubleshooting ad-2500 and ad-2600 no picture...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_2</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>repost from january 13, 2004 with a better fit...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1_3</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>does your apex dvd player only play dvd audio ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1_4</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>or does it play audio and video but scrolling ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1_5</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>before you try to return the player or waste h...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3541</th>\n",
              "      <td>309_4</td>\n",
              "      <td>-1.80</td>\n",
              "      <td>the other day when i was listening to a song, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>309_5</td>\n",
              "      <td>-1.30</td>\n",
              "      <td>it says i have a harddisk problem.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3543</th>\n",
              "      <td>309_6</td>\n",
              "      <td>-1.95</td>\n",
              "      <td>and since i'm out here i can't mail it back un...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3544</th>\n",
              "      <td>309_7</td>\n",
              "      <td>0.45</td>\n",
              "      <td>it worked good for a while.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3545</th>\n",
              "      <td>309_8</td>\n",
              "      <td>-2.75</td>\n",
              "      <td>it did lock up on me a couple of times, and th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3546 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c57ed83-886b-4ae3-8ddb-3e4338e34597')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c57ed83-886b-4ae3-8ddb-3e4338e34597 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c57ed83-886b-4ae3-8ddb-3e4338e34597');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id  sentiment  \\\n",
              "0       1_1      -0.90   \n",
              "1       1_2      -0.15   \n",
              "2       1_3      -0.20   \n",
              "3       1_4      -0.10   \n",
              "4       1_5      -0.50   \n",
              "...     ...        ...   \n",
              "3541  309_4      -1.80   \n",
              "3542  309_5      -1.30   \n",
              "3543  309_6      -1.95   \n",
              "3544  309_7       0.45   \n",
              "3545  309_8      -2.75   \n",
              "\n",
              "                                                   text  ispos  \\\n",
              "0     troubleshooting ad-2500 and ad-2600 no picture...      0   \n",
              "1     repost from january 13, 2004 with a better fit...      0   \n",
              "2     does your apex dvd player only play dvd audio ...      0   \n",
              "3     or does it play audio and video but scrolling ...      0   \n",
              "4     before you try to return the player or waste h...      0   \n",
              "...                                                 ...    ...   \n",
              "3541  the other day when i was listening to a song, ...      0   \n",
              "3542                 it says i have a harddisk problem.      0   \n",
              "3543  and since i'm out here i can't mail it back un...      0   \n",
              "3544                        it worked good for a while.      1   \n",
              "3545  it did lock up on me a couple of times, and th...      0   \n",
              "\n",
              "      predicted_ispositive  \n",
              "0                        0  \n",
              "1                        0  \n",
              "2                        0  \n",
              "3                        0  \n",
              "4                        0  \n",
              "...                    ...  \n",
              "3541                     0  \n",
              "3542                     0  \n",
              "3543                     0  \n",
              "3544                     0  \n",
              "3545                     0  \n",
              "\n",
              "[3546 rows x 5 columns]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osBq58EMNxDP",
        "outputId": "2db265f7-eefa-4331-fa3f-bd2de8b931f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5572476029328821"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(products.predicted_ispositive == products.ispos).sum() / len(products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJMPnP1qO7e0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ2mGbXGQBah"
      },
      "source": [
        "# ch03. 말잘하는 수학 : TF-IDF 벡터 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EquCseEqQM_M"
      },
      "outputs": [],
      "source": [
        "# 1. 단어모음 : 단어빈도들의 벡터\n",
        "# 2. n-그램 모음 \n",
        "# 3. TF-IDF 벡터 : 단어의 중요도를 좀더 잘 표현하는 단어 점수 벡터\n",
        "# -> 통계에 기초한다는 점에서 모두 통계적 모형에 해당"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J3IdB2SOghn",
        "outputId": "a68e0fa6-9b8b-46f7-8e0c-e8d70914ef92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzV53A9CNvvX"
      },
      "outputs": [],
      "source": [
        "# 단어 모음\n",
        "from nltk.tokenize import TreebankWordTokenizer \n",
        "sentence = \"\"\" the faster harry got to the store, the faster harry, the faster, would get home.\"\"\"\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(sentence.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aimApMsMOe4H",
        "outputId": "ed498765-afdf-4442-b54a-a6aab1b3e46f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the',\n",
              " 'faster',\n",
              " 'harry',\n",
              " 'got',\n",
              " 'to',\n",
              " 'the',\n",
              " 'store',\n",
              " ',',\n",
              " 'the',\n",
              " 'faster',\n",
              " 'harry',\n",
              " ',',\n",
              " 'the',\n",
              " 'faster',\n",
              " ',',\n",
              " 'would',\n",
              " 'get',\n",
              " 'home',\n",
              " '.']"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0WjjxegOq5t",
        "outputId": "87339981-e926-4a06-8edf-9c57d7af4bcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({',': 3,\n",
              "         '.': 1,\n",
              "         'faster': 3,\n",
              "         'get': 1,\n",
              "         'got': 1,\n",
              "         'harry': 2,\n",
              "         'home': 1,\n",
              "         'store': 1,\n",
              "         'the': 4,\n",
              "         'to': 1,\n",
              "         'would': 1})"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "bag_of_words = Counter(tokens) \n",
        "bag_of_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5aCYYhCO4IK",
        "outputId": "acadf9da-8857-42f6-8f0f-eeeeb557e0b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 4), ('faster', 3), (',', 3), ('harry', 2)]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bag_of_words.most_common(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42oTJvrIUwuv",
        "outputId": "0c5d2ab3-fcfe-4ca0-a9fe-955bc6447339"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "times_harry_appears = bag_of_words['harry']\n",
        "num_unique_words = len(bag_of_words) \n",
        "num_unique_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFD2V-3WU9p3",
        "outputId": "afe39d44-8752-4c82-ac5a-c7b8620490d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.18181818181818182"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = times_harry_appears / num_unique_words;tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8dVaMrHVCH8",
        "outputId": "28f30d92-3873-4437-d0a3-27889ef6d88e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n"
          ]
        }
      ],
      "source": [
        "from nlpia.data.loaders import kite_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eCb_xGMVWhE",
        "outputId": "bd486cb8-a288-4d9e-d956-f295eb16c97a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({\"'s\": 2,\n",
              "         '(': 1,\n",
              "         ')': 1,\n",
              "         ',': 15,\n",
              "         '.': 2,\n",
              "         ';': 2,\n",
              "         'a': 20,\n",
              "         'above': 1,\n",
              "         'activities': 1,\n",
              "         'aerial': 1,\n",
              "         'against': 1,\n",
              "         'air': 2,\n",
              "         'along': 1,\n",
              "         'also': 3,\n",
              "         'anchor': 1,\n",
              "         'anchors': 1,\n",
              "         'anchors.': 2,\n",
              "         'and': 10,\n",
              "         'angle': 1,\n",
              "         'apply': 1,\n",
              "         'are': 3,\n",
              "         'around': 1,\n",
              "         'art': 1,\n",
              "         'as': 5,\n",
              "         'at': 3,\n",
              "         'attached.': 1,\n",
              "         'ballet': 1,\n",
              "         'balloon': 1,\n",
              "         'be': 5,\n",
              "         'been': 1,\n",
              "         'below': 1,\n",
              "         'boat': 1,\n",
              "         'both': 1,\n",
              "         'bridle': 2,\n",
              "         'buggying': 1,\n",
              "         'by': 2,\n",
              "         'called': 2,\n",
              "         'can': 3,\n",
              "         'competition.': 1,\n",
              "         'components': 1,\n",
              "         'comprising': 1,\n",
              "         'consists': 2,\n",
              "         'correct': 1,\n",
              "         'craft': 2,\n",
              "         'create': 1,\n",
              "         'designed': 2,\n",
              "         'different': 1,\n",
              "         'direction': 1,\n",
              "         'drag': 2,\n",
              "         'drag.': 1,\n",
              "         'e.g.': 1,\n",
              "         'even': 2,\n",
              "         'face': 1,\n",
              "         'festivals': 1,\n",
              "         'fishing': 1,\n",
              "         'fixed': 1,\n",
              "         'flight': 1,\n",
              "         'flow': 1,\n",
              "         'flown': 3,\n",
              "         'flows': 1,\n",
              "         'fluid': 1,\n",
              "         'for': 2,\n",
              "         'force': 2,\n",
              "         'forces': 1,\n",
              "         'free-falling': 1,\n",
              "         'from': 1,\n",
              "         'fugitive': 1,\n",
              "         'generate': 1,\n",
              "         'generated': 1,\n",
              "         'generates': 1,\n",
              "         'guide': 1,\n",
              "         'have': 4,\n",
              "         'heavier-than-air': 1,\n",
              "         'high': 1,\n",
              "         'history': 1,\n",
              "         'horizontal': 1,\n",
              "         'hybrid': 1,\n",
              "         'in': 7,\n",
              "         'individually': 1,\n",
              "         'interaction': 1,\n",
              "         'is': 7,\n",
              "         'it.': 1,\n",
              "         'kite': 16,\n",
              "         'kite.': 1,\n",
              "         'kites': 8,\n",
              "         'kiting': 3,\n",
              "         'kiting.': 1,\n",
              "         'kytoon.': 1,\n",
              "         'landboarding': 1,\n",
              "         'large': 1,\n",
              "         'launch': 1,\n",
              "         'lift': 4,\n",
              "         'lifting': 1,\n",
              "         'lighter-than-air': 1,\n",
              "         'line': 1,\n",
              "         'lines': 1,\n",
              "         'liquids': 1,\n",
              "         'long': 1,\n",
              "         'low': 1,\n",
              "         'made': 1,\n",
              "         'man-lifting': 1,\n",
              "         'many': 1,\n",
              "         'may': 4,\n",
              "         'meets': 1,\n",
              "         'more': 1,\n",
              "         'moving': 2,\n",
              "         'multi-line': 1,\n",
              "         'needed': 1,\n",
              "         'new': 1,\n",
              "         'not': 1,\n",
              "         'of': 10,\n",
              "         'often': 2,\n",
              "         'one': 1,\n",
              "         'opposed': 1,\n",
              "         'or': 6,\n",
              "         'other': 1,\n",
              "         'paragliders': 1,\n",
              "         'parakites': 1,\n",
              "         'part': 1,\n",
              "         'person': 1,\n",
              "         'point': 1,\n",
              "         'point.': 1,\n",
              "         'power': 2,\n",
              "         'practical': 1,\n",
              "         'pressure': 2,\n",
              "         'principles': 1,\n",
              "         'producing': 1,\n",
              "         'react': 1,\n",
              "         'recreation': 1,\n",
              "         'resultant': 1,\n",
              "         'running': 1,\n",
              "         'sailplane': 1,\n",
              "         'same': 1,\n",
              "         'sets': 1,\n",
              "         'single': 1,\n",
              "         'snow': 1,\n",
              "         'so': 3,\n",
              "         'sometimes': 1,\n",
              "         'sport': 1,\n",
              "         'static': 1,\n",
              "         'steerable': 1,\n",
              "         'still': 1,\n",
              "         'such': 1,\n",
              "         'surface': 2,\n",
              "         'surfaces': 1,\n",
              "         'surfing': 1,\n",
              "         'sustains': 1,\n",
              "         'system': 1,\n",
              "         'technical': 2,\n",
              "         'tension': 1,\n",
              "         'tether': 1,\n",
              "         'tether-set-coupled': 1,\n",
              "         'tethered': 2,\n",
              "         'tethers': 2,\n",
              "         'that': 2,\n",
              "         'the': 26,\n",
              "         'though': 1,\n",
              "         'to': 5,\n",
              "         'towing': 1,\n",
              "         'traditionally': 1,\n",
              "         'trend': 1,\n",
              "         'types': 1,\n",
              "         'under': 1,\n",
              "         'untraditionally': 1,\n",
              "         'used': 2,\n",
              "         'uses.': 1,\n",
              "         'varied': 1,\n",
              "         'vector': 1,\n",
              "         'vehicle': 1,\n",
              "         'water.': 1,\n",
              "         'well': 1,\n",
              "         'when': 2,\n",
              "         'which': 2,\n",
              "         'wind': 2,\n",
              "         'wind.': 1,\n",
              "         'wing': 5,\n",
              "         'wings': 1,\n",
              "         'wings.': 1,\n",
              "         'with': 2,\n",
              "         'worldwide.': 1})"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = TreebankWordTokenizer()\n",
        "tokens = tokenizer.tokenize(kite_text.lower())\n",
        "token_counts = Counter(tokens) \n",
        "token_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFhqsa0saaxE",
        "outputId": "8ab34f33-42af-4b19-edcd-1a2131fe53a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 불용어 제거\n",
        "import nltk \n",
        "nltk.download('stopwords', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3pnUTyhar-k",
        "outputId": "dab70562-0490-446a-a613-a3a65a6d9b79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({\"'s\": 2,\n",
              "         '(': 1,\n",
              "         ')': 1,\n",
              "         ',': 15,\n",
              "         '.': 2,\n",
              "         ';': 2,\n",
              "         'activities': 1,\n",
              "         'aerial': 1,\n",
              "         'air': 2,\n",
              "         'along': 1,\n",
              "         'also': 3,\n",
              "         'anchor': 1,\n",
              "         'anchors': 1,\n",
              "         'anchors.': 2,\n",
              "         'angle': 1,\n",
              "         'apply': 1,\n",
              "         'around': 1,\n",
              "         'art': 1,\n",
              "         'attached.': 1,\n",
              "         'ballet': 1,\n",
              "         'balloon': 1,\n",
              "         'boat': 1,\n",
              "         'bridle': 2,\n",
              "         'buggying': 1,\n",
              "         'called': 2,\n",
              "         'competition.': 1,\n",
              "         'components': 1,\n",
              "         'comprising': 1,\n",
              "         'consists': 2,\n",
              "         'correct': 1,\n",
              "         'craft': 2,\n",
              "         'create': 1,\n",
              "         'designed': 2,\n",
              "         'different': 1,\n",
              "         'direction': 1,\n",
              "         'drag': 2,\n",
              "         'drag.': 1,\n",
              "         'e.g.': 1,\n",
              "         'even': 2,\n",
              "         'face': 1,\n",
              "         'festivals': 1,\n",
              "         'fishing': 1,\n",
              "         'fixed': 1,\n",
              "         'flight': 1,\n",
              "         'flow': 1,\n",
              "         'flown': 3,\n",
              "         'flows': 1,\n",
              "         'fluid': 1,\n",
              "         'force': 2,\n",
              "         'forces': 1,\n",
              "         'free-falling': 1,\n",
              "         'fugitive': 1,\n",
              "         'generate': 1,\n",
              "         'generated': 1,\n",
              "         'generates': 1,\n",
              "         'guide': 1,\n",
              "         'heavier-than-air': 1,\n",
              "         'high': 1,\n",
              "         'history': 1,\n",
              "         'horizontal': 1,\n",
              "         'hybrid': 1,\n",
              "         'individually': 1,\n",
              "         'interaction': 1,\n",
              "         'it.': 1,\n",
              "         'kite': 16,\n",
              "         'kite.': 1,\n",
              "         'kites': 8,\n",
              "         'kiting': 3,\n",
              "         'kiting.': 1,\n",
              "         'kytoon.': 1,\n",
              "         'landboarding': 1,\n",
              "         'large': 1,\n",
              "         'launch': 1,\n",
              "         'lift': 4,\n",
              "         'lifting': 1,\n",
              "         'lighter-than-air': 1,\n",
              "         'line': 1,\n",
              "         'lines': 1,\n",
              "         'liquids': 1,\n",
              "         'long': 1,\n",
              "         'low': 1,\n",
              "         'made': 1,\n",
              "         'man-lifting': 1,\n",
              "         'many': 1,\n",
              "         'may': 4,\n",
              "         'meets': 1,\n",
              "         'moving': 2,\n",
              "         'multi-line': 1,\n",
              "         'needed': 1,\n",
              "         'new': 1,\n",
              "         'often': 2,\n",
              "         'one': 1,\n",
              "         'opposed': 1,\n",
              "         'paragliders': 1,\n",
              "         'parakites': 1,\n",
              "         'part': 1,\n",
              "         'person': 1,\n",
              "         'point': 1,\n",
              "         'point.': 1,\n",
              "         'power': 2,\n",
              "         'practical': 1,\n",
              "         'pressure': 2,\n",
              "         'principles': 1,\n",
              "         'producing': 1,\n",
              "         'react': 1,\n",
              "         'recreation': 1,\n",
              "         'resultant': 1,\n",
              "         'running': 1,\n",
              "         'sailplane': 1,\n",
              "         'sets': 1,\n",
              "         'single': 1,\n",
              "         'snow': 1,\n",
              "         'sometimes': 1,\n",
              "         'sport': 1,\n",
              "         'static': 1,\n",
              "         'steerable': 1,\n",
              "         'still': 1,\n",
              "         'surface': 2,\n",
              "         'surfaces': 1,\n",
              "         'surfing': 1,\n",
              "         'sustains': 1,\n",
              "         'system': 1,\n",
              "         'technical': 2,\n",
              "         'tension': 1,\n",
              "         'tether': 1,\n",
              "         'tether-set-coupled': 1,\n",
              "         'tethered': 2,\n",
              "         'tethers': 2,\n",
              "         'though': 1,\n",
              "         'towing': 1,\n",
              "         'traditionally': 1,\n",
              "         'trend': 1,\n",
              "         'types': 1,\n",
              "         'untraditionally': 1,\n",
              "         'used': 2,\n",
              "         'uses.': 1,\n",
              "         'varied': 1,\n",
              "         'vector': 1,\n",
              "         'vehicle': 1,\n",
              "         'water.': 1,\n",
              "         'well': 1,\n",
              "         'wind': 2,\n",
              "         'wind.': 1,\n",
              "         'wing': 5,\n",
              "         'wings': 1,\n",
              "         'wings.': 1,\n",
              "         'worldwide.': 1})"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english') \n",
        "tokens = [ x for x in tokens if x not in stopwords]\n",
        "kite_tokens = Counter(tokens) \n",
        "kite_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKNdwbr0a5Ut"
      },
      "outputs": [],
      "source": [
        "# 단어 빈도를 벡터로 만들기\n",
        "document_vector  = []\n",
        "doc_length = len(tokens) \n",
        "for key, value in kite_tokens.most_common():\n",
        "  document_vector.append(value/ doc_length) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7BYLNN_cZCI",
        "outputId": "8a3b03c9-e5f1-4b0a-b4ec-ae554bff3b2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.07207207207207207,\n",
              " 0.06756756756756757,\n",
              " 0.036036036036036036,\n",
              " 0.02252252252252252,\n",
              " 0.018018018018018018,\n",
              " 0.018018018018018018,\n",
              " 0.013513513513513514,\n",
              " 0.013513513513513514,\n",
              " 0.013513513513513514,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.009009009009009009,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045,\n",
              " 0.0045045045045045045]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SbnnxwDcjaN",
        "outputId": "ee30843f-2f81-4598-e4ae-35d5a9d9d153"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the faster harry got to the store, the faster harry, the faster, would get home.',\n",
              " 'harry is hairy and faster than jill.',\n",
              " 'jill is not as hairy as harry.']"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs = [\"the faster harry got to the store, the faster harry, the faster, would get home.\"]\n",
        "docs.append(\"harry is hairy and faster than jill.\")\n",
        "docs.append(\"jill is not as hairy as harry.\")\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUP-XRH8dDxB",
        "outputId": "07573f01-8aba-43c3-f385-2cc2ec25a41b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[',',\n",
              "  ',',\n",
              "  ',',\n",
              "  '.',\n",
              "  'faster',\n",
              "  'faster',\n",
              "  'faster',\n",
              "  'get',\n",
              "  'got',\n",
              "  'harry',\n",
              "  'harry',\n",
              "  'home',\n",
              "  'store',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'the',\n",
              "  'to',\n",
              "  'would'],\n",
              " ['.', 'and', 'faster', 'hairy', 'harry', 'is', 'jill', 'than'],\n",
              " ['.', 'as', 'as', 'hairy', 'harry', 'is', 'jill', 'not']]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_tokens= []\n",
        "for doc in docs :\n",
        "  doc_tokens += [ sorted(tokenizer.tokenize(doc.lower()))] \n",
        "doc_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kybzS-hdL9N",
        "outputId": "3013c0be-4e84-4935-dd62-7ba18fa05608"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(doc_tokens[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48wfr4jgdTQn",
        "outputId": "5beda1c7-a780-4d4d-a5e2-901cf4a820e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_doc_tokens = sum(doc_tokens,[]) ;all_doc_tokens\n",
        "len(all_doc_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whU-lWM_dsCA",
        "outputId": "61824ed1-25d7-4f7d-e73c-78f53fb3e06e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lexicon = sorted(set(all_doc_tokens)) \n",
        "len(lexicon)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui_8fOJzedE7",
        "outputId": "f6ca4318-5e72-4249-ddf5-4c21b6072866"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([(',', 0),\n",
              "             ('.', 0),\n",
              "             ('and', 0),\n",
              "             ('as', 0),\n",
              "             ('faster', 0),\n",
              "             ('get', 0),\n",
              "             ('got', 0),\n",
              "             ('hairy', 0),\n",
              "             ('harry', 0),\n",
              "             ('home', 0),\n",
              "             ('is', 0),\n",
              "             ('jill', 0),\n",
              "             ('not', 0),\n",
              "             ('store', 0),\n",
              "             ('than', 0),\n",
              "             ('the', 0),\n",
              "             ('to', 0),\n",
              "             ('would', 0)])"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import OrderedDict \n",
        "zero_vector = OrderedDict((token,0) for token in lexicon) \n",
        "zero_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_1K95jYedQV",
        "outputId": "829373ed-7f87-4469-e4b2-510be8a81408"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(lexicon) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7188kVMf4jq",
        "outputId": "ffac5e5a-63b4-423f-8552-38729d5b0e71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the faster harry got to the store, the faster harry, the faster, would get home.',\n",
              " 'harry is hairy and faster than jill.',\n",
              " 'jill is not as hairy as harry.']"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J2Vc9KneotO"
      },
      "outputs": [],
      "source": [
        "import copy \n",
        "doc_vectors = []\n",
        "for doc in docs : \n",
        "  vec = copy.copy(zero_vector) # 주어진 벡터를 복사해서 그 벡터와는 독립적인 벡터를 생성 참조를 해서 재사용하는 것이 아니라 새로운 벡터를 생성\n",
        "  tokens = tokenizer.tokenize(doc.lower()) \n",
        "  token_counts = Counter(tokens) \n",
        "  for key, value in token_counts.items():\n",
        "    vec[key] = value / len(lexicon)  # len(lexicon) = 18\n",
        "  doc_vectors.append(vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3soxkyNeKbl",
        "outputId": "49cf49fb-b6f7-4b9e-dbdc-0b9cb6dc5b64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[OrderedDict([(',', 0.16666666666666666),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.16666666666666666),\n",
              "              ('get', 0.05555555555555555),\n",
              "              ('got', 0.05555555555555555),\n",
              "              ('hairy', 0),\n",
              "              ('harry', 0.1111111111111111),\n",
              "              ('home', 0.05555555555555555),\n",
              "              ('is', 0),\n",
              "              ('jill', 0),\n",
              "              ('not', 0),\n",
              "              ('store', 0.05555555555555555),\n",
              "              ('than', 0),\n",
              "              ('the', 0.2222222222222222),\n",
              "              ('to', 0.05555555555555555),\n",
              "              ('would', 0.05555555555555555)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0.05555555555555555),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.05555555555555555),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.05555555555555555),\n",
              "              ('harry', 0.05555555555555555),\n",
              "              ('home', 0),\n",
              "              ('is', 0.05555555555555555),\n",
              "              ('jill', 0.05555555555555555),\n",
              "              ('not', 0),\n",
              "              ('store', 0),\n",
              "              ('than', 0.05555555555555555),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0),\n",
              "              ('as', 0.1111111111111111),\n",
              "              ('faster', 0),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.05555555555555555),\n",
              "              ('harry', 0.05555555555555555),\n",
              "              ('home', 0),\n",
              "              ('is', 0.05555555555555555),\n",
              "              ('jill', 0.05555555555555555),\n",
              "              ('not', 0.05555555555555555),\n",
              "              ('store', 0),\n",
              "              ('than', 0),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)])]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x27LykHJeLC0"
      },
      "outputs": [],
      "source": [
        "# 벡터공간 : 그 공간안에 나타날 수 있는 모든 가능한 벡터의 집합, 벡터의 성분개수는 해당 벡터 공간의 차원수 \n",
        "# 코사인 유사도,  두벡터의 거리 대신 각도에 기초해서 두벡터의 유사도를 측정, 유클리드 내적 공식에서 유도\n",
        "# a.dot(b) ==np.linalg.nom(a) * np.linalg.norm(b) / np.cos(theta) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbSFgDx5noqC"
      },
      "outputs": [],
      "source": [
        "import math \n",
        "def cosine_sim(vec1,vec2):\n",
        "  \"\"\"두 문서 표현 벡터의 코사인 유사도를 계산하는 함수\"\"\"\n",
        "  vec1= [val for val in vec1.values()] \n",
        "  vec2= [val for val in vec2.values()] \n",
        "  dot_prod = 0\n",
        "  for i, v in enumerate(vec1):  # 곱한것들의 합\n",
        "    dot_prod += v*vec2[i] \n",
        "  \n",
        "  mag_1 = math.sqrt(sum([x**2 for x in vec1])) # norm(a)\n",
        "  mag_2 = math.sqrt(sum([x**2 for x in vec2])) # norm(b)\n",
        "  return dot_prod / (mag_1*mag_2)\n",
        "# 코사인유사도1 : 길이는 다를수있지만 방향은 정확히 일치함을 의미. 두 문서의 유사도가 1이면 비슷한 내용을 담고있을 가능성이 크다\n",
        "# tf벡터는 같은 사분면에 있다. 그러나 코사인 유사도가 음수가 되려면 두벡터 중 하나가 다른 사분면에 있어야하는데 tf벡터는 모든성분이 양수이기에 불가능\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOqvdldcoL_G"
      },
      "outputs": [],
      "source": [
        "# 지프의 법칙 \n",
        "# 어떠한 자연어 말뭉치 표현에 나타나는 단어들을 그 사용빈도가 높은 순서대로 나열했을때, 모든 단어의 사용빈도는 해당 단어의 순위에 반비례함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBj2G2lkQB5E",
        "outputId": "c2e51c92-2d0b-40cc-af5f-2f852c2192c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKyZpCz7P8nr",
        "outputId": "5fe0c23d-4ff2-48bd-eda5-3da61aac8c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUrYn8wcP_EQ"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import brown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_14dPdTQH3h",
        "outputId": "5a5f15a2-a1f6-4712-8872-c514847c32e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "brown.words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO527DNyQJbP",
        "outputId": "64528a3b-e796-4232-c7a1-26e5e15e5e71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "brown.words()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8TYqvsDQLxQ",
        "outputId": "17c26a04-e38d-4b8f-c100-3987b38ddc97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('The', 'AT'),\n",
              " ('Fulton', 'NP-TL'),\n",
              " ('County', 'NN-TL'),\n",
              " ('Grand', 'JJ-TL'),\n",
              " ('Jury', 'NN-TL')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "brown.tagged_words()[:5] # 품사 태깅을 보여줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYMjcCdPQQSN",
        "outputId": "0a43be4e-3f4a-4ac4-a4c1-96a719fd8f26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(brown.words()) # 100만을 넘는 단어 존재함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOBzIh_dQa6y"
      },
      "outputs": [],
      "source": [
        "from collections import Counter  \n",
        "puncs = set((',','.','--','-','!','?',':',';', '(', ')','[', ']','``',\"''\" ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItPI-cWkQ2iq"
      },
      "outputs": [],
      "source": [
        "word_list = (x.lower() for x in brown.words() if x not in puncs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAiDUWgVRWPi"
      },
      "outputs": [],
      "source": [
        "token_counts = Counter(word_list) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4kFj2-LRZQJ",
        "outputId": "73676273-cc85-4422-8cb9-d592a7385c6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 69971),\n",
              " ('of', 36412),\n",
              " ('and', 28853),\n",
              " ('to', 26158),\n",
              " ('a', 23195),\n",
              " ('in', 21337),\n",
              " ('that', 10594),\n",
              " ('is', 10109),\n",
              " ('was', 9815),\n",
              " ('he', 9548),\n",
              " ('for', 9489),\n",
              " ('it', 8760),\n",
              " ('with', 7289),\n",
              " ('as', 7253),\n",
              " ('his', 6996),\n",
              " ('on', 6741),\n",
              " ('be', 6377),\n",
              " ('at', 5372),\n",
              " ('by', 5306),\n",
              " ('i', 5164)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_counts.most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zMJ-WIdRbNb"
      },
      "outputs": [],
      "source": [
        "# 주제 모형화\n",
        "# idf : 역문서빈도, 지프의 법칙을 주제 분석에 적용하는 수단이라 할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zi_PM8WR7EN",
        "outputId": "ac896731-c6a1-49d9-e865-e4ae5bbcf95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nlpia\n",
            "  Downloading nlpia-0.5.2-py2.py3-none-any.whl (32.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.0 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.7.4.tar.gz (30 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nlpia) (2019.12.20)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nlpia) (4.63.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nlpia) (4.2.6)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.2.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from nlpia) (5.5.0)\n",
            "Collecting pugnlp\n",
            "  Downloading pugnlp-0.2.6-py2.py3-none-any.whl (706 kB)\n",
            "\u001b[K     |████████████████████████████████| 706 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.8.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from nlpia) (2.8.0)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.3.5)\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.9.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from nlpia) (1.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from nlpia) (0.16.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from nlpia) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim->nlpia) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->nlpia) (1.5.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->nlpia) (0.5.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (7.6.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.2.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nlpia) (5.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->nlpia) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->nlpia) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->nlpia) (0.2.5)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nlpia) (3.5.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (3.10.0.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (4.11.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (5.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->nlpia) (3.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nlpia) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->nlpia) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->nlpia) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->nlpia) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->nlpia) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nlpia) (1.3.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (4.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->nlpia) (0.8.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->nlpia) (21.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlpia) (2018.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader->nlpia) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader->nlpia) (3.0.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->nlpia) (8.0.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (21.1.3)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (3.7.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (0.37.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from pugnlp->nlpia) (6.1.1)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->pugnlp->nlpia) (1.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nlpia) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nlpia) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->nlpia) (1.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (0.9.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->nlpia) (1.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.13.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (13.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (0.24.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.44.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->nlpia) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->nlpia) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->nlpia) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->nlpia) (3.2.0)\n",
            "Building wheels for collected packages: pypandoc, python-Levenshtein\n",
            "  Building wheel for pypandoc (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypandoc: filename=pypandoc-1.7.4-py2.py3-none-any.whl size=32102 sha256=535179eaf5aa11ddd26e01216c49f2fc41a2190d6ffe18d1c8eb9ad71e3a9426\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/ba/d10ff9f1ebfd8386979b7d86b7e8ed055aa8bc8f4900bfc986\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149878 sha256=78e250ff9c9abec67c42b858c9ae357a59f69814d943cd4513c7470e338a2582\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built pypandoc python-Levenshtein\n",
            "Installing collected packages: tf-estimator-nightly, python-Levenshtein, pypandoc, fuzzywuzzy, pugnlp, html2text, nlpia\n",
            "Successfully installed fuzzywuzzy-0.18.0 html2text-2020.1.16 nlpia-0.5.2 pugnlp-0.2.6 pypandoc-1.7.4 python-Levenshtein-0.12.2 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "!pip install nlpia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypgq02LBR8kd",
        "outputId": "8d1d69c1-a361-4efa-8c37-e1792ce95deb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a',\n",
              " 'kite',\n",
              " 'is',\n",
              " 'traditionally',\n",
              " 'a',\n",
              " 'tethered',\n",
              " 'heavier-than-air',\n",
              " 'craft',\n",
              " 'with',\n",
              " 'wing',\n",
              " 'surfaces',\n",
              " 'that',\n",
              " 'react',\n",
              " 'against',\n",
              " 'the',\n",
              " 'air',\n",
              " 'to',\n",
              " 'create',\n",
              " 'lift',\n",
              " 'and',\n",
              " 'drag.',\n",
              " 'a',\n",
              " 'kite',\n",
              " 'consists',\n",
              " 'of',\n",
              " 'wings',\n",
              " ',',\n",
              " 'tethers',\n",
              " ',',\n",
              " 'and',\n",
              " 'anchors.',\n",
              " 'kites',\n",
              " 'often',\n",
              " 'have',\n",
              " 'a',\n",
              " 'bridle',\n",
              " 'to',\n",
              " 'guide',\n",
              " 'the',\n",
              " 'face',\n",
              " 'of',\n",
              " 'the',\n",
              " 'kite',\n",
              " 'at',\n",
              " 'the',\n",
              " 'correct',\n",
              " 'angle',\n",
              " 'so',\n",
              " 'the',\n",
              " 'wind',\n",
              " 'can',\n",
              " 'lift',\n",
              " 'it.',\n",
              " 'a',\n",
              " 'kite',\n",
              " \"'s\",\n",
              " 'wing',\n",
              " 'also',\n",
              " 'may',\n",
              " 'be',\n",
              " 'so',\n",
              " 'designed',\n",
              " 'so',\n",
              " 'a',\n",
              " 'bridle',\n",
              " 'is',\n",
              " 'not',\n",
              " 'needed',\n",
              " ';',\n",
              " 'when',\n",
              " 'kiting',\n",
              " 'a',\n",
              " 'sailplane',\n",
              " 'for',\n",
              " 'launch',\n",
              " ',',\n",
              " 'the',\n",
              " 'tether',\n",
              " 'meets',\n",
              " 'the',\n",
              " 'wing',\n",
              " 'at',\n",
              " 'a',\n",
              " 'single',\n",
              " 'point.',\n",
              " 'a',\n",
              " 'kite',\n",
              " 'may',\n",
              " 'have',\n",
              " 'fixed',\n",
              " 'or',\n",
              " 'moving',\n",
              " 'anchors.',\n",
              " 'untraditionally',\n",
              " 'in',\n",
              " 'technical',\n",
              " 'kiting',\n",
              " ',',\n",
              " 'a',\n",
              " 'kite',\n",
              " 'consists',\n",
              " 'of',\n",
              " 'tether-set-coupled',\n",
              " 'wing',\n",
              " 'sets',\n",
              " ';',\n",
              " 'even',\n",
              " 'in',\n",
              " 'technical',\n",
              " 'kiting',\n",
              " ',',\n",
              " 'though',\n",
              " ',',\n",
              " 'a',\n",
              " 'wing',\n",
              " 'in',\n",
              " 'the',\n",
              " 'system',\n",
              " 'is',\n",
              " 'still',\n",
              " 'often',\n",
              " 'called',\n",
              " 'the',\n",
              " 'kite.',\n",
              " 'the',\n",
              " 'lift',\n",
              " 'that',\n",
              " 'sustains',\n",
              " 'the',\n",
              " 'kite',\n",
              " 'in',\n",
              " 'flight',\n",
              " 'is',\n",
              " 'generated',\n",
              " 'when',\n",
              " 'air',\n",
              " 'flows',\n",
              " 'around',\n",
              " 'the',\n",
              " 'kite',\n",
              " \"'s\",\n",
              " 'surface',\n",
              " ',',\n",
              " 'producing',\n",
              " 'low',\n",
              " 'pressure',\n",
              " 'above',\n",
              " 'and',\n",
              " 'high',\n",
              " 'pressure',\n",
              " 'below',\n",
              " 'the',\n",
              " 'wings.',\n",
              " 'the',\n",
              " 'interaction',\n",
              " 'with',\n",
              " 'the',\n",
              " 'wind',\n",
              " 'also',\n",
              " 'generates',\n",
              " 'horizontal',\n",
              " 'drag',\n",
              " 'along',\n",
              " 'the',\n",
              " 'direction',\n",
              " 'of',\n",
              " 'the',\n",
              " 'wind.',\n",
              " 'the',\n",
              " 'resultant',\n",
              " 'force',\n",
              " 'vector',\n",
              " 'from',\n",
              " 'the',\n",
              " 'lift',\n",
              " 'and',\n",
              " 'drag',\n",
              " 'force',\n",
              " 'components',\n",
              " 'is',\n",
              " 'opposed',\n",
              " 'by',\n",
              " 'the',\n",
              " 'tension',\n",
              " 'of',\n",
              " 'one',\n",
              " 'or',\n",
              " 'more',\n",
              " 'of',\n",
              " 'the',\n",
              " 'lines',\n",
              " 'or',\n",
              " 'tethers',\n",
              " 'to',\n",
              " 'which',\n",
              " 'the',\n",
              " 'kite',\n",
              " 'is',\n",
              " 'attached.',\n",
              " 'the',\n",
              " 'anchor',\n",
              " 'point',\n",
              " 'of',\n",
              " 'the',\n",
              " 'kite',\n",
              " 'line',\n",
              " 'may',\n",
              " 'be',\n",
              " 'static',\n",
              " 'or',\n",
              " 'moving',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'the',\n",
              " 'towing',\n",
              " 'of',\n",
              " 'a',\n",
              " 'kite',\n",
              " 'by',\n",
              " 'a',\n",
              " 'running',\n",
              " 'person',\n",
              " ',',\n",
              " 'boat',\n",
              " ',',\n",
              " 'free-falling',\n",
              " 'anchors',\n",
              " 'as',\n",
              " 'in',\n",
              " 'paragliders',\n",
              " 'and',\n",
              " 'fugitive',\n",
              " 'parakites',\n",
              " 'or',\n",
              " 'vehicle',\n",
              " ')',\n",
              " '.',\n",
              " 'the',\n",
              " 'same',\n",
              " 'principles',\n",
              " 'of',\n",
              " 'fluid',\n",
              " 'flow',\n",
              " 'apply',\n",
              " 'in',\n",
              " 'liquids',\n",
              " 'and',\n",
              " 'kites',\n",
              " 'are',\n",
              " 'also',\n",
              " 'used',\n",
              " 'under',\n",
              " 'water.',\n",
              " 'a',\n",
              " 'hybrid',\n",
              " 'tethered',\n",
              " 'craft',\n",
              " 'comprising',\n",
              " 'both',\n",
              " 'a',\n",
              " 'lighter-than-air',\n",
              " 'balloon',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'a',\n",
              " 'kite',\n",
              " 'lifting',\n",
              " 'surface',\n",
              " 'is',\n",
              " 'called',\n",
              " 'a',\n",
              " 'kytoon.',\n",
              " 'kites',\n",
              " 'have',\n",
              " 'a',\n",
              " 'long',\n",
              " 'and',\n",
              " 'varied',\n",
              " 'history',\n",
              " 'and',\n",
              " 'many',\n",
              " 'different',\n",
              " 'types',\n",
              " 'are',\n",
              " 'flown',\n",
              " 'individually',\n",
              " 'and',\n",
              " 'at',\n",
              " 'festivals',\n",
              " 'worldwide.',\n",
              " 'kites',\n",
              " 'may',\n",
              " 'be',\n",
              " 'flown',\n",
              " 'for',\n",
              " 'recreation',\n",
              " ',',\n",
              " 'art',\n",
              " 'or',\n",
              " 'other',\n",
              " 'practical',\n",
              " 'uses.',\n",
              " 'sport',\n",
              " 'kites',\n",
              " 'can',\n",
              " 'be',\n",
              " 'flown',\n",
              " 'in',\n",
              " 'aerial',\n",
              " 'ballet',\n",
              " ',',\n",
              " 'sometimes',\n",
              " 'as',\n",
              " 'part',\n",
              " 'of',\n",
              " 'a',\n",
              " 'competition.',\n",
              " 'power',\n",
              " 'kites',\n",
              " 'are',\n",
              " 'multi-line',\n",
              " 'steerable',\n",
              " 'kites',\n",
              " 'designed',\n",
              " 'to',\n",
              " 'generate',\n",
              " 'large',\n",
              " 'forces',\n",
              " 'which',\n",
              " 'can',\n",
              " 'be',\n",
              " 'used',\n",
              " 'to',\n",
              " 'power',\n",
              " 'activities',\n",
              " 'such',\n",
              " 'as',\n",
              " 'kite',\n",
              " 'surfing',\n",
              " ',',\n",
              " 'kite',\n",
              " 'landboarding',\n",
              " ',',\n",
              " 'kite',\n",
              " 'fishing',\n",
              " ',',\n",
              " 'kite',\n",
              " 'buggying',\n",
              " 'and',\n",
              " 'a',\n",
              " 'new',\n",
              " 'trend',\n",
              " 'snow',\n",
              " 'kiting.',\n",
              " 'even',\n",
              " 'man-lifting',\n",
              " 'kites',\n",
              " 'have',\n",
              " 'been',\n",
              " 'made',\n",
              " '.']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "\n",
        "from nlpia.data.loaders import kite_text, kite_history  \n",
        "kite_intro = kite_text.lower()\n",
        "intro_tokens = tokenizer.tokenize(kite_intro) \n",
        "\n",
        "intro_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2ZJfz14SDoS",
        "outputId": "4bcc651d-eef8-4669-8ea8-db6362c80139"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['kites',\n",
              " 'were',\n",
              " 'invented',\n",
              " 'in',\n",
              " 'china',\n",
              " ',',\n",
              " 'where',\n",
              " 'materials',\n",
              " 'ideal',\n",
              " 'for',\n",
              " 'kite',\n",
              " 'building',\n",
              " 'were',\n",
              " 'readily',\n",
              " 'available',\n",
              " ':',\n",
              " 'silk',\n",
              " 'fabric',\n",
              " 'for',\n",
              " 'sail',\n",
              " 'material',\n",
              " ';',\n",
              " 'fine',\n",
              " ',',\n",
              " 'high-tensile-strength',\n",
              " 'silk',\n",
              " 'for',\n",
              " 'flying',\n",
              " 'line',\n",
              " ';',\n",
              " 'and',\n",
              " 'resilient',\n",
              " 'bamboo',\n",
              " 'for',\n",
              " 'a',\n",
              " 'strong',\n",
              " ',',\n",
              " 'lightweight',\n",
              " 'framework.',\n",
              " 'the',\n",
              " 'kite',\n",
              " 'has',\n",
              " 'been',\n",
              " 'claimed',\n",
              " 'as',\n",
              " 'the',\n",
              " 'invention',\n",
              " 'of',\n",
              " 'the',\n",
              " '5th-century',\n",
              " 'bc',\n",
              " 'chinese',\n",
              " 'philosophers',\n",
              " 'mozi',\n",
              " '(',\n",
              " 'also',\n",
              " 'mo',\n",
              " 'di',\n",
              " ')',\n",
              " 'and',\n",
              " 'lu',\n",
              " 'ban',\n",
              " '(',\n",
              " 'also',\n",
              " 'gongshu',\n",
              " 'ban',\n",
              " ')',\n",
              " '.',\n",
              " 'by',\n",
              " '549',\n",
              " 'ad',\n",
              " 'paper',\n",
              " 'kites',\n",
              " 'were',\n",
              " 'certainly',\n",
              " 'being',\n",
              " 'flown',\n",
              " ',',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'recorded',\n",
              " 'that',\n",
              " 'in',\n",
              " 'that',\n",
              " 'year',\n",
              " 'a',\n",
              " 'paper',\n",
              " 'kite',\n",
              " 'was',\n",
              " 'used',\n",
              " 'as',\n",
              " 'a',\n",
              " 'message',\n",
              " 'for',\n",
              " 'a',\n",
              " 'rescue',\n",
              " 'mission.',\n",
              " 'ancient',\n",
              " 'and',\n",
              " 'medieval',\n",
              " 'chinese',\n",
              " 'sources',\n",
              " 'describe',\n",
              " 'kites',\n",
              " 'being',\n",
              " 'used',\n",
              " 'for',\n",
              " 'measuring',\n",
              " 'distances',\n",
              " ',',\n",
              " 'testing',\n",
              " 'the',\n",
              " 'wind',\n",
              " ',',\n",
              " 'lifting',\n",
              " 'men',\n",
              " ',',\n",
              " 'signaling',\n",
              " ',',\n",
              " 'and',\n",
              " 'communication',\n",
              " 'for',\n",
              " 'military',\n",
              " 'operations.',\n",
              " 'the',\n",
              " 'earliest',\n",
              " 'known',\n",
              " 'chinese',\n",
              " 'kites',\n",
              " 'were',\n",
              " 'flat',\n",
              " '(',\n",
              " 'not',\n",
              " 'bowed',\n",
              " ')',\n",
              " 'and',\n",
              " 'often',\n",
              " 'rectangular.',\n",
              " 'later',\n",
              " ',',\n",
              " 'tailless',\n",
              " 'kites',\n",
              " 'incorporated',\n",
              " 'a',\n",
              " 'stabilizing',\n",
              " 'bowline.',\n",
              " 'kites',\n",
              " 'were',\n",
              " 'decorated',\n",
              " 'with',\n",
              " 'mythological',\n",
              " 'motifs',\n",
              " 'and',\n",
              " 'legendary',\n",
              " 'figures',\n",
              " ';',\n",
              " 'some',\n",
              " 'were',\n",
              " 'fitted',\n",
              " 'with',\n",
              " 'strings',\n",
              " 'and',\n",
              " 'whistles',\n",
              " 'to',\n",
              " 'make',\n",
              " 'musical',\n",
              " 'sounds',\n",
              " 'while',\n",
              " 'flying.',\n",
              " 'from',\n",
              " 'china',\n",
              " ',',\n",
              " 'kites',\n",
              " 'were',\n",
              " 'introduced',\n",
              " 'to',\n",
              " 'cambodia',\n",
              " ',',\n",
              " 'thailand',\n",
              " ',',\n",
              " 'india',\n",
              " ',',\n",
              " 'japan',\n",
              " ',',\n",
              " 'korea',\n",
              " 'and',\n",
              " 'the',\n",
              " 'western',\n",
              " 'world.',\n",
              " 'after',\n",
              " 'its',\n",
              " 'introduction',\n",
              " 'into',\n",
              " 'india',\n",
              " ',',\n",
              " 'the',\n",
              " 'kite',\n",
              " 'further',\n",
              " 'evolved',\n",
              " 'into',\n",
              " 'the',\n",
              " 'fighter',\n",
              " 'kite',\n",
              " ',',\n",
              " 'known',\n",
              " 'as',\n",
              " 'the',\n",
              " 'patang',\n",
              " 'in',\n",
              " 'india',\n",
              " ',',\n",
              " 'where',\n",
              " 'thousands',\n",
              " 'are',\n",
              " 'flown',\n",
              " 'every',\n",
              " 'year',\n",
              " 'on',\n",
              " 'festivals',\n",
              " 'such',\n",
              " 'as',\n",
              " 'makar',\n",
              " 'sankranti.',\n",
              " 'kites',\n",
              " 'were',\n",
              " 'known',\n",
              " 'throughout',\n",
              " 'polynesia',\n",
              " ',',\n",
              " 'as',\n",
              " 'far',\n",
              " 'as',\n",
              " 'new',\n",
              " 'zealand',\n",
              " ',',\n",
              " 'with',\n",
              " 'the',\n",
              " 'assumption',\n",
              " 'being',\n",
              " 'that',\n",
              " 'the',\n",
              " 'knowledge',\n",
              " 'diffused',\n",
              " 'from',\n",
              " 'china',\n",
              " 'along',\n",
              " 'with',\n",
              " 'the',\n",
              " 'people.',\n",
              " 'anthropomorphic',\n",
              " 'kites',\n",
              " 'made',\n",
              " 'from',\n",
              " 'cloth',\n",
              " 'and',\n",
              " 'wood',\n",
              " 'were',\n",
              " 'used',\n",
              " 'in',\n",
              " 'religious',\n",
              " 'ceremonies',\n",
              " 'to',\n",
              " 'send',\n",
              " 'prayers',\n",
              " 'to',\n",
              " 'the',\n",
              " 'gods.',\n",
              " 'polynesian',\n",
              " 'kite',\n",
              " 'traditions',\n",
              " 'are',\n",
              " 'used',\n",
              " 'by',\n",
              " 'anthropologists',\n",
              " 'get',\n",
              " 'an',\n",
              " 'idea',\n",
              " 'of',\n",
              " 'early',\n",
              " '``',\n",
              " 'primitive',\n",
              " \"''\",\n",
              " 'asian',\n",
              " 'traditions',\n",
              " 'that',\n",
              " 'are',\n",
              " 'believed',\n",
              " 'to',\n",
              " 'have',\n",
              " 'at',\n",
              " 'one',\n",
              " 'time',\n",
              " 'existed',\n",
              " 'in',\n",
              " 'asia',\n",
              " '.']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kite_history = kite_history.lower()\n",
        "history_tokens = tokenizer.tokenize(kite_history) \n",
        "history_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyM3KbTjSbwA",
        "outputId": "b63562ef-fba3-4825-f5dc-ab05abb216bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "363\n",
            "297\n"
          ]
        }
      ],
      "source": [
        "intro_total = len(intro_tokens) \n",
        "history_total = len(history_tokens) \n",
        "\n",
        "print(intro_total)\n",
        "print(history_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFcgqGfbSmDj"
      },
      "outputs": [],
      "source": [
        "intro_tf = {}\n",
        "history_tf = {}\n",
        "intro_counts = Counter(intro_tokens) \n",
        "intro_tf['kite'] = intro_counts['kite'] / intro_total \n",
        "history_counts = Counter(history_tokens) \n",
        "history_tf['kite'] = history_counts['kite'] / history_total "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8WPrvxhS7da",
        "outputId": "b711514b-1aba-4684-9d27-a80063e4da39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0440771349862259"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "intro_tf['kite'] # 두배정도 kite단어가 많이 등장함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyEKIcAyTAXk",
        "outputId": "c7fb4a7b-84e9-4c24-91aa-724df8fb02cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.020202020202020204"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history_tf['kite'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQo-noWeTCXm"
      },
      "outputs": [],
      "source": [
        "# and를 확인하기\n",
        "intro_tf['and'] = intro_counts['and'] / intro_total \n",
        "history_tf['and'] =history_counts['and'] / history_total "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt8m35kQTSPh",
        "outputId": "4f7004fd-df94-4d28-a3af-037826d62f54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.027548209366391185"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "intro_tf['and']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsW5P-AxTV3Y",
        "outputId": "50010020-7fb5-4388-f25d-e5af06efc669"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.030303030303030304"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history_tf['and']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkuI3KpzTWo2"
      },
      "outputs": [],
      "source": [
        "# 주어진 단어가 문장에서 얼마나 중요한지 보려면 idf가 필요함\n",
        "# 이 토큰이 이 문서에 등장하는 것이 얼마나 이상한 일인가 라는 관점에서 바라봐야함\n",
        "num_docs_containing_and = 0\n",
        "for doc in [intro_tokens, history_tokens] : \n",
        "  if 'and' in doc : \n",
        "    num_docs_containing_and += 1\n",
        "\n",
        "num_docs_containing_kite = 0\n",
        "for doc in [intro_tokens, history_tokens] : \n",
        "  if 'kite' in doc : \n",
        "    num_docs_containing_kite += 1\n",
        "\n",
        "\n",
        "num_docs_containing_china = 0\n",
        "for doc in [intro_tokens, history_tokens] : \n",
        "  if 'china' in doc : \n",
        "    num_docs_containing_china += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI_PcP3jT3BY"
      },
      "outputs": [],
      "source": [
        "intro_tf['china'] = intro_counts['china'] / intro_total \n",
        "history_tf['china'] =history_counts['china'] / history_total "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvyt171nT-Ae"
      },
      "outputs": [],
      "source": [
        "num_docs = 2 \n",
        "intro_idf = {} \n",
        "history_idf ={} \n",
        "intro_idf['and'] = num_docs / num_docs_containing_and # 2/2 = 1\n",
        "history_idf['and'] = num_docs / num_docs_containing_and # 2/2 =1 \n",
        "\n",
        "intro_idf['kite'] = num_docs / num_docs_containing_kite # 2/2 = 1\n",
        "history_idf['kite'] = num_docs / num_docs_containing_kite # 2/2 =1\n",
        "\n",
        "intro_idf['china'] = num_docs / num_docs_containing_china # 2 \n",
        "history_idf['china'] = num_docs / num_docs_containing_china  # 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzINx-XRVSWx",
        "outputId": "d27b69eb-009a-4334-feaa-104f19e17097"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_docs_containing_and"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X50lsAg_V0hK",
        "outputId": "35239a80-7bc4-4cbb-9f90-f4194eea8d1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_docs_containing_kite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PDMzjpzV2vj",
        "outputId": "3609c380-4700-47fe-ca00-32cdf657f2f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_docs_containing_china"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR1KQMqKUg24"
      },
      "outputs": [],
      "source": [
        "intro_tfidf ={} \n",
        "intro_tfidf['and'] = intro_tf['and'] * intro_idf['and']\n",
        "intro_tfidf['kite'] = intro_tf['kite'] * intro_idf['kite']\n",
        "intro_tfidf['china'] = intro_tf['china'] * intro_idf['china']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of2w-GRmUt-a"
      },
      "outputs": [],
      "source": [
        "history_tfidf ={} \n",
        "history_tfidf['and'] = history_tf['and'] * history_idf['and']\n",
        "history_tfidf['kite'] = history_tf['kite'] * history_idf['kite']\n",
        "history_tfidf['china'] = history_tf['china'] * history_idf['china']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEUjevZRUy_M",
        "outputId": "2f3593dc-5e69-4434-f0fb-4281fd8bb594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'and': 0.027548209366391185, 'kite': 0.0440771349862259, 'china': 0.0}\n",
            "{'and': 0.030303030303030304, 'kite': 0.020202020202020204, 'china': 0.020202020202020204}\n"
          ]
        }
      ],
      "source": [
        "print(intro_tfidf)\n",
        "print(history_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hh06XBNVML0"
      },
      "outputs": [],
      "source": [
        "# 전체 단어 1000000\n",
        "# cat 1번등장 : idf = 1000000\n",
        "# dog 10번등장 : idf = 100000\n",
        "# 말뭉치가 크면 cat과 dog의 빈도차이가 크지 않더라도 idf차이는 아주 클 수 있음\n",
        "# idf 에 로그를 씌우면 두 용어의 idf를 비교하기 좋을뿐 아니라 tf-idf점수들이 좀더 고르게 분포됨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ri3CS58WuUi"
      },
      "outputs": [],
      "source": [
        "# 한 단어가 문서에 자주 나올수록 그 단어의 tf가 올라감\n",
        "# 그 단어를 포함한 문서가 많을수록 그단어의 idf는 내려감\n",
        "# tf*idf = tf-idf \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efqsWZgCW4ul"
      },
      "outputs": [],
      "source": [
        "#log_tf = log(term_occurences_in_doc) - log(num_terms_in_doc) \n",
        "#log_log_idf = log(log(total_num_docs) - log(num_docs_containing_term)) \n",
        "#log_tf_idf = log_tf + log_idf \n",
        "# 간단한 검색 엔진들은 tf-idf수치하나에 기초함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAMwOkjoXPgm"
      },
      "outputs": [],
      "source": [
        "# 관련성 순위\n",
        "# 문서를 표현하는 벡터는 각 단어의 출현횟수가 아니라 각 단어의 tf-idf로 이루어진 벡터는 문서의 의미나 주제를 좀더 충실하게 반영함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GguCXvF8ahA8"
      },
      "outputs": [],
      "source": [
        "import copy \n",
        "document_tfidf_vectors = []\n",
        "for doc in docs : \n",
        "  vec = copy.copy(zero_vector)\n",
        "  tokens = tokenizer.tokenize(doc.lower()) \n",
        "  token_counts = Counter(tokens)  \n",
        "\n",
        "  for key, value in token_counts.items():\n",
        "    docs_containing_key = 0\n",
        "\n",
        "    for _doc in docs:\n",
        "      if key in _doc:\n",
        "        docs_containing_key += 1 \n",
        "      \n",
        "      tf= value / len(lexicon) \n",
        "      \n",
        "      if docs_containing_key:\n",
        "        idf = len(docs) / docs_containing_key \n",
        "      else:\n",
        "        idf = 0\n",
        "      vec[key] = tf*idf \n",
        "  document_tfidf_vectors.append(vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfySnAEDbXQe",
        "outputId": "d7b3aa02-a617-4203-e989-7de81bfb4019"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the faster harry got to the store, the faster harry, the faster, would get home.',\n",
              " 'harry is hairy and faster than jill.',\n",
              " 'jill is not as hairy as harry.']"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLZOPJEEbMsS",
        "outputId": "75e288e1-bbac-4ef8-8d92-5513c10b0f3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[OrderedDict([(',', 0.5),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.25),\n",
              "              ('get', 0.16666666666666666),\n",
              "              ('got', 0.16666666666666666),\n",
              "              ('hairy', 0),\n",
              "              ('harry', 0.1111111111111111),\n",
              "              ('home', 0.16666666666666666),\n",
              "              ('is', 0),\n",
              "              ('jill', 0),\n",
              "              ('not', 0),\n",
              "              ('store', 0.16666666666666666),\n",
              "              ('than', 0),\n",
              "              ('the', 0.6666666666666666),\n",
              "              ('to', 0.16666666666666666),\n",
              "              ('would', 0.16666666666666666)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0.16666666666666666),\n",
              "              ('as', 0),\n",
              "              ('faster', 0.08333333333333333),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.08333333333333333),\n",
              "              ('harry', 0.05555555555555555),\n",
              "              ('home', 0),\n",
              "              ('is', 0.08333333333333333),\n",
              "              ('jill', 0.08333333333333333),\n",
              "              ('not', 0),\n",
              "              ('store', 0),\n",
              "              ('than', 0.16666666666666666),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)]),\n",
              " OrderedDict([(',', 0),\n",
              "              ('.', 0.05555555555555555),\n",
              "              ('and', 0),\n",
              "              ('as', 0.1111111111111111),\n",
              "              ('faster', 0),\n",
              "              ('get', 0),\n",
              "              ('got', 0),\n",
              "              ('hairy', 0.08333333333333333),\n",
              "              ('harry', 0.05555555555555555),\n",
              "              ('home', 0),\n",
              "              ('is', 0.08333333333333333),\n",
              "              ('jill', 0.08333333333333333),\n",
              "              ('not', 0.16666666666666666),\n",
              "              ('store', 0),\n",
              "              ('than', 0),\n",
              "              ('the', 0),\n",
              "              ('to', 0),\n",
              "              ('would', 0)])]"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_tfidf_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3n21rTgbSFs"
      },
      "outputs": [],
      "source": [
        "# tf-idf값들과 코사인 유사도가 있으면 간단한 문서 검색이 가능함\n",
        "# 검색질의 문자체를 하나의 문서로 간주해서, 그것의 tf-idf문서 표현벡터를 구하고 말뭉치의 문서 표현벡터중 검색질의 문서 표현벡터와의 코사인 유사도 구함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2l8CEAUb5qU",
        "outputId": "e12d8d7e-e13f-438f-8e41-36eb11b77460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([(',', 0),\n",
              "             ('.', 0),\n",
              "             ('and', 0),\n",
              "             ('as', 0),\n",
              "             ('faster', 0),\n",
              "             ('get', 0),\n",
              "             ('got', 0),\n",
              "             ('hairy', 0),\n",
              "             ('harry', 0),\n",
              "             ('home', 0),\n",
              "             ('is', 0),\n",
              "             ('jill', 0),\n",
              "             ('not', 0),\n",
              "             ('store', 0),\n",
              "             ('than', 0),\n",
              "             ('the', 0),\n",
              "             ('to', 0),\n",
              "             ('would', 0)])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"how long does it take to get to the store?\" \n",
        "\n",
        "query_vec = copy.copy(zero_vector);query_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEgp1Z1ccFzv"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.tokenize(query.lower()) \n",
        "token_counts = Counter(tokens) \n",
        "for key, value in token_counts.items():\n",
        "  docs_containing_key = 0\n",
        "  for _doc in docs: \n",
        "    if key in _doc.lower(): \n",
        "      docs_containing_key += 1\n",
        "  if docs_containing_key ==0:\n",
        "    continue \n",
        "  tf = value / len(tokens) \n",
        "  idf = len(docs) / docs_containing_key\n",
        "  query_vec[key] = tf*idf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBrRfM3nciJy",
        "outputId": "bf52a483-e77b-491c-dc9e-9b661d89d5c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([(',', 0),\n",
              "             ('.', 0),\n",
              "             ('and', 0),\n",
              "             ('as', 0),\n",
              "             ('faster', 0),\n",
              "             ('get', 0.2727272727272727),\n",
              "             ('got', 0),\n",
              "             ('hairy', 0),\n",
              "             ('harry', 0),\n",
              "             ('home', 0),\n",
              "             ('is', 0),\n",
              "             ('jill', 0),\n",
              "             ('not', 0),\n",
              "             ('store', 0.2727272727272727),\n",
              "             ('than', 0),\n",
              "             ('the', 0.2727272727272727),\n",
              "             ('to', 0.5454545454545454),\n",
              "             ('would', 0)])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl_q9qX7c00K",
        "outputId": "49fe0ba6-d16e-4f29-bab3-b0d77fda507a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.52005218841113"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_sim(query_vec, document_tfidf_vectors[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKCSUzr3ds_6",
        "outputId": "ff16b316-ffad-44ad-cee7-e519467daa1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_sim(query_vec, document_tfidf_vectors[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QiCgbV_dtTU",
        "outputId": "5d3f783a-8f41-4ebb-ffde-cda7829b53cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_sim(query_vec, document_tfidf_vectors[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn_LOOAxd4W7"
      },
      "outputs": [],
      "source": [
        "# 선형검색 : 선형 복잡도가 O(N) \n",
        "# 구글 검색엔진은 역색인 : O(1)에 해당, whoosh라고 하는 파이썬 패키지가 있음\n",
        "# 가산적 평활화 : 코드에서는 어휘집에 토큰이 없으면 0으로 나누기를 피하기 위해 continue로 넘김, 이를 해결하기 위해 분모에 1을 더해줌\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPBZn-zOfipK",
        "outputId": "3eb8d0fc-7107-49d7-95b1-38e66b97bc6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# scikit-learn\n",
        "!pip install scipy\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA6U98ARgV8V",
        "outputId": "09f5c58b-3a1f-4af0-c7b5-ae775a964e42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['the faster harry got to the store, the faster harry, the faster, would get home.',\n",
              " 'harry is hairy and faster than jill.',\n",
              " 'jill is not as hairy as harry.']"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs # 3개의 문장 / 단어는 16개 / 어휘에 문장부호는 포함되지 않음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCH9uJNKfrFe",
        "outputId": "39a658b6-8c27-445e-b739-d8812ecb9bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.   0.   0.43 0.19 0.19 0.   0.22 0.19 0.   0.   0.   0.19 0.   0.75\n",
            "  0.19 0.19]\n",
            " [0.46 0.   0.35 0.   0.   0.35 0.27 0.   0.35 0.35 0.   0.   0.46 0.\n",
            "  0.   0.  ]\n",
            " [0.   0.75 0.   0.   0.   0.29 0.22 0.   0.29 0.29 0.38 0.   0.   0.\n",
            "  0.   0.  ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = docs \n",
        "vectorizer = TfidfVectorizer(min_df =1)\n",
        "model = vectorizer.fit_transform(corpus) \n",
        "print(model.todense().round(2))# 희소행렬을 numpy행렬로 반환함 , \n",
        "# 사이킥런을 사용하면 단 네줄의 코드로 tf-idf행렬을 만들어줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KTkmhwHgH6P",
        "outputId": "01fbca79-e6f4-4bd4-f3ee-6463961a3b44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3x16 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 22 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqYxY1HVf8lR"
      },
      "outputs": [],
      "source": [
        "# 여러 tf-idf 정규화 방법\n",
        "# 용어-문서 행렬로서의 tf-idf행렬은 정보조회의 주춧돌\n",
        "# idf를 최적화하는데 많은 시간을 투자함\n",
        "# tf-idf 코사인 유사도 대신 okapi bm25이 고려됨 (코사인유사도를 정규화하고 평활화한 값을 사용함)\n",
        "# 의미론적인 검색엔진들이 더욱 좋음 (향후 챕터에서 다룰예정)\n",
        "# 문서개수가 수십억 규모인 말뭉치에서는 의미론적 단어벡터나 주제벡터가 효율적이지 못하나. 그러나 문서 수백만건 정도는 의미론적 검색도 감당할 수 있음\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEHGHmDHhs20"
      },
      "source": [
        "# ch04. 단어빈도에서 의미찾기 : 의미분석 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC1uAVc5hxTf"
      },
      "outputs": [],
      "source": [
        "# 잠재의미분석(LSA): 단어들의 뜻을 벡터 형태로 표현할수있을 뿐만 아니라 문서 전체의 뜻도 표현할수있음\n",
        "# 주제벡터(의미론적 벡터) : tf-idf벡터의 가중빈도들을 이용해서 구한 주제 점수들을 성분으로 하는 다차원 벡터임\n",
        "# 주제벡터 기반검색이 키워드검색(tf-idf)보다 훨씬 낫다.\n",
        "# 의미벡터를 이용하면 주어진 문장이나 문서, 또는 말뭉치의 주제를 가장 잘 나타내는 단어들과 n-그램들을 식별 할 수 있음\n",
        "# 주어진 문서에 대해 가장 의미있는 단어들, 문서의 의미를 가장 잘 요약하는 핵심어들을 찾아낼 수 있음\n",
        "# 두문서(또는 문장)의 핵심어들을 비교함으로써 두 문서의 의미가 얼마나 가까운지 추정할 수 있음\n",
        "# tf-idf의 단점 : 단어 구성이 다르거나, 철자가 다르면 tf-idf 벡터 표현이 완전히 달라짐, 이는 토큰 빈도에 기초한 검색엔진과 유사도 비교의 큰 단점임\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOQ3tzgKnEk2"
      },
      "outputs": [],
      "source": [
        "# 단어주제벡터(word-topic vector): 문서의 의미를 표ㅕㄴ하는 벡터를 문서-주제 벡터라고 부름\n",
        "# 단어와 문장의 의미를 수치로 표현하는것이 간단한 일은 아님,  영어처럼 FUZZY한 언어, 다수의 방언이 존재하며, 같은 단어라도 해석이 다양한 언어에서는 더욱 그러함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcqehQqspI_0"
      },
      "outputs": [],
      "source": [
        "topic = {}\n",
        "import numpy as np\n",
        "tfidf = dict(list(zip('cat dog apple lion NYC love'.split(), np.random.rand(6))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zzj-d6xlSY4",
        "outputId": "66531cfe-482d-46cd-e57f-8b6cc37b80cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'NYC': 0.7636089427968705,\n",
              " 'apple': 0.5003625935807061,\n",
              " 'cat': 0.1651195170611346,\n",
              " 'dog': 0.17410241556025274,\n",
              " 'lion': 0.8720361504834037,\n",
              " 'love': 0.37470675405495246}"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6a_YjvfpSOI"
      },
      "outputs": [],
      "source": [
        "topic['petness'] = (0.3 * tfidf['cat'] + 0.3*tfidf['dog'] + 0*tfidf['apple'] + 0 * tfidf['lion'] - 0.2*tfidf['NYC'] + 0.2* tfidf['love'])\n",
        "\n",
        "topic['animalness'] = (0.1 * tfidf['cat'] + 0.1*tfidf['dog'] - 0.1 *tfidf['apple'] + 0.5* tfidf['lion'] - 0.1*tfidf['NYC'] + 0.1* tfidf['love'])\n",
        "\n",
        "topic['cityness'] = (0 * tfidf['cat'] - 0.1*tfidf['dog'] + 0.2 * tfidf['apple'] - 0.1 * tfidf['lion'] + 0.5 *tfidf['NYC'] + 0.1* tfidf['love'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzLQljOJpxiC"
      },
      "outputs": [],
      "source": [
        "word_vector= {}\n",
        "word_vector['cat'] = 0.3*topic['petness'] + 0.1*topic['animalness'] + 0* topic['cityness'] \n",
        "word_vector['dog'] = 0.3*topic['petness'] + 0.1*topic['animalness'] - 0.1* topic['cityness'] \n",
        "\n",
        "word_vector['aplle'] = 0*topic['petness'] - 0.1*topic['animalness'] + 0.2* topic['cityness'] \n",
        "word_vector['lion'] = 0*topic['petness'] + 0.5*topic['animalness'] - 0.1* topic['cityness'] \n",
        "\n",
        "word_vector['NYC'] = -0.2*topic['petness'] + 0.1*topic['animalness'] + 0.5* topic['cityness'] \n",
        "word_vector['love'] = 0.2*topic['petness'] - 0.1*topic['animalness'] + 0.1* topic['cityness'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7zzvr80tCND"
      },
      "outputs": [],
      "source": [
        "# 상식에 기초하지 않고도 주제 가중치를 선택하는 알고리즘이 필요함\n",
        "# 가중합의 계산방식을 생각해보면 각 가중합이 하나의 내적임\n",
        "# 세 내적은 곧 행렬 곱셈에 해당함\n",
        "# 3xn(n:어휘의 단어수) 가중 행렬에 한문서의 가중단어 빈도들로 이루어진 n차원 tf-idf를 곱한결과는 문서의 주제를 말해주는 3x1주제벡터가됨\n",
        "# 한 벡터공간에 있는 고차원 벡터(tf-idf벡터)를 그보다 낮은 차원의 다른 벡터공간의 벡터(주제벡터)로 변환하는것에 해당함\n",
        "# n개의 용어와 m개의 주제에 대한 행렬을 산출해야함\n",
        "# 그 행렬에 한 문서의 가중빈도들로 이루어진 벡터를 곱하면 그 문서에 대한 주제벡터가 나옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM2JArShvIVx"
      },
      "outputs": [],
      "source": [
        "# LSA는 TF-IDF를 분석해서 단어들을 주제들로 요약하는 알고리즘의 하나이다\n",
        "# BOW에도 이 알고리즘을 적용할 수 있지만 TF-IDF벡터를 사용할때의 결과가 약간 더 낫다\n",
        "# LSA는 주제 차원들의 다양성이 유지되도록 주제들을 최적화함\n",
        "# LSA를 하나의 차원축소 기법이라고도 함, 문서들의 의미를 파악하는데 필요한 차원의 수를 줄임\n",
        "# PCA에 사용되는 수학은 LSA에 사용되는것과 같음\n",
        "# PCA는 이미지나 기타 수치행렬의 차원을 줄이기 위한것이고, LSA는 BOW나 TF-IDF의 차원을 줄이기 위한것\n",
        "# LSA와 비슷한 용도의 알고리즘 : LDA(선형판별분석), LDiA(잠재 디리클레 할당, 문서들을 원하는 만큼의 여러 주제로 축약할수있음)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKCMNmVvwT1r",
        "outputId": "507dae46-80a1-42dd-8d78-5714566990c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n"
          ]
        }
      ],
      "source": [
        "# [1] LDA 분류기\n",
        "# 차원축소기법과 분류모형중 가장 간단하고 빠름\n",
        "# LDA분류기는 지도학습 알고리즘에 속함, \n",
        "# 순서\n",
        "# 1. 한 부류에 속하는 TF-IDF 벡터들의 평균위치(무게중심)계산\n",
        "# 2. 다른 부류에 속하지 않는 TF-IDF벡터들의 평균위치 계산\n",
        "# 3. 두 무게중심을 잇는 직선을 나타내느 벡터를 계산함\n",
        "# 4. TF-IDF벡터가 어느 부류의 무게중심에 더 가까운지 보면됨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaASRVB2xC1e",
        "outputId": "ffb6b1e1-35b8-40b6-c0d3-b0b697baf53c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n",
            "/usr/local/lib/python3.7/dist-packages/nlpia/loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  np = pd.np\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nlpia.data.loaders import get_data  \n",
        "pd.options.display.width = 120 \n",
        "sms  = get_data('sms-spam') \n",
        "index = ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "6JPtemtyxXdf",
        "outputId": "e61f93fe-985c-42d9-f03a-8599a2440c0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2a967e55-7c6b-4f48-8b3c-01980480d0b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sms0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a967e55-7c6b-4f48-8b3c-01980480d0b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a967e55-7c6b-4f48-8b3c-01980480d0b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a967e55-7c6b-4f48-8b3c-01980480d0b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     spam                                               text\n",
              "sms0    0  Go until jurong point, crazy.. Available only ...\n",
              "sms1    0                      Ok lar... Joking wif u oni..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sms = pd.DataFrame(sms.values, columns= sms.columns, index= index) ; sms.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmL4u3L8xqIj",
        "outputId": "2ab0fefc-101a-4c0d-f2a8-1e09158eb19e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0,\n",
              "        'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'],\n",
              "       [0, 'Ok lar... Joking wif u oni...'],\n",
              "       [1,\n",
              "        \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"],\n",
              "       ...,\n",
              "       [0, 'Pity, * was in mood for that. So...any other suggestions?'],\n",
              "       [0,\n",
              "        \"The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free\"],\n",
              "       [0, 'Rofl. Its true to its name']], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sms.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJqDukwbxqda",
        "outputId": "b9db0645-cfef-4f7d-8322-3f2ddf660377"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4837"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0BfNh8vx0Kg",
        "outputId": "e6403a8a-5a8d-4834-88d5-79f34c17e864"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "638"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sms.spam.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di4L4wVAx1A9",
        "outputId": "0a826447-7b7a-46e4-dafe-ed6d7c5b3ae5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from nltk.tokenize.casual import casual_tokenize  \n",
        "tfidf_model = TfidfVectorizer(tokenizer = casual_tokenize) \n",
        "tfidf_docs = tfidf_model.fit_transform(raw_documents=sms.text).toarray()\n",
        "tfidf_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyp21nwEyLex",
        "outputId": "832db270-c819-4ba1-d971-075956b36e48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4837, 9232)"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_docs.shape # 어휘의단어개수는 9232개, 전체 문자 메시지수의 약 두배이고, 스팸 메시지수의 약 15배"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_uiETjayajm",
        "outputId": "5b385bad-a2ef-44db-e914-ea2a5d66c3ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([False, False,  True, ..., False, False, False])"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask = sms.spam.astype(bool).values ; mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaOJdWucyNYg",
        "outputId": "fffc34f4-c300-4fab-f893-4303d60dfa8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sms0        0\n",
            "sms1        0\n",
            "sms2!       1\n",
            "sms3        0\n",
            "sms4        0\n",
            "           ..\n",
            "sms4832!    1\n",
            "sms4833     0\n",
            "sms4834     0\n",
            "sms4835     0\n",
            "sms4836     0\n",
            "Name: spam, Length: 4837, dtype: object\n"
          ]
        }
      ],
      "source": [
        " print(sms.spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUSvayfkykw5",
        "outputId": "6dbbeb3c-4292-453c-a508-603cf2eb7b0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.06377591, 0.0041675 , 0.00056204, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spam_centroid = tfidf_docs[mask].mean(axis=0) ; spam_centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMAGuyuXytME",
        "outputId": "92bf73b2-838c-4ffb-f9b2-988ff7b8e96f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.98493115e-02, 6.09435187e-03, 1.77747817e-04, ...,\n",
              "       6.31869803e-05, 6.31869803e-05, 6.31869803e-05])"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ham_centroid = tfidf_docs[~mask].mean(axis=0) ; ham_centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF-mvWheyxv3",
        "outputId": "94d3e1ec-8af9-4b77-d54c-0809f44f83c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.01469806, -0.02007376,  0.03856095, ..., -0.01014774,\n",
              "       -0.00344281,  0.00395752])"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spamminess_score = tfidf_docs.dot(spam_centroid - ham_centroid) ;spamminess_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqXxl54hA8KZ",
        "outputId": "fb21644a-9a40-4daa-e926-4d66f827e5ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.01469806]\n",
            " [-0.02007376]\n",
            " [ 0.03856095]\n",
            " ...\n",
            " [-0.01014774]\n",
            " [-0.00344281]\n",
            " [ 0.00395752]]\n",
            "(4837,)\n",
            "(4837, 1)\n"
          ]
        }
      ],
      "source": [
        "print(spamminess_score.reshape(-1,1)) # n -> nx1로 변환(차원하나 늘리기)\n",
        "print(spamminess_score.shape)\n",
        "print(spamminess_score.reshape(-1,1).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUmrgUoLy9Xf",
        "outputId": "dc27cab9-985c-4990-c3bd-da5b4a060891"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.01, -0.02,  0.04, ..., -0.01, -0.  ,  0.  ])"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spamminess_score.round(2) # 비스팸과 스팸 무게중심을 잇는 직선에 상대적인 각 벡터의 길이들을 담은 배열이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Dy-heaW8zD8K",
        "outputId": "cd5eecf3-7f6a-4843-f014-d0c005e59930"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6357e4df-1168-4522-ae8b-71fffc798cc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spam</th>\n",
              "      <th>lda_predict</th>\n",
              "      <th>lda_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sms0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms2!</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms5!</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6357e4df-1168-4522-ae8b-71fffc798cc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6357e4df-1168-4522-ae8b-71fffc798cc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6357e4df-1168-4522-ae8b-71fffc798cc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      spam  lda_predict  lda_score\n",
              "sms0     0            0       0.23\n",
              "sms1     0            0       0.18\n",
              "sms2!    1            1       0.72\n",
              "sms3     0            0       0.18\n",
              "sms4     0            0       0.29\n",
              "sms5!    1            1       0.55"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler \n",
        "sms['lda_score'] = MinMaxScaler().fit_transform(spamminess_score.reshape(-1,1))\n",
        "sms['lda_predict'] = (sms.lda_score> 0.5).astype(int) \n",
        "sms['spam lda_predict lda_score'.split()].round(2).head(6) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCblpTLVBYLx",
        "outputId": "342af70a-0803-4ee6-e33d-f898903d108d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9774653710977879"
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(1. - (sms.spam - sms.lda_predict).abs().sum() / len(sms))\n",
        "# 간단한 예제였지만 의미분석 접근 방식의 위력을 실감\n",
        "# 의미분석은 뜻이 비슷한 단어들을 모아서 함께 사용\n",
        "# 이 훈련 집합은 어휘가 작으며 영어사전에는 없는 단어들도 포함되어 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBNM1H_OBi3-",
        "outputId": "28eb0acf-98b3-4ef6-ad99-6c054626d0dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4837"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onnTA80ZCbDQ",
        "outputId": "eade5132-babc-4722-d46c-1ae666d71e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pugnlp in /usr/local/lib/python3.7/dist-packages (0.2.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pugnlp) (4.63.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from pugnlp) (21.1.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pugnlp) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pugnlp) (3.2.2)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (from pugnlp) (0.18.0)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.7/dist-packages (from pugnlp) (1.7.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pugnlp) (1.4.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from pugnlp) (6.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pugnlp) (1.0.2)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (from pugnlp) (0.12.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from pugnlp) (5.5.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from pugnlp) (1.0.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pugnlp) (0.11.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from pugnlp) (0.37.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pugnlp) (3.2.5)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from pugnlp) (3.7.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pugnlp) (3.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pugnlp) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->pugnlp) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim->pugnlp) (1.21.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pugnlp) (5.2.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->pugnlp) (7.6.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->pugnlp) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->pugnlp) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->pugnlp) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->pugnlp) (5.2.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->pugnlp) (5.2.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->pugnlp) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->pugnlp) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->pugnlp) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->pugnlp) (5.3.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->pugnlp) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->pugnlp) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->pugnlp) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->pugnlp) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->pugnlp) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->pugnlp) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->pugnlp) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->pugnlp) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->pugnlp) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->pugnlp) (1.0.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->pugnlp) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->pugnlp) (3.5.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (4.9.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (4.11.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->pugnlp) (3.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->pugnlp) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->pugnlp) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->pugnlp) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->pugnlp) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->pugnlp) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->pugnlp) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->pugnlp) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pugnlp) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pugnlp) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pugnlp) (1.3.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->pugnlp) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->pugnlp) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->pugnlp) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->pugnlp) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->pugnlp) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->pugnlp) (0.8.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->pugnlp) (21.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->pugnlp) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pugnlp) (2018.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->pugnlp) (8.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->pugnlp) (1.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->pugnlp) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pugnlp) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pugnlp) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pugnlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "zT5krbOtBpYn",
        "outputId": "e4b5dced-25ff-4b71-df8e-1db41ce90baf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pugnlp/stats.py:504: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  self.__setattr__('_hist_labels', self.sum().astype(int))\n",
            "/usr/local/lib/python3.7/dist-packages/pugnlp/stats.py:510: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  setattr(self, '_hist_classes', self.T.sum())\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4b1b7318-3627-459a-8598-b3db26ebbddc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>lda_predict</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4135</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b1b7318-3627-459a-8598-b3db26ebbddc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b1b7318-3627-459a-8598-b3db26ebbddc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b1b7318-3627-459a-8598-b3db26ebbddc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "lda_predict     0    1\n",
              "spam                  \n",
              "0            4135   64\n",
              "1              45  593"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pugnlp.stats import Confusion \n",
        "Confusion(sms['spam lda_predict'.split()]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3-JkjzACZxb"
      },
      "outputs": [],
      "source": [
        "#LDiA (잠재 디리클레 할당) : 단어 또는 문서의 의미를 표현하는 벡터를 생성하는데 사용\n",
        "# LSA의 수학을 다른방향으로 적용함\n",
        "# LDiA는 비선형 통계알고리즘을 이용해서 단어들을 그룹으로 묵음\n",
        "# 선형접근방식을 사용하는 LSA보다 대체적으로 훈련시간이 훨씬더 길다\n",
        "# LDiA가 산출하는 주제관련 통계량들이 단어와 주제에 대한 사람의 직관을 좀더 잘 반영할때가 있음\n",
        "# 문장요약에서 LDiA로 중심적인 문장들을 찾고 그 문장들을 연결해서 요약문을 생성함\n",
        "# 대부분의 회귀나 분류문제에서는 LSA알고리즘을 사용하는것이 대체로 낫다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qeMvQfLDTOo"
      },
      "outputs": [],
      "source": [
        "# LSA : SVD기법에 기초한 알고리즘, SVD를 활용해서 TF-IDF 행렬을 세 행렬로 분해함(큰 정수의 소인수 분해와 유사함)\n",
        "# SVD의 한용도는 행렬의 역을 구하는것, \n",
        "# TF-IDF 를 분해하면 원래의 TF-IDF행렬에 관한 유용한 정보를 얻을 수 있으며, 이를 이용해서 행렬을절단한 후 다시 결합해서 문서를 표현하는 벡터 공간의 차원을 줄임\n",
        "# LSA는 숨겨진 발견되길 기다리는 단어들의 의미를 드러냄\n",
        "# 절단된 SVD\n",
        "# LSA는 SVD를 이용해서 자료의 가장 큰 분산의 원인이되는 단어조합을 찾음\n",
        "# SVD는 최대분산 방향들을 수학적으로 찾아냄, (편향벡터)\n",
        "# TF-IDF 의 IDF 부분처럼LSA는 벡터의 어떤 차원이 문서의 의미에 중요한지 알려줌\n",
        "# LSA의 일반화와 압축의 과정은 불용어를 제거해서 얻는 장점과 비슷함\n",
        "# 차이는 LSA는 차원을 최적으로 축소하며, 어떤 단어도 제거하지 않으면서 정보를 최대한 유지함, 쓸모없는 차원만 폐기할뿐\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE9bsrz9f-YS"
      },
      "outputs": [],
      "source": [
        "from nlpia.book.examples.ch04_catdog_lsa_3x6x16 import word_topic_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "n9j5N2KEgDTm",
        "outputId": "cabac0e3-cd2b-4fae-fa68-7a1f29469557"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a495d461-a8df-408f-83ce-baac806e45fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>apple</th>\n",
              "      <th>lion</th>\n",
              "      <th>nyc</th>\n",
              "      <th>love</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>top0</th>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top1</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top2</th>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a495d461-a8df-408f-83ce-baac806e45fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a495d461-a8df-408f-83ce-baac806e45fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a495d461-a8df-408f-83ce-baac806e45fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      cat  dog  apple  lion  nyc  love\n",
              "top0 -0.6 -0.4    0.5  -0.3  0.4  -0.1\n",
              "top1 -0.1 -0.3   -0.4  -0.1  0.1   0.8\n",
              "top2 -0.3  0.8   -0.1  -0.5  0.0   0.1"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_topic_vectors.T.round(1) # 각 주제에 각 단어가 얼마나 관련이 있는지를 나타냄"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "Y187csftgItq",
        "outputId": "591abd10-9243-4ef5-caee-772f329bde13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 263/263 [00:00<00:00, 142611.76it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-162598e6-5d68-41d2-b920-cc04f9db1ad0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>dog</th>\n",
              "      <th>apple</th>\n",
              "      <th>lion</th>\n",
              "      <th>nyc</th>\n",
              "      <th>love</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>NYC is the Big Apple.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>NYC is known as the Big Apple.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>I love NYC!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>I wore a hat to the Big Apple party in NYC.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>Come to NYC. See the Big Apple!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Manhattan is called the Big Apple.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>New York is a big city for a small cat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>The lion, a big cat, is the king of the jungle.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>I love my pet cat.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>I love New York City (NYC).</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Your dog chased my cat.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-162598e6-5d68-41d2-b920-cc04f9db1ad0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-162598e6-5d68-41d2-b920-cc04f9db1ad0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-162598e6-5d68-41d2-b920-cc04f9db1ad0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   cat dog apple lion nyc love                                             text\n",
              "0              1        1                                 NYC is the Big Apple.\n",
              "1              1        1                        NYC is known as the Big Apple.\n",
              "2                       1    1                                      I love NYC!\n",
              "3              1        1           I wore a hat to the Big Apple party in NYC.\n",
              "4              1        1                       Come to NYC. See the Big Apple!\n",
              "5              1                             Manhattan is called the Big Apple.\n",
              "6    1                                  New York is a big city for a small cat.\n",
              "7    1              1           The lion, a big cat, is the king of the jungle.\n",
              "8    1                       1                               I love my pet cat.\n",
              "9                       1    1                      I love New York City (NYC).\n",
              "10   1   1                                              Your dog chased my cat."
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 특이값분해\n",
        "from nlpia.book.examples.ch04_catdog_lsa_sorted import lsa_models, prettify_tdm \n",
        "bow_svd, tfidf_svd = lsa_models() \n",
        "prettify_tdm(**bow_svd) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Y_izTwj8hem_",
        "outputId": "fea03716-3284-4887-a6fa-a4f2a02f164c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-61995fa4-2cb3-4490-be82-a468fdc257f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cat</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>apple</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lion</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nyc</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61995fa4-2cb3-4490-be82-a468fdc257f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61995fa4-2cb3-4490-be82-a468fdc257f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61995fa4-2cb3-4490-be82-a468fdc257f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0   1   2   3   4   5   6   7   8   9   10\n",
              "cat     0   0   0   0   0   0   1   1   1   0   1\n",
              "dog     0   0   0   0   0   0   0   0   0   0   1\n",
              "apple   1   1   0   1   1   1   0   0   0   0   0\n",
              "lion    0   0   0   0   0   0   0   1   0   0   0\n",
              "nyc     1   1   1   1   1   0   0   0   0   1   0\n",
              "love    0   0   1   0   0   0   0   0   1   1   0"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tdm = bow_svd['tdm'];tdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKgEngs0hliW"
      },
      "outputs": [],
      "source": [
        "# SVD는 용어 문서 행렬의 열들사이의 상관계수를 계산하여 공동 출현단어들을 찾음\n",
        "# 문서들 사이의 용어 빈도 상관관계와 문서들 사이의 상관관계도 파악함\n",
        "# 두가지를 파악해서 SVD는 말뭉치 전체에서 분산이 가장 큰 용어들의 일차결합들을 계산함\n",
        "# 이러한 용어들의 일차결합이 주제임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "JN1uKF_jkUio",
        "outputId": "7079003a-fa0c-4d42-f147-878a3dd45f3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e29d8cc3-79a8-4675-bd17-053170b03172\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cat</th>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.83</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.11</td>\n",
              "      <td>-0.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dog</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.21</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>apple</th>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.51</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lion</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.21</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>0.71</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nyc</th>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>-0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>-0.22</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e29d8cc3-79a8-4675-bd17-053170b03172')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e29d8cc3-79a8-4675-bd17-053170b03172 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e29d8cc3-79a8-4675-bd17-053170b03172');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          0     1     2     3     4     5\n",
              "cat   -0.04  0.83 -0.38 -0.00  0.11 -0.38\n",
              "dog   -0.00  0.21 -0.18 -0.71 -0.39  0.52\n",
              "apple -0.62 -0.21 -0.51  0.00  0.49  0.27\n",
              "lion  -0.00  0.21 -0.18  0.71 -0.39  0.52\n",
              "nyc   -0.75  0.00  0.24 -0.00 -0.52 -0.32\n",
              "love  -0.22  0.42  0.69  0.00  0.41  0.37"
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "U,s,Vt = np.linalg.svd(tdm) \n",
        "import pandas as pd  \n",
        "pd.DataFrame(U, index=tdm.index).round(2)\n",
        "# 행렬 U의 각열은 말뭉치의 각 단어의 주제벡터임\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATrb-WP9kclT",
        "outputId": "f4b5a278-bf3d-400b-cb7a-1837116ba20d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3.1, 2.2, 1.8, 1. , 0.8, 0.5])"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 특이값행렬 S : 주제의 특잇값들로 이루어진 대각행렬\n",
        "# 주제벡터공간의 각 차원이 얼마나 많은 정보를 담고있는지를 말해줌\n",
        "s.round(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU6dTcvTlCjr",
        "outputId": "d13f98c2-4b75-4fa2-9d7f-4925fc27b1b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "S= np.zeros((len(U), len(Vt))) ;S\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "NSZeMCtQlMw7",
        "outputId": "c1bfbfbe-111c-4c49-abb0-6b02b685b8c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8cc88e61-9f6a-4075-a475-e1792892e758\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cc88e61-9f6a-4075-a475-e1792892e758')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cc88e61-9f6a-4075-a475-e1792892e758 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cc88e61-9f6a-4075-a475-e1792892e758');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    0    1    2    3    4    5    6    7    8    9    10\n",
              "0  3.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "1  0.0  2.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.0  1.8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0  0.8  0.0  0.0  0.0  0.0  0.0  0.0\n",
              "5  0.0  0.0  0.0  0.0  0.0  0.5  0.0  0.0  0.0  0.0  0.0"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.np.fill_diagonal(S, s) \n",
        "pd.DataFrame(S).round(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V32KyDCldSt"
      },
      "outputs": [],
      "source": [
        "# 행렬 Vt는 오른쪽 특이벡터들이 열벡터들인 문서-문서 행렬\n",
        "# 각 성분은 새 문서의미 모형에서 문서들이 같은 주제를 얼마나 자주 사용하는지를 나타냄\n",
        "# 이 행렬은 문서들 사이의 의미 공유정도를 말해줌\n",
        "# 행수는 주제의수 p, 열수는 말뭉치의 문서수 n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A55G-rAcmLMS"
      },
      "outputs": [],
      "source": [
        "# 주제 절단\n",
        "# 지금까지는 주제의 수가 단어의 수와 같음 : 차원은 전혀 줄어들지 않음\n",
        "err = []\n",
        "for numdim in range(len(s), 0, -1):\n",
        "  S[numdim -1, numdim -1] = 0 \n",
        "  reconstructed_tdm = U.dot(S).dot(Vt) \n",
        "  err.append(np.sqrt(((reconstructed_tdm - tdm).values.flatten() **2).sum() / np.product(tdm.shape)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8q6bxBtmwRe",
        "outputId": "c9da285c-2d7b-4481-8c8d-b90fd0e13b77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.06, 0.12, 0.17, 0.28, 0.39, 0.55])"
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(err).round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzqTY2t5WZmc"
      },
      "outputs": [],
      "source": [
        "# 주성분 분석 (PCA) \n",
        "# 사실 SVD의 다른이름\n",
        "# sklearn.decomposition.PCA : 중심화수행됨 + 백화기능\n",
        "# 백화기능 :  단어문서 벡터를 주제 문서벡터로 변환할때 특잇값들을 무시하는것과 비슷한 요령\n",
        "# 자료를 분산 값들을 이용해서 분리함, 이렇게 하면 자료가 좀더 넓게 퍼져서 최적화 알고리즘이 자료공간의 하프파이프 또는 계곡에서 벗어나지 못하는 문제가 줄어듬\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "iq8S0XWqX2dk",
        "outputId": "7aa8e929-e40d-4ec1-b6f5-269704805412"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 6) # 지면에 맞게 출력\n",
        "from sklearn.decomposition import PCA  \n",
        "import seaborn   \n",
        "from matplotlib import pyplot as plt \n",
        "from nlpia.data.loaders import get_data   \n",
        "\n",
        "df = get_data('pointcloud').sample(1000)\n",
        "pca = PCA(n_components=2) \n",
        "df2d = pd.DataFrame(pca.fit_transform(df) , columns = list('xy')) \n",
        "df2d.plot(kind='scatter', x='x',y='y') \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "jZRfM6Y-YG1a",
        "outputId": "4ccf14b6-4daf-4be7-8abd-fe9035836465"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-52f64dfc-e17f-4f02-8953-a77e74fc92ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only in bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52f64dfc-e17f-4f02-8953-a77e74fc92ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52f64dfc-e17f-4f02-8953-a77e74fc92ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52f64dfc-e17f-4f02-8953-a77e74fc92ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   spam                                                    text\n",
              "0     0  Go until jurong point, crazy.. Available only in bu...\n",
              "1     0                           Ok lar... Joking wif u oni...\n",
              "2     1  Free entry in 2 a wkly comp to win FA Cup final tkt..."
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# nlp에 svd적용하기\n",
        "# 실제 예제 : 5000개의 문자/스팸 구분\n",
        "import pandas as pd \n",
        "from nlpia.data.loaders import get_data   \n",
        "pd.options.display.width = 120 \n",
        "sms = get_data('sms-spam') \n",
        "index  =  ['sms{}{}'.format(i, '!'*j) for (i,j) in zip(range(len(sms)), sms.spam)]\n",
        "sms.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "QgTV_1-EZR8Q",
        "outputId": "0265cfd0-dfd4-4f92-fd2b-ae06817cf65f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2e0b1ece-0101-4d75-9321-70ee6de978c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spam</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sms0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only in bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms2!</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkt...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e0b1ece-0101-4d75-9321-70ee6de978c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e0b1ece-0101-4d75-9321-70ee6de978c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e0b1ece-0101-4d75-9321-70ee6de978c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       spam                                                    text\n",
              "sms0      0  Go until jurong point, crazy.. Available only in bu...\n",
              "sms1      0                           Ok lar... Joking wif u oni...\n",
              "sms2!     1  Free entry in 2 a wkly comp to win FA Cup final tkt..."
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sms.index = index \n",
        "\n",
        "sms.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4R-kx8wZnAM",
        "outputId": "72ef464a-d660-489a-e581-b0a4d4f8d9bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 각 메시지의 tf-idf 벡터 계산\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer   \n",
        "from nltk.tokenize.casual import casual_tokenize   \n",
        "tfidf = TfidfVectorizer(tokenizer = casual_tokenize)  # 9232개의 서로 다른 1그램 토큰을 추출함\n",
        "tfidf_docs = tfidf.fit_transform(raw_documents = sms.text).toarray()  ; tfidf_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMBSUx5AaAXn",
        "outputId": "7774a3bd-29ff-4f44-84e1-7ed34d8d2dc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9232"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tfidf.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR9T-udfaC37",
        "outputId": "880e5619-cb28-4519-e3fc-bfc983ef28ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4837, 9232)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_docs = pd.DataFrame(tfidf_docs)  \n",
        "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
        "tfidf_docs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dzvRZGYaHP0",
        "outputId": "79397f56-7a59-4d38-f07d-88653c1eb882"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "638"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sms.spam.sum() # 스팸은 총 638개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIiJqjQiaIVl"
      },
      "outputs": [],
      "source": [
        "# 과대적합의 가능성이 보임 : 스팸필터가 적은수의 익숙한 단어들에만 의존하는것 \n",
        "# 차원축소는 과대적합에 대한 주된 대응책이다. 수많은 단어를 그보다 적은수의 주제들로 통합함으로써 차원이 줄어들며, 결과적으로 nlp파이프라인이 좀더 일반화됨\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "c_5y3fJxcuIh",
        "outputId": "d65058e9-ac31-46b6-d5a3-f3fe48466131"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e76dd40-fe7b-4e13-a03f-dda0b1665147\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic0</th>\n",
              "      <th>topic1</th>\n",
              "      <th>topic2</th>\n",
              "      <th>...</th>\n",
              "      <th>topic13</th>\n",
              "      <th>topic14</th>\n",
              "      <th>topic15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sms0</th>\n",
              "      <td>0.201</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.037</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.036</td>\n",
              "      <td>-0.012</td>\n",
              "      <td>0.043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms1</th>\n",
              "      <td>0.404</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>-0.078</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.055</td>\n",
              "      <td>-0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms2!</th>\n",
              "      <td>-0.030</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>0.090</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>-0.042</td>\n",
              "      <td>0.063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms3</th>\n",
              "      <td>0.329</td>\n",
              "      <td>-0.033</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039</td>\n",
              "      <td>0.021</td>\n",
              "      <td>-0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4</th>\n",
              "      <td>0.002</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>-0.016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms5!</th>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.014</td>\n",
              "      <td>...</td>\n",
              "      <td>0.070</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>-0.030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e76dd40-fe7b-4e13-a03f-dda0b1665147')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e76dd40-fe7b-4e13-a03f-dda0b1665147 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e76dd40-fe7b-4e13-a03f-dda0b1665147');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       topic0  topic1  topic2  ...  topic13  topic14  topic15\n",
              "sms0    0.201   0.003   0.037  ...   -0.036   -0.012    0.043\n",
              "sms1    0.404  -0.094  -0.078  ...   -0.020    0.055   -0.020\n",
              "sms2!  -0.030  -0.048   0.090  ...   -0.018   -0.042    0.063\n",
              "sms3    0.329  -0.033  -0.035  ...   -0.039    0.021   -0.087\n",
              "sms4    0.002   0.031   0.038  ...    0.030   -0.083   -0.016\n",
              "sms5!  -0.016   0.059   0.014  ...    0.070   -0.005   -0.030\n",
              "\n",
              "[6 rows x 16 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pca를 이용한 문자 메시지 잠재의미분석\n",
        "# 9232차원의 tfidf벡터를 16차원의 주제벡터들로 줄이는데 pca모형을 사용\n",
        "from sklearn.decomposition import PCA \n",
        "\n",
        "pca = PCA(n_components = 16) \n",
        "pca = pca.fit(tfidf_docs)  \n",
        "pca_topic_vectors  =  pca.transform(tfidf_docs)   \n",
        "columns = ['topic{}'.format(i) for i in range(pca.n_components)]  \n",
        "pca_topic_vectors = pd.DataFrame(pca_topic_vectors  ,  columns = columns , index= index )   \n",
        "pca_topic_vectors.round(3).head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFgXGgmadUJV",
        "outputId": "407d716c-5328-4eec-d179-171135e3a374"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'go': 3807,\n",
              " 'until': 8487,\n",
              " 'jurong': 4675,\n",
              " 'point': 6296,\n",
              " ',': 13,\n",
              " 'crazy': 2549,\n",
              " '..': 21,\n",
              " 'available': 1531,\n",
              " 'only': 5910,\n",
              " 'in': 4396,\n",
              " 'bugis': 1973,\n",
              " 'n': 5594,\n",
              " 'great': 3894,\n",
              " 'world': 8977,\n",
              " 'la': 4811,\n",
              " 'e': 3056,\n",
              " 'buffet': 1971,\n",
              " '...': 25,\n",
              " 'cine': 2277,\n",
              " 'there': 8071,\n",
              " 'got': 3855,\n",
              " 'amore': 1296,\n",
              " 'wat': 8736,\n",
              " 'ok': 5874,\n",
              " 'lar': 4848,\n",
              " 'joking': 4642,\n",
              " 'wif': 8875,\n",
              " 'u': 8395,\n",
              " 'oni': 5906,\n",
              " 'free': 3604,\n",
              " 'entry': 3195,\n",
              " '2': 471,\n",
              " 'a': 1054,\n",
              " 'wkly': 8933,\n",
              " 'comp': 2386,\n",
              " 'to': 8192,\n",
              " 'win': 8890,\n",
              " 'fa': 3328,\n",
              " 'cup': 2608,\n",
              " 'final': 3450,\n",
              " 'tkts': 8180,\n",
              " '21st': 497,\n",
              " 'may': 5272,\n",
              " '2005': 487,\n",
              " '.': 15,\n",
              " 'text': 8020,\n",
              " '87121': 948,\n",
              " 'receive': 6688,\n",
              " 'question': 6574,\n",
              " '(': 9,\n",
              " 'std': 7651,\n",
              " 'txt': 8379,\n",
              " 'rate': 6628,\n",
              " ')': 10,\n",
              " 't': 7889,\n",
              " '&': 7,\n",
              " \"c's\": 2020,\n",
              " 'apply': 1383,\n",
              " '08452810075': 115,\n",
              " 'over': 6003,\n",
              " '18': 438,\n",
              " \"'\": 8,\n",
              " 's': 6959,\n",
              " 'dun': 3041,\n",
              " 'say': 7034,\n",
              " 'so': 7438,\n",
              " 'early': 3069,\n",
              " 'hor': 4207,\n",
              " 'c': 2019,\n",
              " 'already': 1268,\n",
              " 'then': 8065,\n",
              " 'nah': 5606,\n",
              " 'i': 4311,\n",
              " \"don't\": 2948,\n",
              " 'think': 8092,\n",
              " 'he': 4048,\n",
              " 'goes': 3819,\n",
              " 'usf': 8537,\n",
              " 'lives': 5004,\n",
              " 'around': 1435,\n",
              " 'here': 4104,\n",
              " 'though': 8111,\n",
              " 'freemsg': 3613,\n",
              " 'hey': 4116,\n",
              " 'darling': 2666,\n",
              " \"it's\": 4535,\n",
              " 'been': 1693,\n",
              " '3': 591,\n",
              " \"week's\": 8788,\n",
              " 'now': 5784,\n",
              " 'and': 1310,\n",
              " 'no': 5732,\n",
              " 'word': 8967,\n",
              " 'back': 1584,\n",
              " '!': 0,\n",
              " \"i'd\": 4312,\n",
              " 'like': 4954,\n",
              " 'some': 7454,\n",
              " 'fun': 3677,\n",
              " 'you': 9158,\n",
              " 'up': 8489,\n",
              " 'for': 3552,\n",
              " 'it': 4533,\n",
              " 'still': 7674,\n",
              " '?': 1037,\n",
              " 'tb': 7955,\n",
              " 'xxx': 9097,\n",
              " 'chgs': 2230,\n",
              " 'send': 7127,\n",
              " '£': 9216,\n",
              " '1.50': 344,\n",
              " 'rcv': 6641,\n",
              " 'even': 3240,\n",
              " 'my': 5584,\n",
              " 'brother': 1942,\n",
              " 'is': 4519,\n",
              " 'not': 5769,\n",
              " 'speak': 7529,\n",
              " 'with': 8918,\n",
              " 'me': 5281,\n",
              " 'they': 8083,\n",
              " 'treat': 8312,\n",
              " 'aids': 1214,\n",
              " 'patent': 6106,\n",
              " 'as': 1452,\n",
              " 'per': 6148,\n",
              " 'your': 9171,\n",
              " 'request': 6796,\n",
              " 'melle': 5315,\n",
              " 'oru': 5968,\n",
              " 'minnaminunginte': 5386,\n",
              " 'nurungu': 5807,\n",
              " 'vettam': 8599,\n",
              " 'has': 4022,\n",
              " 'set': 7154,\n",
              " 'callertune': 2047,\n",
              " 'all': 1253,\n",
              " 'callers': 2046,\n",
              " 'press': 6418,\n",
              " '*': 11,\n",
              " '9': 982,\n",
              " 'copy': 2489,\n",
              " 'friends': 3634,\n",
              " 'winner': 8900,\n",
              " 'valued': 8569,\n",
              " 'network': 5678,\n",
              " 'customer': 2620,\n",
              " 'have': 4036,\n",
              " 'selected': 7113,\n",
              " 'receivea': 6689,\n",
              " '900': 986,\n",
              " 'prize': 6450,\n",
              " 'reward': 6851,\n",
              " 'claim': 2283,\n",
              " 'call': 2038,\n",
              " '09061701461': 263,\n",
              " 'code': 2344,\n",
              " 'kl341': 4771,\n",
              " 'valid': 8565,\n",
              " '12': 384,\n",
              " 'hours': 4226,\n",
              " 'had': 3965,\n",
              " 'mobile': 5441,\n",
              " '11': 371,\n",
              " 'months': 5484,\n",
              " 'or': 5946,\n",
              " 'more': 5489,\n",
              " 'r': 6590,\n",
              " 'entitled': 3192,\n",
              " 'update': 8495,\n",
              " 'the': 8052,\n",
              " 'latest': 4862,\n",
              " 'colour': 2364,\n",
              " 'mobiles': 5442,\n",
              " 'camera': 2058,\n",
              " 'co': 2333,\n",
              " 'on': 5897,\n",
              " '08002986030': 99,\n",
              " \"i'm\": 4314,\n",
              " 'gonna': 3834,\n",
              " 'be': 1669,\n",
              " 'home': 4176,\n",
              " 'soon': 7483,\n",
              " 'want': 8715,\n",
              " 'talk': 7921,\n",
              " 'about': 1076,\n",
              " 'this': 8100,\n",
              " 'stuff': 7741,\n",
              " 'anymore': 1350,\n",
              " 'tonight': 8235,\n",
              " 'k': 4683,\n",
              " \"i've\": 4316,\n",
              " 'cried': 2566,\n",
              " 'enough': 3182,\n",
              " 'today': 8199,\n",
              " 'six': 7341,\n",
              " 'chances': 2172,\n",
              " 'cash': 2116,\n",
              " 'from': 3652,\n",
              " '100': 354,\n",
              " '20,000': 482,\n",
              " 'pounds': 6357,\n",
              " '>': 1035,\n",
              " 'csh': 2584,\n",
              " '87575': 952,\n",
              " 'cost': 2501,\n",
              " '150p': 415,\n",
              " '/': 27,\n",
              " 'day': 2683,\n",
              " '6days': 827,\n",
              " '16': 431,\n",
              " '+': 12,\n",
              " 'tsandcs': 8344,\n",
              " 'reply': 6788,\n",
              " 'hl': 4148,\n",
              " '4': 659,\n",
              " 'info': 4433,\n",
              " 'urgent': 8513,\n",
              " 'won': 8950,\n",
              " '1': 337,\n",
              " 'week': 8787,\n",
              " 'membership': 5321,\n",
              " 'our': 5980,\n",
              " '100,000': 355,\n",
              " 'jackpot': 4564,\n",
              " ':': 1006,\n",
              " '81010': 900,\n",
              " 'www.dbuk.net': 9039,\n",
              " 'lccltd': 4880,\n",
              " 'pobox': 6286,\n",
              " '4403ldnw1a7rw18': 696,\n",
              " 'searching': 7081,\n",
              " 'right': 6863,\n",
              " 'words': 8968,\n",
              " 'thank': 8037,\n",
              " 'breather': 1912,\n",
              " 'promise': 6487,\n",
              " 'wont': 8958,\n",
              " 'take': 7913,\n",
              " 'help': 4089,\n",
              " 'granted': 3883,\n",
              " 'will': 8887,\n",
              " 'fulfil': 3673,\n",
              " 'wonderful': 8955,\n",
              " 'blessing': 1802,\n",
              " 'at': 1488,\n",
              " 'times': 8158,\n",
              " 'date': 2675,\n",
              " 'sunday': 7805,\n",
              " 'xxxmobilemovieclub': 9098,\n",
              " 'use': 8531,\n",
              " 'credit': 2556,\n",
              " 'click': 2306,\n",
              " 'wap': 8719,\n",
              " 'link': 4977,\n",
              " 'next': 5696,\n",
              " 'message': 5340,\n",
              " 'http://wap': 4259,\n",
              " 'xxxmobilemovieclub.com': 9099,\n",
              " '=': 1031,\n",
              " 'qjkgighjjgcbl': 6566,\n",
              " 'oh': 5869,\n",
              " 'watching': 8743,\n",
              " ':)': 1008,\n",
              " 'eh': 3116,\n",
              " 'remember': 6755,\n",
              " 'how': 4233,\n",
              " 'spell': 7545,\n",
              " 'his': 4139,\n",
              " 'name': 5612,\n",
              " 'yes': 9137,\n",
              " 'did': 2823,\n",
              " 'v': 8553,\n",
              " 'naughty': 5635,\n",
              " 'make': 5193,\n",
              " 'wet': 8828,\n",
              " 'fine': 3458,\n",
              " 'if': 4350,\n",
              " 'that': 8045,\n",
              " '\\x92': 9211,\n",
              " 'way': 8753,\n",
              " 'feel': 3400,\n",
              " 'its': 4546,\n",
              " 'gota': 3856,\n",
              " 'b': 1560,\n",
              " 'england': 3173,\n",
              " 'macedonia': 5156,\n",
              " '-': 14,\n",
              " 'dont': 2952,\n",
              " 'miss': 5402,\n",
              " 'goals': 3812,\n",
              " 'team': 7968,\n",
              " 'news': 5692,\n",
              " 'ur': 8510,\n",
              " 'national': 5629,\n",
              " '87077': 947,\n",
              " 'eg': 3109,\n",
              " 'try': 8340,\n",
              " 'wales': 8695,\n",
              " 'scotland': 7060,\n",
              " '4txt': 737,\n",
              " 'ú1': 9220,\n",
              " '20': 481,\n",
              " 'poboxox': 6287,\n",
              " '36504w45wq': 629,\n",
              " 'seriously': 7147,\n",
              " '‘': 9225,\n",
              " 'm': 5139,\n",
              " 'going': 3823,\n",
              " 'ha': 3961,\n",
              " 'ü': 9221,\n",
              " 'pay': 6119,\n",
              " 'first': 3476,\n",
              " 'when': 8840,\n",
              " 'da': 2639,\n",
              " 'stock': 7678,\n",
              " 'comin': 2376,\n",
              " 'aft': 1182,\n",
              " 'finish': 3462,\n",
              " 'lunch': 5121,\n",
              " 'str': 7702,\n",
              " 'down': 2974,\n",
              " 'lor': 5058,\n",
              " 'ard': 1410,\n",
              " 'smth': 7422,\n",
              " 'ffffffffff': 3420,\n",
              " 'alright': 1269,\n",
              " 'can': 2062,\n",
              " 'meet': 5303,\n",
              " 'sooner': 7485,\n",
              " 'just': 4677,\n",
              " 'forced': 3554,\n",
              " 'myself': 5591,\n",
              " 'eat': 3081,\n",
              " 'slice': 7372,\n",
              " 'really': 6670,\n",
              " 'hungry': 4287,\n",
              " 'tho': 8107,\n",
              " 'sucks': 7778,\n",
              " 'mark': 5230,\n",
              " 'getting': 3767,\n",
              " 'worried': 8981,\n",
              " 'knows': 4782,\n",
              " 'sick': 7289,\n",
              " 'turn': 8362,\n",
              " 'pizza': 6238,\n",
              " 'lol': 5035,\n",
              " 'always': 1279,\n",
              " 'convincing': 2476,\n",
              " 'catch': 2128,\n",
              " 'bus': 1993,\n",
              " 'are': 1411,\n",
              " 'frying': 3660,\n",
              " 'an': 1305,\n",
              " 'egg': 3111,\n",
              " 'tea': 7962,\n",
              " 'eating': 3084,\n",
              " \"mom's\": 5463,\n",
              " 'left': 4901,\n",
              " 'dinner': 2858,\n",
              " 'do': 2909,\n",
              " 'love': 5081,\n",
              " \"we're\": 8760,\n",
              " 'packing': 6032,\n",
              " 'car': 2085,\n",
              " \"i'll\": 4313,\n",
              " 'let': 4923,\n",
              " 'know': 4779,\n",
              " \"there's\": 8074,\n",
              " 'room': 6906,\n",
              " 'ahhh': 1209,\n",
              " 'work': 8970,\n",
              " 'vaguely': 8560,\n",
              " 'what': 8832,\n",
              " 'does': 2923,\n",
              " 'wait': 8689,\n",
              " \"that's\": 8048,\n",
              " 'clear': 2300,\n",
              " 'were': 8817,\n",
              " 'sure': 7832,\n",
              " 'being': 1713,\n",
              " 'sarcastic': 7010,\n",
              " 'why': 8868,\n",
              " 'x': 9076,\n",
              " \"doesn't\": 2926,\n",
              " 'live': 5000,\n",
              " 'us': 8525,\n",
              " 'yeah': 9125,\n",
              " 'was': 8728,\n",
              " 'apologetic': 1371,\n",
              " 'fallen': 3352,\n",
              " 'out': 5983,\n",
              " 'she': 7199,\n",
              " 'actin': 1123,\n",
              " 'spoilt': 7572,\n",
              " 'child': 2238,\n",
              " 'caught': 2132,\n",
              " 'till': 8152,\n",
              " 'but': 1999,\n",
              " 'we': 8757,\n",
              " \"won't\": 8951,\n",
              " 'doing': 2938,\n",
              " 'too': 8242,\n",
              " 'badly': 1589,\n",
              " 'cheers': 2214,\n",
              " 'tell': 7985,\n",
              " 'anything': 1356,\n",
              " 'fear': 3391,\n",
              " 'of': 5847,\n",
              " 'fainting': 3344,\n",
              " 'housework': 4231,\n",
              " 'quick': 6577,\n",
              " 'cuppa': 2610,\n",
              " 'thanks': 8038,\n",
              " 'subscription': 7766,\n",
              " 'ringtone': 6872,\n",
              " 'uk': 8415,\n",
              " 'charged': 2184,\n",
              " '5': 745,\n",
              " 'month': 5479,\n",
              " 'please': 6265,\n",
              " 'confirm': 2431,\n",
              " 'by': 2016,\n",
              " 'replying': 6790,\n",
              " 'yup': 9192,\n",
              " 'look': 5046,\n",
              " 'timings': 8162,\n",
              " 'msg': 5528,\n",
              " 'again': 1190,\n",
              " 'xuhui': 9093,\n",
              " 'learn': 4892,\n",
              " '2nd': 567,\n",
              " 'her': 4099,\n",
              " 'lesson': 4921,\n",
              " '8am': 974,\n",
              " 'oops': 5921,\n",
              " \"roommate's\": 6909,\n",
              " 'done': 2950,\n",
              " 'see': 7098,\n",
              " 'letter': 4926,\n",
              " 'decide': 2711,\n",
              " 'hello': 4084,\n",
              " \"how's\": 4235,\n",
              " 'saturday': 7024,\n",
              " 'texting': 8027,\n",
              " \"you'd\": 9159,\n",
              " 'decided': 2712,\n",
              " 'tomo': 8224,\n",
              " 'trying': 8342,\n",
              " 'invite': 4493,\n",
              " 'pls': 6273,\n",
              " 'ahead': 1208,\n",
              " 'watts': 8751,\n",
              " 'wanted': 8716,\n",
              " 'weekend': 8791,\n",
              " 'abiola': 1072,\n",
              " 'forget': 3560,\n",
              " 'need': 5654,\n",
              " 'crave': 2546,\n",
              " 'most': 5499,\n",
              " 'sweet': 7863,\n",
              " 'arabian': 1407,\n",
              " 'steed': 7658,\n",
              " 'mmmmmm': 5431,\n",
              " 'yummy': 9187,\n",
              " '07732584351': 62,\n",
              " 'rodger': 6895,\n",
              " 'burns': 1990,\n",
              " 'tried': 8321,\n",
              " 're': 6645,\n",
              " 'sms': 7416,\n",
              " 'nokia': 5744,\n",
              " 'camcorder': 2056,\n",
              " '08000930705': 95,\n",
              " 'delivery': 2750,\n",
              " 'tomorrow': 8226,\n",
              " 'who': 8859,\n",
              " 'seeing': 7101,\n",
              " 'hope': 4198,\n",
              " 'man': 5203,\n",
              " 'well': 8807,\n",
              " 'endowed': 3163,\n",
              " 'am': 1281,\n",
              " '<#>': 1024,\n",
              " 'inches': 4401,\n",
              " 'calls': 2053,\n",
              " 'messages': 5344,\n",
              " 'missed': 5405,\n",
              " \"didn't\": 2828,\n",
              " 'get': 3760,\n",
              " 'hep': 4098,\n",
              " 'immunisation': 4379,\n",
              " 'nigeria': 5708,\n",
              " 'fair': 3345,\n",
              " 'hopefully': 4201,\n",
              " 'tyler': 8389,\n",
              " \"can't\": 2063,\n",
              " 'could': 2511,\n",
              " 'maybe': 5274,\n",
              " 'ask': 1463,\n",
              " 'bit': 1779,\n",
              " 'stubborn': 7730,\n",
              " 'hospital': 4214,\n",
              " 'kept': 4730,\n",
              " 'telling': 7986,\n",
              " 'weak': 8762,\n",
              " 'sucker': 7776,\n",
              " 'hospitals': 4215,\n",
              " 'suckers': 7777,\n",
              " 'thinked': 8093,\n",
              " 'time': 8154,\n",
              " 'saw': 7033,\n",
              " 'class': 2292,\n",
              " 'gram': 3875,\n",
              " 'usually': 8543,\n",
              " 'runs': 6949,\n",
              " 'half': 3977,\n",
              " 'eighth': 3119,\n",
              " 'smarter': 7395,\n",
              " 'gets': 3763,\n",
              " 'almost': 1264,\n",
              " 'whole': 8862,\n",
              " 'second': 7085,\n",
              " 'fyi': 3693,\n",
              " 'ride': 6862,\n",
              " 'morning': 5493,\n",
              " \"he's\": 4050,\n",
              " 'crashing': 2545,\n",
              " 'place': 6240,\n",
              " 'wow': 8997,\n",
              " 'never': 5683,\n",
              " 'realized': 6668,\n",
              " 'embarassed': 3144,\n",
              " 'accomodations': 1103,\n",
              " 'thought': 8112,\n",
              " 'liked': 4955,\n",
              " 'since': 7314,\n",
              " 'best': 1733,\n",
              " 'seemed': 7105,\n",
              " 'happy': 4011,\n",
              " '\"': 1,\n",
              " 'cave': 2136,\n",
              " 'sorry': 7494,\n",
              " 'give': 3788,\n",
              " 'offered': 5855,\n",
              " 'embarassing': 3145,\n",
              " 'ac': 1089,\n",
              " 'sptv': 7594,\n",
              " 'new': 5687,\n",
              " 'jersey': 4608,\n",
              " 'devils': 2803,\n",
              " 'detroit': 2797,\n",
              " 'red': 6711,\n",
              " 'wings': 8898,\n",
              " 'play': 6255,\n",
              " 'ice': 4330,\n",
              " 'hockey': 4161,\n",
              " 'correct': 2494,\n",
              " 'incorrect': 4412,\n",
              " 'end': 3158,\n",
              " 'mallika': 5202,\n",
              " 'sherawat': 7208,\n",
              " 'yesterday': 9141,\n",
              " 'find': 3455,\n",
              " '@': 1038,\n",
              " '<url>': 1030,\n",
              " 'congrats': 2437,\n",
              " 'year': 9126,\n",
              " 'special': 7531,\n",
              " 'cinema': 2278,\n",
              " 'pass': 6094,\n",
              " 'yours': 9176,\n",
              " '09061209465': 258,\n",
              " 'suprman': 7830,\n",
              " 'matrix': 5263,\n",
              " 'starwars': 7638,\n",
              " 'etc': 3230,\n",
              " 'bx420': 2014,\n",
              " 'ip4': 4502,\n",
              " '5we': 781,\n",
              " '150pm': 417,\n",
              " 'later': 4861,\n",
              " 'meeting': 5305,\n",
              " 'where': 8846,\n",
              " 'reached': 6652,\n",
              " 'gauti': 3728,\n",
              " 'sehwag': 7110,\n",
              " 'odi': 5846,\n",
              " 'series': 7145,\n",
              " 'pick': 6211,\n",
              " '$': 5,\n",
              " 'burger': 1985,\n",
              " 'yourself': 9177,\n",
              " 'move': 5513,\n",
              " 'pain': 6039,\n",
              " 'killing': 4754,\n",
              " 'good': 3836,\n",
              " 'joke': 4636,\n",
              " 'girls': 3785,\n",
              " 'situation': 7338,\n",
              " 'seekers': 7102,\n",
              " 'part': 6081,\n",
              " 'checking': 2208,\n",
              " 'iq': 4508,\n",
              " 'roommates': 6910,\n",
              " 'took': 8245,\n",
              " 'forever': 3557,\n",
              " 'come': 2371,\n",
              " 'double': 2966,\n",
              " 'check': 2204,\n",
              " 'hair': 3972,\n",
              " 'dresser': 2998,\n",
              " 'said': 6980,\n",
              " 'wun': 9024,\n",
              " 'cut': 2624,\n",
              " 'short': 7248,\n",
              " 'nice': 5701,\n",
              " 'pleased': 6266,\n",
              " 'advise': 1165,\n",
              " 'following': 3534,\n",
              " 'recent': 6692,\n",
              " 'review': 6849,\n",
              " 'mob': 5439,\n",
              " 'awarded': 1549,\n",
              " '1500': 414,\n",
              " 'bonus': 1844,\n",
              " '09066364589': 306,\n",
              " 'song': 7478,\n",
              " 'dedicated': 2722,\n",
              " 'which': 8853,\n",
              " 'dedicate': 2721,\n",
              " 'valuable': 8566,\n",
              " 'frnds': 3643,\n",
              " 'rply': 6925,\n",
              " 'complimentary': 2406,\n",
              " 'trip': 8322,\n",
              " 'eurodisinc': 3234,\n",
              " 'trav': 8304,\n",
              " 'aco': 1119,\n",
              " '41': 679,\n",
              " '1000': 356,\n",
              " 'dis': 2871,\n",
              " '6': 785,\n",
              " 'morefrmmob': 5490,\n",
              " 'shracomorsglsuplt': 7273,\n",
              " '10': 350,\n",
              " 'ls1': 5103,\n",
              " '3aj': 638,\n",
              " 'hear': 4062,\n",
              " 'divorce': 2900,\n",
              " 'barbie': 1620,\n",
              " 'comes': 2373,\n",
              " \"ken's\": 4728,\n",
              " 'plane': 6247,\n",
              " 'wah': 8682,\n",
              " 'lucky': 5114,\n",
              " 'save': 7029,\n",
              " 'money': 5470,\n",
              " 'hee': 4075,\n",
              " 'finished': 3464,\n",
              " 'hi': 4120,\n",
              " 'babe': 1574,\n",
              " 'im': 4368,\n",
              " 'wanna': 8713,\n",
              " 'something': 7464,\n",
              " 'xx': 9094,\n",
              " 'performed': 6155,\n",
              " 'waiting': 8692,\n",
              " 'machan': 5158,\n",
              " 'once': 5901,\n",
              " 'thats': 8051,\n",
              " 'cool': 2481,\n",
              " 'gentleman': 3751,\n",
              " 'dignity': 2848,\n",
              " 'respect': 6816,\n",
              " 'peoples': 6147,\n",
              " 'very': 8598,\n",
              " 'much': 5544,\n",
              " 'shy': 7283,\n",
              " 'pa': 6027,\n",
              " 'operate': 5928,\n",
              " 'after': 1183,\n",
              " 'same': 6996,\n",
              " 'looking': 5050,\n",
              " 'job': 4623,\n",
              " \"ta's\": 7896,\n",
              " 'earn': 3070,\n",
              " 'ah': 1204,\n",
              " 'stop': 7688,\n",
              " 'urgnt': 8517,\n",
              " 'real': 6662,\n",
              " 'yo': 9152,\n",
              " 'tickets': 8142,\n",
              " 'one': 5903,\n",
              " 'jacket': 4563,\n",
              " 'used': 8532,\n",
              " 'multis': 5553,\n",
              " 'started': 7632,\n",
              " 'requests': 6797,\n",
              " 'came': 2057,\n",
              " 'bed': 1686,\n",
              " 'coins': 2350,\n",
              " 'factory': 3335,\n",
              " 'gotta': 3860,\n",
              " 'nitros': 5727,\n",
              " 'ela': 3124,\n",
              " 'kano': 4708,\n",
              " 'il': 4362,\n",
              " 'download': 2975,\n",
              " 'wen': 8811,\n",
              " 'don': 2947,\n",
              " 'stand': 7620,\n",
              " 'close': 2313,\n",
              " 'll': 5008,\n",
              " 'another': 1332,\n",
              " 'night': 5710,\n",
              " 'spent': 7550,\n",
              " 'late': 4858,\n",
              " 'afternoon': 1185,\n",
              " 'casualty': 2126,\n",
              " 'means': 5291,\n",
              " \"haven't\": 4039,\n",
              " 'any': 1346,\n",
              " 'y': 9107,\n",
              " '42moro': 689,\n",
              " 'includes': 4405,\n",
              " 'sheets': 7203,\n",
              " 'smile': 7403,\n",
              " 'pleasure': 6268,\n",
              " 'trouble': 8328,\n",
              " 'pours': 6359,\n",
              " 'rain': 6602,\n",
              " 'sum': 7798,\n",
              " 'hurts': 4297,\n",
              " 'becoz': 1684,\n",
              " 'someone': 7457,\n",
              " 'loves': 5090,\n",
              " 'smiling': 7407,\n",
              " 'service': 7150,\n",
              " 'representative': 6794,\n",
              " '0800 169 6031': 86,\n",
              " 'between': 1741,\n",
              " '10am': 365,\n",
              " '9pm': 1002,\n",
              " 'guaranteed': 3930,\n",
              " '5000': 755,\n",
              " 'havent': 4040,\n",
              " 'planning': 6251,\n",
              " 'buy': 2004,\n",
              " 'lido': 4937,\n",
              " '530': 767,\n",
              " 'show': 7264,\n",
              " 'collected': 2358,\n",
              " 'simply': 7311,\n",
              " 'password': 6102,\n",
              " 'mix': 5421,\n",
              " '85069': 934,\n",
              " 'verify': 8594,\n",
              " 'usher': 8538,\n",
              " 'britney': 1932,\n",
              " 'fml': 3525,\n",
              " 'po': 6284,\n",
              " 'box': 1879,\n",
              " '5249': 764,\n",
              " 'mk17': 5424,\n",
              " '92h': 990,\n",
              " '450ppw': 705,\n",
              " 'telugu': 7991,\n",
              " 'movie': 5516,\n",
              " 'abt': 1084,\n",
              " 'loads': 5014,\n",
              " 'loans': 5016,\n",
              " 'wk': 8928,\n",
              " 'hols': 4174,\n",
              " 'run': 6946,\n",
              " 'forgot': 3565,\n",
              " 'hairdressers': 3974,\n",
              " 'appointment': 1386,\n",
              " 'four': 3584,\n",
              " 'shower': 7266,\n",
              " 'beforehand': 1702,\n",
              " 'cause': 2133,\n",
              " 'prob': 6456,\n",
              " 'coffee': 2345,\n",
              " 'animation': 1319,\n",
              " 'nothing': 5774,\n",
              " 'else': 3138,\n",
              " 'okay': 5877,\n",
              " 'price': 6431,\n",
              " 'long': 5042,\n",
              " 'legal': 4904,\n",
              " 'them': 8061,\n",
              " 'ave': 1536,\n",
              " 'ams': 1301,\n",
              " 'gone': 3832,\n",
              " '4the': 735,\n",
              " 'driving': 3007,\n",
              " 'test': 8014,\n",
              " 'yet': 9142,\n",
              " \"you're\": 9162,\n",
              " 'mean': 5287,\n",
              " 'guess': 3936,\n",
              " 'gave': 3729,\n",
              " 'boston': 1866,\n",
              " 'men': 5326,\n",
              " 'changed': 2174,\n",
              " 'search': 7080,\n",
              " 'location': 5019,\n",
              " 'nyc': 5819,\n",
              " 'cuz': 2631,\n",
              " 'signin': 7299,\n",
              " 'page': 6035,\n",
              " 'says': 7038,\n",
              " 'umma': 8423,\n",
              " 'life': 4940,\n",
              " 'vava': 8580,\n",
              " 'lot': 5066,\n",
              " 'dear': 2699,\n",
              " 'wishes': 8912,\n",
              " 'birthday': 1777,\n",
              " 'making': 5197,\n",
              " 'truly': 8335,\n",
              " 'memorable': 5323,\n",
              " 'aight': 1216,\n",
              " 'hit': 4141,\n",
              " 'would': 8993,\n",
              " 'ip': 4501,\n",
              " 'address': 1141,\n",
              " 'considering': 2449,\n",
              " 'computer': 2412,\n",
              " \"isn't\": 4528,\n",
              " 'minecraft': 5380,\n",
              " 'server': 7149,\n",
              " 'grumpy': 3923,\n",
              " 'old': 5889,\n",
              " 'people': 6146,\n",
              " 'mom': 5462,\n",
              " 'better': 1738,\n",
              " 'lying': 5135,\n",
              " 'jokes': 4640,\n",
              " 'worry': 8983,\n",
              " 'busy': 1998,\n",
              " 'plural': 6277,\n",
              " 'noun': 5781,\n",
              " 'research': 6802,\n",
              " 'dinner.msg': 2859,\n",
              " 'cos': 2499,\n",
              " 'things': 8091,\n",
              " 'scared': 7044,\n",
              " 'mah': 5180,\n",
              " 'loud': 5076,\n",
              " 'gent': 3749,\n",
              " 'contact': 2454,\n",
              " 'last': 4855,\n",
              " 'weekends': 8793,\n",
              " 'draw': 2989,\n",
              " 'shows': 7272,\n",
              " '09064012160': 282,\n",
              " 'k52': 4691,\n",
              " '12hrs': 398,\n",
              " '150ppm': 419,\n",
              " 'wa': 8677,\n",
              " 'openin': 5925,\n",
              " 'sentence': 7138,\n",
              " 'formal': 3569,\n",
              " 'anyway': 1360,\n",
              " 'juz': 4682,\n",
              " 'tt': 8348,\n",
              " 'eatin': 3083,\n",
              " 'puttin': 6554,\n",
              " 'weight': 8798,\n",
              " 'haha': 3968,\n",
              " 'anythin': 1355,\n",
              " 'happened': 4003,\n",
              " 'entered': 3185,\n",
              " 'cabin': 2025,\n",
              " \"b'day\": 1562,\n",
              " 'boss': 1865,\n",
              " 'felt': 3411,\n",
              " 'askd': 1464,\n",
              " 'invited': 4494,\n",
              " 'apartment': 1365,\n",
              " 'went': 8814,\n",
              " 'specially': 7536,\n",
              " 'holiday': 4171,\n",
              " 'flights': 3502,\n",
              " 'inc': 4399,\n",
              " 'operator': 5929,\n",
              " '08712778109': 166,\n",
              " '10p': 368,\n",
              " 'min': 5372,\n",
              " 'goodo': 3846,\n",
              " 'must': 5575,\n",
              " 'friday': 3626,\n",
              " 'egg-potato': 3112,\n",
              " 'ratio': 6631,\n",
              " 'tortilla': 8262,\n",
              " 'needed': 5656,\n",
              " 'hmm': 4153,\n",
              " 'uncle': 8433,\n",
              " 'informed': 4438,\n",
              " 'paying': 6124,\n",
              " 'school': 7050,\n",
              " 'directly': 2865,\n",
              " 'food': 3542,\n",
              " 'private': 6447,\n",
              " '2004': 486,\n",
              " 'account': 1107,\n",
              " 'statement': 7641,\n",
              " '07742676969': 64,\n",
              " '786': 864,\n",
              " 'unredeemed': 8477,\n",
              " 'points': 6297,\n",
              " '08719180248': 213,\n",
              " 'identifier': 4344,\n",
              " '45239': 707,\n",
              " 'expires': 3307,\n",
              " '2000': 484,\n",
              " 'caller': 2045,\n",
              " '5/9': 752,\n",
              " '03': 46,\n",
              " 'landline': 4835,\n",
              " '09064019788': 288,\n",
              " '42wr29c': 690,\n",
              " 'apples': 1381,\n",
              " 'pairs': 6044,\n",
              " 'malarky': 5199,\n",
              " 'todays': 8205,\n",
              " 'voda': 8645,\n",
              " 'numbers': 5804,\n",
              " 'ending': 3160,\n",
              " '7548': 856,\n",
              " '350': 624,\n",
              " 'award': 1548,\n",
              " 'match': 5251,\n",
              " '08712300220': 149,\n",
              " 'quoting': 6589,\n",
              " '4041': 674,\n",
              " 'standard': 7621,\n",
              " 'rates': 6629,\n",
              " 'app': 1375,\n",
              " 'sao': 7004,\n",
              " 'mu': 5542,\n",
              " 'predict': 6392,\n",
              " \"ü'll\": 9222,\n",
              " 'buying': 2007,\n",
              " 'yetunde': 9144,\n",
              " \"hasn't\": 4024,\n",
              " 'sent': 7137,\n",
              " 'bother': 1869,\n",
              " 'sending': 7129,\n",
              " 'involve': 4498,\n",
              " \"shouldn't\": 7259,\n",
              " 'imposed': 4386,\n",
              " 'apologise': 1372,\n",
              " 'girl': 3782,\n",
              " 'del': 2740,\n",
              " 'bak': 1597,\n",
              " 'lucyxx': 5118,\n",
              " 'tmorrow.pls': 8185,\n",
              " 'accomodate': 1102,\n",
              " 'answer': 1335,\n",
              " 'sunshine': 7812,\n",
              " 'quiz': 6584,\n",
              " 'q': 6559,\n",
              " 'top': 8253,\n",
              " 'sony': 7480,\n",
              " 'dvd': 3051,\n",
              " 'player': 6257,\n",
              " 'country': 2518,\n",
              " 'algarve': 1245,\n",
              " 'ansr': 1334,\n",
              " '82277': 907,\n",
              " 'sp': 7516,\n",
              " 'tyrone': 8394,\n",
              " 'laid': 4827,\n",
              " 'dogging': 2932,\n",
              " 'locations': 5020,\n",
              " 'direct': 2864,\n",
              " 'join': 4631,\n",
              " \"uk's\": 8416,\n",
              " 'largest': 4852,\n",
              " 'bt': 1958,\n",
              " 'txting': 8383,\n",
              " 'gravel': 3888,\n",
              " '69888': 822,\n",
              " 'nt': 5791,\n",
              " 'ec2a': 3086,\n",
              " '31p': 611,\n",
              " '@150p': 1039,\n",
              " 'haf': 3967,\n",
              " 'msn': 5534,\n",
              " 'yijue@hotmail.com': 9149,\n",
              " 'him': 4132,\n",
              " 'rooms': 6911,\n",
              " 'befor': 1699,\n",
              " 'activities': 1129,\n",
              " \"you'll\": 9161,\n",
              " 'msgs': 5533,\n",
              " 'chat': 2195,\n",
              " ...}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKwBVkOzdhmf"
      },
      "outputs": [],
      "source": [
        "column_nums, terms  =  zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FBz3x0wdqfq",
        "outputId": "977a78a9-9a23-48b2-aeb6-42be3a846818"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('!',\n",
              " '\"',\n",
              " '#',\n",
              " '#150',\n",
              " '#5000',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '. .',\n",
              " '. . .',\n",
              " '. . . .',\n",
              " '. . . . .',\n",
              " '. ..',\n",
              " '..',\n",
              " '.. .',\n",
              " '.. . . .',\n",
              " '.. ... ...',\n",
              " '...',\n",
              " '... . . . .',\n",
              " '/',\n",
              " '0',\n",
              " '00',\n",
              " '00870405040',\n",
              " '0089',\n",
              " '01',\n",
              " '0121 2025050',\n",
              " '01223585236',\n",
              " '01223585334',\n",
              " '01256987',\n",
              " '02',\n",
              " '02/06',\n",
              " '02/09',\n",
              " '0207 153 9153',\n",
              " '0207 153 9996',\n",
              " '0207-083-6089',\n",
              " '02072069400',\n",
              " '02073162414',\n",
              " '02085076972',\n",
              " '03',\n",
              " '03530150',\n",
              " '04',\n",
              " '04/09',\n",
              " '05',\n",
              " '050703',\n",
              " '06',\n",
              " '06.05',\n",
              " '06/11',\n",
              " '07/11',\n",
              " '07008009200',\n",
              " '07046744435',\n",
              " '07090201529',\n",
              " '07090298926',\n",
              " '07099833605',\n",
              " '07123456789',\n",
              " '07732584351',\n",
              " '07734396839',\n",
              " '07742676969',\n",
              " '07753741225',\n",
              " '0776xxxxxxx',\n",
              " '07786200117',\n",
              " '077xxx',\n",
              " '078',\n",
              " '07801543489',\n",
              " '07808',\n",
              " '07808247860',\n",
              " '07808726822',\n",
              " '07815296484',\n",
              " '07821230901',\n",
              " '078498',\n",
              " '07880867867',\n",
              " '0789xxxxxxx',\n",
              " '07946746291',\n",
              " '0796xxxxxx',\n",
              " '07973788240',\n",
              " '07xxxxxxxxx',\n",
              " '08',\n",
              " '0800',\n",
              " '0800 0721072',\n",
              " '0800 169 6031',\n",
              " '0800 195 6669',\n",
              " '0800 1956669',\n",
              " '0800 5050',\n",
              " '0800 542 0578',\n",
              " '0800 542 0825',\n",
              " '08000407165',\n",
              " '08000776320',\n",
              " '08000839402',\n",
              " '08000930705',\n",
              " '08000938767',\n",
              " '08001950382',\n",
              " '08002888812',\n",
              " '08002986030',\n",
              " '08002986906',\n",
              " '08002988890',\n",
              " '08006344447',\n",
              " '0808 145 4742',\n",
              " '08081263000',\n",
              " '08081560665',\n",
              " '0819',\n",
              " '0844',\n",
              " '08448350055',\n",
              " '08448714184',\n",
              " '0845 021 3680',\n",
              " '0845 2814032',\n",
              " '08450542832',\n",
              " '08452810071',\n",
              " '08452810073',\n",
              " '08452810075',\n",
              " '0870',\n",
              " '08700435505',\n",
              " '08700469649',\n",
              " '08700621170',\n",
              " '08701213186',\n",
              " '08701237397',\n",
              " '08701417012',\n",
              " '08701624',\n",
              " '08701752560',\n",
              " '08701872873',\n",
              " '08702411827',\n",
              " '08702490080',\n",
              " '08702840625',\n",
              " '08702840625.comuk',\n",
              " '08704050406',\n",
              " '08704439680',\n",
              " '08706091795',\n",
              " '08707379102',\n",
              " '08707500020',\n",
              " '08707509020',\n",
              " '08707533310',\n",
              " '08707808226',\n",
              " '08708034412',\n",
              " '08708800282',\n",
              " '08709222922',\n",
              " '08709501522',\n",
              " '0871-4719',\n",
              " '0871-872-9755',\n",
              " '0871-872-9758',\n",
              " '08710471114',\n",
              " '08712101358',\n",
              " '08712103738',\n",
              " '08712120250',\n",
              " '08712300220',\n",
              " '08712317606',\n",
              " '08712400200',\n",
              " '08712400602',\n",
              " '08712400603',\n",
              " '08712402050',\n",
              " '08712402578',\n",
              " '08712402779',\n",
              " '08712402902',\n",
              " '08712402972',\n",
              " '08712404000',\n",
              " '08712405020',\n",
              " '08712405022',\n",
              " '08712460324',\n",
              " '08712466669',\n",
              " '08712778107',\n",
              " '08712778108',\n",
              " '08712778109',\n",
              " '08714342399',\n",
              " '08714712377',\n",
              " '08714712379',\n",
              " '08714712388',\n",
              " '08714712394',\n",
              " '08714712412',\n",
              " '08714714011',\n",
              " '08714740323',\n",
              " '08714742804',\n",
              " '08715203028',\n",
              " '08715203649',\n",
              " '08715203652',\n",
              " '08715203656',\n",
              " '08715203677',\n",
              " '08715203685',\n",
              " '08715203694',\n",
              " '08715205273',\n",
              " '08715500022',\n",
              " '08715705022',\n",
              " '08717111821',\n",
              " '08717168528',\n",
              " '08717205546',\n",
              " '0871750',\n",
              " '08717507382',\n",
              " '08717509990',\n",
              " '08717890890',\n",
              " '08717895698',\n",
              " '08717898035',\n",
              " '08718711108',\n",
              " '08718720201',\n",
              " '08718723815',\n",
              " '08718725756',\n",
              " '08718726270',\n",
              " '08718726970',\n",
              " '08718726971',\n",
              " '08718726978',\n",
              " '08718727200',\n",
              " '08718727868',\n",
              " '08718727870',\n",
              " '08718728876',\n",
              " '08718730555',\n",
              " '08718730666',\n",
              " '08718738001',\n",
              " '08718738002',\n",
              " '08718738034',\n",
              " '08719180219',\n",
              " '08719180248',\n",
              " '08719181259',\n",
              " '08719181503',\n",
              " '08719181513',\n",
              " '08719839835',\n",
              " '08719899217',\n",
              " '08719899229',\n",
              " '08719899230',\n",
              " '09',\n",
              " '09041940223',\n",
              " '09050000301',\n",
              " '09050000327',\n",
              " '09050000332',\n",
              " '09050000460',\n",
              " '09050000555',\n",
              " '09050000878',\n",
              " '09050000928',\n",
              " '09050001295',\n",
              " '09050001808',\n",
              " '09050002311',\n",
              " '09050003091',\n",
              " '09050005321',\n",
              " '09050090044',\n",
              " '09050280520',\n",
              " '09053750005',\n",
              " '09056242159',\n",
              " '09057039994',\n",
              " '09058091854',\n",
              " '09058091870',\n",
              " '09058094454',\n",
              " '09058094455',\n",
              " '09058094507',\n",
              " '09058094565',\n",
              " '09058094583',\n",
              " '09058094594',\n",
              " '09058094597',\n",
              " '09058094599',\n",
              " '09058095107',\n",
              " '09058095201',\n",
              " '09058097189',\n",
              " '09058097218',\n",
              " '09058098002',\n",
              " '09058099801',\n",
              " '09061104276',\n",
              " '09061104283',\n",
              " '09061209465',\n",
              " '09061213237',\n",
              " '09061221061',\n",
              " '09061221066',\n",
              " '09061701444',\n",
              " '09061701461',\n",
              " '09061701851',\n",
              " '09061701939',\n",
              " '09061702893',\n",
              " '09061743386',\n",
              " '09061743806',\n",
              " '09061743810',\n",
              " '09061743811',\n",
              " '09061744553',\n",
              " '09061749602',\n",
              " '09061790121',\n",
              " '09061790125',\n",
              " '09061790126',\n",
              " '09063440451',\n",
              " '09063442151',\n",
              " '09063458130',\n",
              " '09063463',\n",
              " '09064011000',\n",
              " '09064012103',\n",
              " '09064012160',\n",
              " '09064015307',\n",
              " '09064017295',\n",
              " '09064017305',\n",
              " '09064018838',\n",
              " '09064019014',\n",
              " '09064019788',\n",
              " '09065069120',\n",
              " '09065069154',\n",
              " '09065171142',\n",
              " '09065174042',\n",
              " '09065394514',\n",
              " '09065394973',\n",
              " '09065989180',\n",
              " '09065989182',\n",
              " '09066350750',\n",
              " '09066358152',\n",
              " '09066358361',\n",
              " '09066361921',\n",
              " '09066362206',\n",
              " '09066362220',\n",
              " '09066362231',\n",
              " '09066364311',\n",
              " '09066364349',\n",
              " '09066364589',\n",
              " '09066368327',\n",
              " '09066368470',\n",
              " '09066368753',\n",
              " '09066380611',\n",
              " '09066382422',\n",
              " '09066612661',\n",
              " '09066649731',\n",
              " '09066660100',\n",
              " '09071512432',\n",
              " '09071512433',\n",
              " '09071517866',\n",
              " '09077818151',\n",
              " '09090204448',\n",
              " '09090900040',\n",
              " '09094100151',\n",
              " '09094646631',\n",
              " '09094646899',\n",
              " '09095350301',\n",
              " '09096102316',\n",
              " '09099725823',\n",
              " '09099726395',\n",
              " '09099726429',\n",
              " '09099726481',\n",
              " '09099726553',\n",
              " '09111030116',\n",
              " '09111032124',\n",
              " '09701213186',\n",
              " '0a',\n",
              " '0p',\n",
              " '0quit',\n",
              " '1',\n",
              " '1,000',\n",
              " '1,2',\n",
              " '1,50',\n",
              " '1,500',\n",
              " '1.20',\n",
              " '1.5',\n",
              " '1.50',\n",
              " '1.childish',\n",
              " '1/08',\n",
              " '1/1',\n",
              " '1/2',\n",
              " '1/3',\n",
              " '10',\n",
              " '10,000',\n",
              " '10.1',\n",
              " '10/06',\n",
              " '100',\n",
              " '100,000',\n",
              " '1000',\n",
              " '1000call',\n",
              " '1000s',\n",
              " '100p',\n",
              " '100txt',\n",
              " '1013',\n",
              " '1030',\n",
              " '10:10',\n",
              " '10:30',\n",
              " '10am',\n",
              " '10k',\n",
              " '10mins',\n",
              " '10p',\n",
              " '10ppm',\n",
              " '10th',\n",
              " '11',\n",
              " '11.48',\n",
              " '1120',\n",
              " '113',\n",
              " '1131',\n",
              " '114/14',\n",
              " '1146',\n",
              " '1151',\n",
              " '116',\n",
              " '1172',\n",
              " '118p',\n",
              " '11mths',\n",
              " '11pm',\n",
              " '12',\n",
              " '12,000',\n",
              " '1205',\n",
              " '120p',\n",
              " '121',\n",
              " '1225',\n",
              " '123',\n",
              " '125',\n",
              " '1250',\n",
              " '125gift',\n",
              " '128',\n",
              " '1282essexcm61xn',\n",
              " '12:30',\n",
              " '12hours',\n",
              " '12hrs',\n",
              " '12mths',\n",
              " '12n146tf15',\n",
              " '12n146tf150p',\n",
              " '13/10',\n",
              " '13/4',\n",
              " '130',\n",
              " '1327',\n",
              " '139',\n",
              " '140',\n",
              " '1405',\n",
              " '140ppm',\n",
              " '1450',\n",
              " '146tf150p',\n",
              " '14thmarch',\n",
              " '150',\n",
              " '1500',\n",
              " '150p',\n",
              " '150p16',\n",
              " '150pm',\n",
              " '150ppermesssubscription',\n",
              " '150ppm',\n",
              " '150ppmmobilesvary',\n",
              " '150ppmpobox10183bhamb64xe',\n",
              " '150ppmsg',\n",
              " '150ppmx3age16',\n",
              " '150pw',\n",
              " '150x3',\n",
              " '151',\n",
              " '1510',\n",
              " '15541',\n",
              " '15:26',\n",
              " '15h',\n",
              " '16',\n",
              " '16.150',\n",
              " '165',\n",
              " '1680',\n",
              " '16yrs',\n",
              " '177',\n",
              " '177hp51fl',\n",
              " '18',\n",
              " '18/11',\n",
              " '180',\n",
              " '1843',\n",
              " '1896wc1n3xx',\n",
              " '18:0430-',\n",
              " '18p',\n",
              " '18yrs',\n",
              " '1apple',\n",
              " '1b6a5ecef91ff9',\n",
              " '1cup',\n",
              " '1da',\n",
              " '1er',\n",
              " '1hr',\n",
              " '1im',\n",
              " '1lemon',\n",
              " '1million',\n",
              " '1more',\n",
              " '1n3xx',\n",
              " '1pm',\n",
              " '1st',\n",
              " '1st4terms',\n",
              " '1stchoice.co.uk',\n",
              " '1stone',\n",
              " '1thing',\n",
              " '1tulsi',\n",
              " '1win150ppmx3',\n",
              " '1win150ppmx3age16',\n",
              " '1win150ppmx3age16subscription',\n",
              " '1winaweek',\n",
              " '1winawk',\n",
              " '1x150p',\n",
              " '1yf',\n",
              " '2',\n",
              " '2,000',\n",
              " '2-4-',\n",
              " '2.15',\n",
              " '2.30',\n",
              " '2.50',\n",
              " '2.im',\n",
              " '2.naughty',\n",
              " '2/2',\n",
              " '2/3',\n",
              " '20',\n",
              " '20,000',\n",
              " '200',\n",
              " '2000',\n",
              " '2003',\n",
              " '2004',\n",
              " '2005',\n",
              " '2006',\n",
              " '2007',\n",
              " '200p',\n",
              " '202',\n",
              " '20m12aq',\n",
              " '20p',\n",
              " '21',\n",
              " '21/11',\n",
              " '2187000',\n",
              " '21st',\n",
              " '22',\n",
              " '220',\n",
              " '220cm2',\n",
              " '23',\n",
              " '2309',\n",
              " '23f',\n",
              " '23g',\n",
              " '24',\n",
              " '24/10',\n",
              " '24/7',\n",
              " '245c2150pm',\n",
              " '24hrs',\n",
              " '24m',\n",
              " '24th',\n",
              " '25',\n",
              " '250',\n",
              " '250k',\n",
              " '255',\n",
              " '25p',\n",
              " '26.03',\n",
              " '26/10',\n",
              " '26/11',\n",
              " '2667',\n",
              " '26th',\n",
              " '27/03',\n",
              " '27/6',\n",
              " '28',\n",
              " '28/5',\n",
              " '28days',\n",
              " '28th',\n",
              " '28thfeb',\n",
              " '29',\n",
              " '29/03',\n",
              " '29/10',\n",
              " '2b',\n",
              " '2bed',\n",
              " '2bold',\n",
              " '2bremoved',\n",
              " '2c',\n",
              " '2channel',\n",
              " '2come',\n",
              " '2day',\n",
              " '2day.love',\n",
              " '2die',\n",
              " '2docd.please',\n",
              " '2end',\n",
              " '2exit',\n",
              " '2ez',\n",
              " '2find',\n",
              " '2getha',\n",
              " '2geva',\n",
              " '2go',\n",
              " '2go.did',\n",
              " '2gthr',\n",
              " '2hear',\n",
              " '2hook',\n",
              " '2hrs',\n",
              " '2i',\n",
              " '2kbsubject',\n",
              " '2marrow',\n",
              " '2mobile',\n",
              " '2moro',\n",
              " '2morow',\n",
              " '2morro',\n",
              " '2morrow',\n",
              " '2morrowxxxx',\n",
              " '2mro',\n",
              " '2mrw',\n",
              " '2mwen',\n",
              " '2nd',\n",
              " '2nhite',\n",
              " '2nights',\n",
              " '2nite',\n",
              " '2optout',\n",
              " '2p',\n",
              " '2px',\n",
              " '2rcv',\n",
              " '2stop',\n",
              " '2stoptx',\n",
              " '2stoptxt',\n",
              " '2tell',\n",
              " '2the',\n",
              " '2u',\n",
              " '2u2',\n",
              " '2watershd',\n",
              " '2waxsto',\n",
              " '2wks',\n",
              " '2worzels',\n",
              " '2wt',\n",
              " '2wu',\n",
              " '2years',\n",
              " '2yr',\n",
              " '2yrs',\n",
              " '3',\n",
              " '3.00',\n",
              " '3.75',\n",
              " '3.99',\n",
              " '3.sentiment',\n",
              " '30',\n",
              " '300',\n",
              " '3000',\n",
              " '300603',\n",
              " '300603t',\n",
              " '300p',\n",
              " '3030',\n",
              " '30apr',\n",
              " '30pp',\n",
              " '30s',\n",
              " '30th',\n",
              " '31',\n",
              " '31/10',\n",
              " '3100',\n",
              " '310303',\n",
              " '31p',\n",
              " '32',\n",
              " '32000',\n",
              " '3230',\n",
              " '32323',\n",
              " '326',\n",
              " '33.65',\n",
              " '330',\n",
              " '334',\n",
              " '334sk38ch',\n",
              " '3355',\n",
              " '33:50',\n",
              " '342/2',\n",
              " '350',\n",
              " '3510i',\n",
              " '35p',\n",
              " '3650',\n",
              " '36504',\n",
              " '36504w45wq',\n",
              " '365o4w45wq',\n",
              " '373',\n",
              " '3750',\n",
              " '37819',\n",
              " '38',\n",
              " '385',\n",
              " '391784',\n",
              " '39822',\n",
              " '3aj',\n",
              " '3cktz8r7',\n",
              " '3d',\n",
              " '3days',\n",
              " '3g',\n",
              " '3gbp',\n",
              " '3hrs',\n",
              " '3lions',\n",
              " '3lp',\n",
              " '3miles',\n",
              " '3mins',\n",
              " '3mobile',\n",
              " '3optical',\n",
              " '3pound',\n",
              " '3qxj9',\n",
              " '3rd',\n",
              " '3ss',\n",
              " '3uz',\n",
              " '3wks',\n",
              " '3x',\n",
              " '3xx',\n",
              " '4',\n",
              " '4-6',\n",
              " '4-7',\n",
              " '4.15',\n",
              " '4.30',\n",
              " '4.47',\n",
              " '4.49',\n",
              " '4.50',\n",
              " '4.cook',\n",
              " '4.rowdy',\n",
              " '40',\n",
              " '400',\n",
              " '400mins',\n",
              " '402',\n",
              " '403',\n",
              " '4041',\n",
              " '40411',\n",
              " '40533',\n",
              " '40gb',\n",
              " '40mph',\n",
              " '41',\n",
              " '41685',\n",
              " '41782',\n",
              " '420',\n",
              " '42049',\n",
              " '4217',\n",
              " '4235wc1n3xx',\n",
              " '42478',\n",
              " '42810',\n",
              " '4284',\n",
              " '42moro',\n",
              " '42wr29c',\n",
              " '430',\n",
              " '434',\n",
              " '434sk38wp150ppm18',\n",
              " '44',\n",
              " '440',\n",
              " '4403ldnw1a7rw18',\n",
              " '4477977060',\n",
              " '4478012592',\n",
              " '4487124040',\n",
              " '4490500003',\n",
              " '4490715124',\n",
              " '45',\n",
              " '450',\n",
              " '450p',\n",
              " '450ppw',\n",
              " '450pw',\n",
              " '45239',\n",
              " '45po139wa',\n",
              " '45w2tg150p',\n",
              " '47',\n",
              " '48',\n",
              " '4882',\n",
              " '48922',\n",
              " '49557',\n",
              " '4a',\n",
              " '4an18th',\n",
              " '4brekkie',\n",
              " '4d',\n",
              " '4eva',\n",
              " '4few',\n",
              " '4fil',\n",
              " '4get',\n",
              " '4get2text',\n",
              " '4give',\n",
              " '4got',\n",
              " '4goten',\n",
              " '4info',\n",
              " '4jx',\n",
              " '4msgs',\n",
              " '4mths',\n",
              " '4my',\n",
              " '4qf2',\n",
              " '4t',\n",
              " '4th',\n",
              " '4the',\n",
              " '4thnov.behind',\n",
              " '4txt',\n",
              " '4u',\n",
              " '4utxt',\n",
              " '4w',\n",
              " '4ward',\n",
              " '4wrd',\n",
              " '4xx26',\n",
              " '4years',\n",
              " '5',\n",
              " '5.00',\n",
              " '5.15',\n",
              " '5.30',\n",
              " '5.ful',\n",
              " '5.gardener',\n",
              " '5.terror',\n",
              " '5/9',\n",
              " '50',\n",
              " '500',\n",
              " '5000',\n",
              " '5000.00',\n",
              " '50award',\n",
              " '50p',\n",
              " '50s',\n",
              " '5120',\n",
              " '515',\n",
              " '5226',\n",
              " '523',\n",
              " '5249',\n",
              " '526',\n",
              " '528',\n",
              " '530',\n",
              " '54',\n",
              " '545',\n",
              " '5digital',\n",
              " '5free',\n",
              " '5ish',\n",
              " '5k',\n",
              " '5min',\n",
              " '5mls',\n",
              " '5p',\n",
              " '5pm',\n",
              " '5th',\n",
              " '5times',\n",
              " '5wb',\n",
              " '5we',\n",
              " '5wkg',\n",
              " '5wq',\n",
              " '5years',\n",
              " '6',\n",
              " '6.30',\n",
              " '6.45',\n",
              " '6.cruel',\n",
              " '6.house',\n",
              " '6.romantic',\n",
              " '60',\n",
              " '60,400',\n",
              " '600',\n",
              " '60p',\n",
              " '61',\n",
              " '61200',\n",
              " '61610',\n",
              " '62220cncl',\n",
              " '6230',\n",
              " '62468',\n",
              " '62735',\n",
              " '630',\n",
              " '63miles',\n",
              " '645',\n",
              " '65,61',\n",
              " '650',\n",
              " '66,382',\n",
              " '6600',\n",
              " '6650',\n",
              " '674',\n",
              " '6744123',\n",
              " '68866',\n",
              " '69',\n",
              " '69101',\n",
              " '69200',\n",
              " '69669',\n",
              " '69696',\n",
              " '69698',\n",
              " '69855',\n",
              " '69866.18',\n",
              " '69876',\n",
              " '69888',\n",
              " '69888nyt',\n",
              " '69911',\n",
              " '69969',\n",
              " '69988',\n",
              " '6days',\n",
              " '6gbp',\n",
              " '6hl',\n",
              " '6hrs',\n",
              " '6ish',\n",
              " '6missed',\n",
              " '6months',\n",
              " '6ph',\n",
              " '6pm',\n",
              " '6th',\n",
              " '6times',\n",
              " '6wu',\n",
              " '6zf',\n",
              " '7',\n",
              " '7.30',\n",
              " '7.8',\n",
              " '7.children',\n",
              " '7.romantic',\n",
              " '7.shy',\n",
              " '700',\n",
              " '71',\n",
              " '7250',\n",
              " '7250i',\n",
              " '730',\n",
              " '731',\n",
              " '734ls27yf',\n",
              " '74355',\n",
              " '75,000',\n",
              " '750',\n",
              " '7548',\n",
              " '75ldns7',\n",
              " '762',\n",
              " '7634',\n",
              " '7684',\n",
              " '77.11',\n",
              " '7732584351',\n",
              " '78',\n",
              " '786',\n",
              " '7876150',\n",
              " '79',\n",
              " '7:30',\n",
              " '7am',\n",
              " '7cfca1a',\n",
              " '7ish',\n",
              " '7oz',\n",
              " '7pm',\n",
              " '7th',\n",
              " '7ws',\n",
              " '7zs',\n",
              " '8',\n",
              " '8,22',\n",
              " '8-8',\n",
              " '8.30',\n",
              " '8.attractive',\n",
              " '8.lovable',\n",
              " '8.neighbour',\n",
              " '80',\n",
              " '800',\n",
              " '8000930705',\n",
              " '80062',\n",
              " '8007',\n",
              " '80082',\n",
              " '80086',\n",
              " '8012230',\n",
              " '80155',\n",
              " '80160',\n",
              " '80182',\n",
              " '8027',\n",
              " '80488',\n",
              " '80488.biz',\n",
              " '80608',\n",
              " '8077',\n",
              " '80878',\n",
              " '81010',\n",
              " '81151',\n",
              " '81303',\n",
              " '81618',\n",
              " '820554ad0a1705572711',\n",
              " '82228',\n",
              " '82242',\n",
              " '82277',\n",
              " '82277.unsub',\n",
              " '82324',\n",
              " '82468',\n",
              " '83021',\n",
              " '83039',\n",
              " '83049',\n",
              " '83110',\n",
              " '83118',\n",
              " '83222',\n",
              " '83332.please',\n",
              " '83338',\n",
              " '83355',\n",
              " '83370',\n",
              " '83383',\n",
              " '83435',\n",
              " '83600',\n",
              " '83738',\n",
              " '84',\n",
              " '84025',\n",
              " '84122',\n",
              " '84128',\n",
              " '84199',\n",
              " '84484',\n",
              " '85',\n",
              " '850',\n",
              " '85023',\n",
              " '85069',\n",
              " '85222',\n",
              " '85233',\n",
              " '8552',\n",
              " '85555',\n",
              " '86021',\n",
              " '861',\n",
              " '864233',\n",
              " '86688',\n",
              " '86888',\n",
              " '87021',\n",
              " '87066',\n",
              " '87070',\n",
              " '87077',\n",
              " '87121',\n",
              " '87131',\n",
              " '8714714',\n",
              " '87239',\n",
              " '87575',\n",
              " '8800',\n",
              " '88039',\n",
              " '88039.skilgme',\n",
              " '88066',\n",
              " '88088',\n",
              " '88222',\n",
              " '88600',\n",
              " '88800',\n",
              " '8883',\n",
              " '88877',\n",
              " '88888',\n",
              " '89',\n",
              " '89034',\n",
              " '89070',\n",
              " '89080',\n",
              " '89105',\n",
              " '89123',\n",
              " '89545',\n",
              " '89555',\n",
              " '89693',\n",
              " '89938',\n",
              " '8am',\n",
              " '8ball',\n",
              " '8i',\n",
              " '8lb',\n",
              " '8p',\n",
              " '8r',\n",
              " '8th',\n",
              " '8wp',\n",
              " '9',\n",
              " '9-6',\n",
              " '9.decent',\n",
              " '9.funny',\n",
              " '900',\n",
              " '9061100010',\n",
              " '910',\n",
              " '9280114',\n",
              " '92h',\n",
              " '930',\n",
              " '9307622',\n",
              " '945',\n",
              " '946',\n",
              " '95',\n",
              " '95qu',\n",
              " '97n7qp',\n",
              " '9832156',\n",
              " '9ae',\n",
              " ...)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb-ZpcACdr4b"
      },
      "outputs": [],
      "source": [
        "weights = pd.DataFrame(pca.components_, columns= terms, index =['topic{}'.format(i) for i in range(16)] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "v7G76lI6elTP",
        "outputId": "dc41bee4-93f8-4ed8-ba32-4b78277c1c74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bf1842f2-70a5-401e-aaae-459e3297f76a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>!</th>\n",
              "      <th>\"</th>\n",
              "      <th>#</th>\n",
              "      <th>#150</th>\n",
              "      <th>#5000</th>\n",
              "      <th>$</th>\n",
              "      <th>%</th>\n",
              "      <th>&amp;</th>\n",
              "      <th>'</th>\n",
              "      <th>(</th>\n",
              "      <th>...</th>\n",
              "      <th>ü'll</th>\n",
              "      <th>–</th>\n",
              "      <th>—</th>\n",
              "      <th>‘</th>\n",
              "      <th>’</th>\n",
              "      <th>“</th>\n",
              "      <th>…</th>\n",
              "      <th>┾</th>\n",
              "      <th>〨ud</th>\n",
              "      <th>鈥</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>topic0</th>\n",
              "      <td>-0.071</td>\n",
              "      <td>0.008</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.012</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>-0.005</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic1</th>\n",
              "      <td>0.064</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.001</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.004</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic2</th>\n",
              "      <td>0.071</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.019</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic3</th>\n",
              "      <td>-0.059</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.003</td>\n",
              "      <td>-0.028</td>\n",
              "      <td>0.001</td>\n",
              "      <td>-0.010</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 9232 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf1842f2-70a5-401e-aaae-459e3297f76a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf1842f2-70a5-401e-aaae-459e3297f76a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf1842f2-70a5-401e-aaae-459e3297f76a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            !      \"      #   #150  #5000      $      %      &      '      (  ...   ü'll      –    —      ‘      ’  \\\n",
              "topic0 -0.071  0.008 -0.001 -0.000 -0.001  0.003 -0.000 -0.012 -0.007 -0.005  ...  0.003 -0.000 -0.0 -0.004 -0.001   \n",
              "topic1  0.064  0.008  0.000 -0.000 -0.001 -0.001 -0.002 -0.016 -0.016  0.001  ...  0.002  0.001 -0.0  0.004 -0.001   \n",
              "topic2  0.071  0.027  0.000  0.001  0.002  0.000  0.001  0.059  0.008  0.019  ...  0.000  0.001 -0.0  0.002  0.000   \n",
              "topic3 -0.059 -0.032 -0.001 -0.000 -0.001  0.001 -0.003 -0.028  0.001 -0.010  ... -0.001 -0.001  0.0  0.000 -0.000   \n",
              "\n",
              "            “      …      ┾    〨ud      鈥  \n",
              "topic0 -0.001 -0.002  0.001  0.001  0.001  \n",
              "topic1 -0.001  0.003  0.001  0.001  0.001  \n",
              "topic2  0.001  0.002 -0.001 -0.001 -0.001  \n",
              "topic3 -0.000  0.001  0.001  0.001  0.001  \n",
              "\n",
              "[4 rows x 9232 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.options.display.max_columns = 20\n",
        "weights.head(4).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B89thU8cemhC"
      },
      "outputs": [],
      "source": [
        "deals =  weights['! ;) :) half off free crazy deal only $ 80 %'.split()].round(3) *100 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "JipN9PvsfA6A",
        "outputId": "1d473508-0aa9-4d1f-c09b-edfcb202e947"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-99cd97fd-2598-4a10-a3a1-6b2ea5a18486\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>!</th>\n",
              "      <th>;)</th>\n",
              "      <th>:)</th>\n",
              "      <th>half</th>\n",
              "      <th>off</th>\n",
              "      <th>free</th>\n",
              "      <th>crazy</th>\n",
              "      <th>deal</th>\n",
              "      <th>only</th>\n",
              "      <th>$</th>\n",
              "      <th>80</th>\n",
              "      <th>%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>topic0</th>\n",
              "      <td>-7.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic1</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-3.8</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic2</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic3</th>\n",
              "      <td>-5.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic4</th>\n",
              "      <td>38.1</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-12.4</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>9.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic5</th>\n",
              "      <td>-26.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-1.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic6</th>\n",
              "      <td>-10.9</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>19.8</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-1.4</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic7</th>\n",
              "      <td>16.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-17.9</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic8</th>\n",
              "      <td>34.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.5</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>3.3</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic9</th>\n",
              "      <td>6.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>17.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>6.4</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>3.1</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic10</th>\n",
              "      <td>-32.4</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>12.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic11</th>\n",
              "      <td>24.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>28.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic12</th>\n",
              "      <td>-22.4</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>36.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic13</th>\n",
              "      <td>12.6</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>31.0</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.6</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic14</th>\n",
              "      <td>-3.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.9</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>6.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic15</th>\n",
              "      <td>-19.0</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.1</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99cd97fd-2598-4a10-a3a1-6b2ea5a18486')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99cd97fd-2598-4a10-a3a1-6b2ea5a18486 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99cd97fd-2598-4a10-a3a1-6b2ea5a18486');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            !   ;)    :)  half  off  free  crazy  deal  only    $   80    %\n",
              "topic0   -7.1  0.1  -0.5  -0.0 -0.4  -2.0   -0.0  -0.1  -2.2  0.3 -0.0 -0.0\n",
              "topic1    6.4  0.0   7.4   0.1  0.4  -2.3   -0.2  -0.1  -3.8 -0.1 -0.0 -0.2\n",
              "topic2    7.1  0.2  -0.1   0.0  0.3   4.4    0.1  -0.1   0.7  0.0  0.0  0.1\n",
              "topic3   -5.9 -0.3  -7.0   0.2  0.3  -0.2    0.0   0.1  -2.3  0.1 -0.1 -0.3\n",
              "topic4   38.1 -0.1 -12.4  -0.1 -0.2   9.9    0.1  -0.2   3.0  0.3  0.1 -0.1\n",
              "topic5  -26.5  0.1  -1.6  -0.3 -0.7  -1.4   -0.6  -0.2  -1.8 -0.9  0.0  0.0\n",
              "topic6  -10.9 -0.5  19.8  -0.4 -0.9  -0.6   -0.2  -0.1  -1.4 -0.0 -0.0 -0.1\n",
              "topic7   16.2  0.1 -17.9   0.8  0.8  -2.7    0.0   0.0  -1.9 -0.3  0.0 -0.1\n",
              "topic8   34.9  0.1   4.5  -0.5 -0.6  -0.0   -0.4  -0.4   3.3 -0.6 -0.0 -0.2\n",
              "topic9    6.9 -0.3  17.1   1.5 -0.9   6.4   -0.5  -0.4   3.1 -0.5 -0.0  0.0\n",
              "topic10 -32.4 -0.2  -9.5   0.1  0.1  12.6    0.1   0.0   0.3 -0.0 -0.0 -0.2\n",
              "topic11  24.1  0.4  28.5   0.5  1.4  -4.1    0.0   0.1   0.1 -0.4 -0.0 -0.3\n",
              "topic12 -22.4 -0.2  36.0  -0.1  0.1  -3.1   -0.6   0.1   3.5  0.3 -0.0  0.3\n",
              "topic13  12.6 -0.3  31.0  -0.4  0.5   5.6    0.3   0.1  -1.7 -0.4  0.0 -0.3\n",
              "topic14  -3.2  0.0  14.9  -0.0 -0.8   6.4    0.2  -0.1   3.5  0.0  0.1 -0.3\n",
              "topic15 -19.0 -0.3   2.5   1.1 -1.3   2.9   -0.5   0.5   1.0 -0.4  0.1 -0.1"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAanzJBhfFVs",
        "outputId": "21c5cc45-a9a4-42a0-d967-adf2a036054a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "topic0    -11.9\n",
              "topic1      7.6\n",
              "topic2     12.7\n",
              "topic3    -15.4\n",
              "topic4     38.4\n",
              "topic5    -33.9\n",
              "topic6      4.7\n",
              "topic7     -5.0\n",
              "topic8     40.1\n",
              "topic9     32.4\n",
              "topic10   -29.1\n",
              "topic11    50.3\n",
              "topic12    13.9\n",
              "topic13    47.0\n",
              "topic14    20.7\n",
              "topic15   -13.5\n",
              "dtype: float64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deals.T.sum()  # 4,8,9가 거래관련 스팸일거라 예상 가능함\n",
        "# pca는 9232개의 단어 빈도들의 부난이 가장 커지는 조합을 찾음, 사람이 보기에는 전혀 다른 여러 주제의 여러단어가 하나의 차원으로 합쳐지는 일이 발생\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGj4qJl4fjbZ"
      },
      "outputs": [],
      "source": [
        "# 절단되 svd를 이용한 문자 메시지 잠재 의미 분석\n",
        "from sklearn.decomposition import TruncatedSVD \n",
        "svd = TruncatedSVD(n_components = 16, n_iter =100) # 16개의 주제를 산출하되 pca만큼 정확한 결과를 얻기위해 자료를 100번 반복해서 처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz4uHA-Nf9dD",
        "outputId": "2bc6b211-3aed-4041-ae23-c4d3a09e4665"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-2.56432277e-02, -5.84019981e-03, -2.28435274e-04, ...,\n",
              "        -5.48526215e-05, -5.48526215e-05, -5.48526215e-05],\n",
              "       [-2.56432277e-02, -5.84019981e-03, -2.28435274e-04, ...,\n",
              "        -5.48526215e-05, -5.48526215e-05, -5.48526215e-05],\n",
              "       [-2.56432277e-02, -5.84019981e-03, -2.28435274e-04, ...,\n",
              "        -5.48526215e-05, -5.48526215e-05, -5.48526215e-05],\n",
              "       ...,\n",
              "       [-2.56432277e-02, -5.84019981e-03, -2.28435274e-04, ...,\n",
              "        -5.48526215e-05, -5.48526215e-05, -5.48526215e-05],\n",
              "       [-2.56432277e-02, -5.84019981e-03, -2.28435274e-04, ...,\n",
              "        -5.48526215e-05, -5.48526215e-05, -5.48526215e-05],\n",
              "       [-2.56432277e-02, -5.84019981e-03, -2.28435274e-04, ...,\n",
              "        -5.48526215e-05, -5.48526215e-05, -5.48526215e-05]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_docs.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsPFLs0-f2_l"
      },
      "outputs": [],
      "source": [
        "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLnamO9Ef_bQ"
      },
      "outputs": [],
      "source": [
        "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns= columns, index=index) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "rY6-jhYVfIGG",
        "outputId": "572bb0f3-6358-4676-8921-9bc754d215f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7d583bdc-e76f-401a-9f5a-7167c7fc6ddb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic0</th>\n",
              "      <th>topic1</th>\n",
              "      <th>topic2</th>\n",
              "      <th>topic3</th>\n",
              "      <th>topic4</th>\n",
              "      <th>topic5</th>\n",
              "      <th>topic6</th>\n",
              "      <th>topic7</th>\n",
              "      <th>topic8</th>\n",
              "      <th>topic9</th>\n",
              "      <th>topic10</th>\n",
              "      <th>topic11</th>\n",
              "      <th>topic12</th>\n",
              "      <th>topic13</th>\n",
              "      <th>topic14</th>\n",
              "      <th>topic15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sms0</th>\n",
              "      <td>0.201</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>0.039</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>0.012</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>0.007</td>\n",
              "      <td>-0.007</td>\n",
              "      <td>0.002</td>\n",
              "      <td>-0.036</td>\n",
              "      <td>-0.014</td>\n",
              "      <td>0.037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms1</th>\n",
              "      <td>0.404</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>-0.078</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.047</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.065</td>\n",
              "      <td>0.023</td>\n",
              "      <td>-0.024</td>\n",
              "      <td>-0.004</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.043</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>0.051</td>\n",
              "      <td>-0.042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms2!</th>\n",
              "      <td>-0.030</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>0.090</td>\n",
              "      <td>-0.067</td>\n",
              "      <td>0.091</td>\n",
              "      <td>-0.043</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>-0.057</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.026</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>-0.042</td>\n",
              "      <td>0.052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms3</th>\n",
              "      <td>0.329</td>\n",
              "      <td>-0.033</td>\n",
              "      <td>-0.035</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.056</td>\n",
              "      <td>-0.166</td>\n",
              "      <td>-0.074</td>\n",
              "      <td>0.063</td>\n",
              "      <td>-0.108</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.023</td>\n",
              "      <td>0.073</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.022</td>\n",
              "      <td>-0.070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4</th>\n",
              "      <td>0.002</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>-0.093</td>\n",
              "      <td>-0.044</td>\n",
              "      <td>0.061</td>\n",
              "      <td>-0.045</td>\n",
              "      <td>0.029</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.009</td>\n",
              "      <td>0.027</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>-0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms5!</th>\n",
              "      <td>-0.016</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.014</td>\n",
              "      <td>-0.006</td>\n",
              "      <td>0.122</td>\n",
              "      <td>-0.040</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.167</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.055</td>\n",
              "      <td>-0.037</td>\n",
              "      <td>0.075</td>\n",
              "      <td>-0.001</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d583bdc-e76f-401a-9f5a-7167c7fc6ddb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d583bdc-e76f-401a-9f5a-7167c7fc6ddb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d583bdc-e76f-401a-9f5a-7167c7fc6ddb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  topic8  topic9  topic10  topic11  topic12  \\\n",
              "sms0    0.201   0.003   0.037   0.011  -0.019  -0.053   0.039  -0.066   0.012  -0.083    0.007   -0.007    0.002   \n",
              "sms1    0.404  -0.094  -0.078   0.051   0.100   0.047   0.023   0.065   0.023  -0.024   -0.004    0.036    0.043   \n",
              "sms2!  -0.030  -0.048   0.090  -0.067   0.091  -0.043  -0.000  -0.001  -0.057   0.051    0.125    0.023    0.026   \n",
              "sms3    0.329  -0.033  -0.035  -0.016   0.052   0.056  -0.166  -0.074   0.063  -0.108    0.022    0.023    0.073   \n",
              "sms4    0.002   0.031   0.038   0.034  -0.075  -0.093  -0.044   0.061  -0.045   0.029    0.028   -0.009    0.027   \n",
              "sms5!  -0.016   0.059   0.014  -0.006   0.122  -0.040   0.005   0.167  -0.023   0.064    0.041    0.055   -0.037   \n",
              "\n",
              "       topic13  topic14  topic15  \n",
              "sms0    -0.036   -0.014    0.037  \n",
              "sms1    -0.021    0.051   -0.042  \n",
              "sms2!   -0.020   -0.042    0.052  \n",
              "sms3    -0.046    0.022   -0.070  \n",
              "sms4     0.034   -0.083   -0.021  \n",
              "sms5!    0.075   -0.001    0.020  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svd_topic_vectors.round(3).head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAKoa0aCgHp1"
      },
      "outputs": [],
      "source": [
        "# 산출한 벡터들이 pca모형이 산출한 것들과 정확히 일치 \n",
        "# 반복횟수를 크게 잡았고, 각 단어의 tf-idf빈도들을 0에 대해 중심화한 덕분\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8acJKwungv-P"
      },
      "outputs": [],
      "source": [
        "# 스팸분류에 대한 lsa의 정확도\n",
        "import numpy as np  \n",
        "svd_topic_vectors = (svd_topic_vectors.T / np.linalg.norm(svd_topic_vectors, axis=1)).T "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "zw0k70p5g5Q4",
        "outputId": "2c7b8f3b-c10f-47ce-fcf0-d24cd09d9642"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-17c558d3-07e4-4354-9060-78e9ba6c6af3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic0</th>\n",
              "      <th>topic1</th>\n",
              "      <th>topic2</th>\n",
              "      <th>topic3</th>\n",
              "      <th>topic4</th>\n",
              "      <th>topic5</th>\n",
              "      <th>topic6</th>\n",
              "      <th>topic7</th>\n",
              "      <th>topic8</th>\n",
              "      <th>topic9</th>\n",
              "      <th>topic10</th>\n",
              "      <th>topic11</th>\n",
              "      <th>topic12</th>\n",
              "      <th>topic13</th>\n",
              "      <th>topic14</th>\n",
              "      <th>topic15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sms0</th>\n",
              "      <td>0.815339</td>\n",
              "      <td>0.011229</td>\n",
              "      <td>0.150911</td>\n",
              "      <td>0.044478</td>\n",
              "      <td>-0.077920</td>\n",
              "      <td>-0.214706</td>\n",
              "      <td>0.158655</td>\n",
              "      <td>-0.265822</td>\n",
              "      <td>0.048434</td>\n",
              "      <td>-0.334490</td>\n",
              "      <td>0.030397</td>\n",
              "      <td>-0.029076</td>\n",
              "      <td>0.010069</td>\n",
              "      <td>-0.144022</td>\n",
              "      <td>-0.055770</td>\n",
              "      <td>0.149626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms1</th>\n",
              "      <td>0.888956</td>\n",
              "      <td>-0.206368</td>\n",
              "      <td>-0.170397</td>\n",
              "      <td>0.111870</td>\n",
              "      <td>0.219957</td>\n",
              "      <td>0.103543</td>\n",
              "      <td>0.050283</td>\n",
              "      <td>0.142806</td>\n",
              "      <td>0.050673</td>\n",
              "      <td>-0.052748</td>\n",
              "      <td>-0.009661</td>\n",
              "      <td>0.078080</td>\n",
              "      <td>0.095108</td>\n",
              "      <td>-0.045777</td>\n",
              "      <td>0.111280</td>\n",
              "      <td>-0.092359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms2!</th>\n",
              "      <td>-0.131376</td>\n",
              "      <td>-0.207488</td>\n",
              "      <td>0.389017</td>\n",
              "      <td>-0.289237</td>\n",
              "      <td>0.391411</td>\n",
              "      <td>-0.186100</td>\n",
              "      <td>-0.001226</td>\n",
              "      <td>-0.004307</td>\n",
              "      <td>-0.245876</td>\n",
              "      <td>0.221588</td>\n",
              "      <td>0.541174</td>\n",
              "      <td>0.100243</td>\n",
              "      <td>0.110209</td>\n",
              "      <td>-0.087526</td>\n",
              "      <td>-0.183288</td>\n",
              "      <td>0.225754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms3</th>\n",
              "      <td>0.778228</td>\n",
              "      <td>-0.077499</td>\n",
              "      <td>-0.081756</td>\n",
              "      <td>-0.037400</td>\n",
              "      <td>0.123524</td>\n",
              "      <td>0.131796</td>\n",
              "      <td>-0.391606</td>\n",
              "      <td>-0.175440</td>\n",
              "      <td>0.147886</td>\n",
              "      <td>-0.254562</td>\n",
              "      <td>0.051789</td>\n",
              "      <td>0.054281</td>\n",
              "      <td>0.171660</td>\n",
              "      <td>-0.108844</td>\n",
              "      <td>0.052625</td>\n",
              "      <td>-0.164697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4</th>\n",
              "      <td>0.011327</td>\n",
              "      <td>0.161933</td>\n",
              "      <td>0.201076</td>\n",
              "      <td>0.177766</td>\n",
              "      <td>-0.391843</td>\n",
              "      <td>-0.485564</td>\n",
              "      <td>-0.229397</td>\n",
              "      <td>0.321560</td>\n",
              "      <td>-0.234242</td>\n",
              "      <td>0.150988</td>\n",
              "      <td>0.147053</td>\n",
              "      <td>-0.045737</td>\n",
              "      <td>0.140988</td>\n",
              "      <td>0.177142</td>\n",
              "      <td>-0.438170</td>\n",
              "      <td>-0.107920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4832!</th>\n",
              "      <td>-0.258607</td>\n",
              "      <td>-0.327030</td>\n",
              "      <td>0.186161</td>\n",
              "      <td>-0.152079</td>\n",
              "      <td>0.398326</td>\n",
              "      <td>0.210249</td>\n",
              "      <td>-0.329410</td>\n",
              "      <td>0.039892</td>\n",
              "      <td>0.193684</td>\n",
              "      <td>-0.234405</td>\n",
              "      <td>-0.113023</td>\n",
              "      <td>0.073043</td>\n",
              "      <td>0.254455</td>\n",
              "      <td>-0.183272</td>\n",
              "      <td>0.489593</td>\n",
              "      <td>0.082544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4833</th>\n",
              "      <td>0.208962</td>\n",
              "      <td>0.230708</td>\n",
              "      <td>0.010256</td>\n",
              "      <td>-0.188276</td>\n",
              "      <td>-0.092476</td>\n",
              "      <td>0.137350</td>\n",
              "      <td>-0.054067</td>\n",
              "      <td>-0.236280</td>\n",
              "      <td>-0.263342</td>\n",
              "      <td>0.472585</td>\n",
              "      <td>0.212953</td>\n",
              "      <td>0.067743</td>\n",
              "      <td>-0.239005</td>\n",
              "      <td>0.024633</td>\n",
              "      <td>-0.055658</td>\n",
              "      <td>0.614764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4834</th>\n",
              "      <td>0.383772</td>\n",
              "      <td>0.216981</td>\n",
              "      <td>-0.097046</td>\n",
              "      <td>0.298546</td>\n",
              "      <td>0.082005</td>\n",
              "      <td>-0.044816</td>\n",
              "      <td>-0.119424</td>\n",
              "      <td>-0.111154</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>-0.352788</td>\n",
              "      <td>-0.384167</td>\n",
              "      <td>-0.452152</td>\n",
              "      <td>0.017510</td>\n",
              "      <td>0.288414</td>\n",
              "      <td>0.103322</td>\n",
              "      <td>-0.078645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4835</th>\n",
              "      <td>-0.149449</td>\n",
              "      <td>0.033859</td>\n",
              "      <td>0.004042</td>\n",
              "      <td>-0.075757</td>\n",
              "      <td>-0.337570</td>\n",
              "      <td>-0.514506</td>\n",
              "      <td>-0.143665</td>\n",
              "      <td>0.170049</td>\n",
              "      <td>-0.570358</td>\n",
              "      <td>0.192602</td>\n",
              "      <td>0.110736</td>\n",
              "      <td>0.166365</td>\n",
              "      <td>-0.018017</td>\n",
              "      <td>-0.209168</td>\n",
              "      <td>0.145450</td>\n",
              "      <td>-0.273790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4836</th>\n",
              "      <td>-0.251022</td>\n",
              "      <td>-0.517849</td>\n",
              "      <td>0.106531</td>\n",
              "      <td>-0.422860</td>\n",
              "      <td>-0.049373</td>\n",
              "      <td>0.046188</td>\n",
              "      <td>0.253770</td>\n",
              "      <td>-0.043237</td>\n",
              "      <td>-0.365863</td>\n",
              "      <td>-0.019784</td>\n",
              "      <td>0.320278</td>\n",
              "      <td>-0.012062</td>\n",
              "      <td>0.219584</td>\n",
              "      <td>-0.138209</td>\n",
              "      <td>-0.303982</td>\n",
              "      <td>-0.105483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4837 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17c558d3-07e4-4354-9060-78e9ba6c6af3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17c558d3-07e4-4354-9060-78e9ba6c6af3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17c558d3-07e4-4354-9060-78e9ba6c6af3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            topic0    topic1    topic2    topic3    topic4    topic5    topic6    topic7    topic8    topic9  \\\n",
              "sms0      0.815339  0.011229  0.150911  0.044478 -0.077920 -0.214706  0.158655 -0.265822  0.048434 -0.334490   \n",
              "sms1      0.888956 -0.206368 -0.170397  0.111870  0.219957  0.103543  0.050283  0.142806  0.050673 -0.052748   \n",
              "sms2!    -0.131376 -0.207488  0.389017 -0.289237  0.391411 -0.186100 -0.001226 -0.004307 -0.245876  0.221588   \n",
              "sms3      0.778228 -0.077499 -0.081756 -0.037400  0.123524  0.131796 -0.391606 -0.175440  0.147886 -0.254562   \n",
              "sms4      0.011327  0.161933  0.201076  0.177766 -0.391843 -0.485564 -0.229397  0.321560 -0.234242  0.150988   \n",
              "...            ...       ...       ...       ...       ...       ...       ...       ...       ...       ...   \n",
              "sms4832! -0.258607 -0.327030  0.186161 -0.152079  0.398326  0.210249 -0.329410  0.039892  0.193684 -0.234405   \n",
              "sms4833   0.208962  0.230708  0.010256 -0.188276 -0.092476  0.137350 -0.054067 -0.236280 -0.263342  0.472585   \n",
              "sms4834   0.383772  0.216981 -0.097046  0.298546  0.082005 -0.044816 -0.119424 -0.111154 -0.308067 -0.352788   \n",
              "sms4835  -0.149449  0.033859  0.004042 -0.075757 -0.337570 -0.514506 -0.143665  0.170049 -0.570358  0.192602   \n",
              "sms4836  -0.251022 -0.517849  0.106531 -0.422860 -0.049373  0.046188  0.253770 -0.043237 -0.365863 -0.019784   \n",
              "\n",
              "           topic10   topic11   topic12   topic13   topic14   topic15  \n",
              "sms0      0.030397 -0.029076  0.010069 -0.144022 -0.055770  0.149626  \n",
              "sms1     -0.009661  0.078080  0.095108 -0.045777  0.111280 -0.092359  \n",
              "sms2!     0.541174  0.100243  0.110209 -0.087526 -0.183288  0.225754  \n",
              "sms3      0.051789  0.054281  0.171660 -0.108844  0.052625 -0.164697  \n",
              "sms4      0.147053 -0.045737  0.140988  0.177142 -0.438170 -0.107920  \n",
              "...            ...       ...       ...       ...       ...       ...  \n",
              "sms4832! -0.113023  0.073043  0.254455 -0.183272  0.489593  0.082544  \n",
              "sms4833   0.212953  0.067743 -0.239005  0.024633 -0.055658  0.614764  \n",
              "sms4834  -0.384167 -0.452152  0.017510  0.288414  0.103322 -0.078645  \n",
              "sms4835   0.110736  0.166365 -0.018017 -0.209168  0.145450 -0.273790  \n",
              "sms4836   0.320278 -0.012062  0.219584 -0.138209 -0.303982 -0.105483  \n",
              "\n",
              "[4837 rows x 16 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svd_topic_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ci_s7qKhg6XW",
        "outputId": "bed7e19f-c127-424f-e45b-eef1cfd0c712"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb48d112-7d13-4794-bf13-cc5db62040ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sms0</th>\n",
              "      <th>sms1</th>\n",
              "      <th>sms2!</th>\n",
              "      <th>sms3</th>\n",
              "      <th>sms4</th>\n",
              "      <th>sms5!</th>\n",
              "      <th>sms6</th>\n",
              "      <th>sms7</th>\n",
              "      <th>sms8!</th>\n",
              "      <th>sms9!</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sms0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms1</th>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms2!</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms3</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms4</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms5!</th>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms6</th>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms7</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms8!</th>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sms9!</th>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb48d112-7d13-4794-bf13-cc5db62040ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb48d112-7d13-4794-bf13-cc5db62040ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb48d112-7d13-4794-bf13-cc5db62040ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       sms0  sms1  sms2!  sms3  sms4  sms5!  sms6  sms7  sms8!  sms9!\n",
              "sms0    1.0   0.6   -0.1   0.6  -0.0   -0.3  -0.3  -0.1   -0.3   -0.3\n",
              "sms1    0.6   1.0   -0.2   0.8  -0.2    0.0  -0.2  -0.2   -0.1   -0.1\n",
              "sms2!  -0.1  -0.2    1.0  -0.2   0.1    0.4   0.0   0.3    0.5    0.4\n",
              "sms3    0.6   0.8   -0.2   1.0  -0.2   -0.3  -0.1  -0.3   -0.2   -0.1\n",
              "sms4   -0.0  -0.2    0.1  -0.2   1.0    0.2   0.0   0.1   -0.4   -0.2\n",
              "sms5!  -0.3   0.0    0.4  -0.3   0.2    1.0  -0.1   0.1    0.3    0.4\n",
              "sms6   -0.3  -0.2    0.0  -0.1   0.0   -0.1   1.0   0.1   -0.2   -0.2\n",
              "sms7   -0.1  -0.2    0.3  -0.3   0.1    0.1   0.1   1.0    0.1    0.4\n",
              "sms8!  -0.3  -0.1    0.5  -0.2  -0.4    0.3  -0.2   0.1    1.0    0.3\n",
              "sms9!  -0.3  -0.1    0.4  -0.1  -0.2    0.4  -0.2   0.4    0.3    1.0"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)\n",
        "# sms0 따라가면서 다른 메시지들의 코사인 유사도를 살펴보면, 2,5,8,9와 0은 모두 음수의 코사인 유사도\n",
        "# svd는 tf-idf벡터들을 변환하는 행렬의 회전성분들만 처리하게됨\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2bV4x3bhHGz"
      },
      "outputs": [],
      "source": [
        "# 의미분석을 위한 알고리즘은 lsa, pca, svd, 단절된svd, LDiA 등으로 다양\n",
        "# BOW나 TF-IDF벡터들을 정규화해야함\n",
        "# 정규화를 하지 않으면, 주제들의 비례계수의 차이가 커짐 , 모형이 미묘하고 드문주제들을 구별하는 능력이 감소하게됨\n",
        "# 이런 비례 차이가 목적함수의 등고선 지형에 깊은 계곡과 강을 만들어서 최적의 문턱값을 찾아내기 어려움\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6ygBCVD4mu0"
      },
      "outputs": [],
      "source": [
        "# LSA SVD의 개선\n",
        "# 1. 이차판별분석(QDA) : LDA의 대안, 선형 변환이 아니라 이차 다항식 변환행렬을 산출함 / QDA의 벡터 공간에서 부류들을 가르는 경계는 사발이나 반구, 하프파이프 같은 이차곡면\n",
        "# 2. 무작위 투영 : SVD와 비슷한 행렬분해및 변환접근 방식이지만, 이런 확률적 성격덕분에 실행할때마다 다른 해답이 나옴, 알고리즘을 여러대의 컴퓨터에서 병렬로 수행하기 쉽다. NLP에서는 거의 사용안함\n",
        "# 3. 비음수 행렬 인수분해(NMF) \n",
        "# 대부분의 경우는 이런 개선안들보다는 효과가 이미 검증된 SVD알고리즘에 기초한 LSA를 사용하는것이 낫다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbQikwsG4lIH"
      },
      "outputs": [],
      "source": [
        "# 잠재 디리클레 할당(LDia)\n",
        "# 2015년 논문에 따르면 LSA가 LDiA보다 두배로 정확하다. \n",
        "# LSA에 깔린 수학은 간단하고 효율적\n",
        "# LSA로 얻은 선형변환 행렬은 추가적인 훈련 없이도 새로운 자연어 텍스트 말뭉치에 적용가능\n",
        "# 특정상황에서는 잠재 디리클레 할당이 나은 결과를 낸다\n",
        "# LDiA는 LSA처럼 하나의 주제모형을 산출함\n",
        "# LDiA는 단어빈도들이 디리클레 분포를 따른다고 가정함 \n",
        "# LSA의 선형 모형보다 LDiA의 디리클레 분포가 단어 빈도들의 분포를 좀더 정확하게 반영한다.\n",
        "# LDiA는 문서를 임임의 개수의 주제들의 혼합으로 간주함\n",
        "# 주제개수는 훈련하기 전에 개발자가 미리정함\n",
        "# 각 주제를 단어 출현횟수들의 분포로 표현할 수 있다고 가정함\n",
        "# 한 주제가 어떤 한문서의 실제의미에 해당할 확률과 한 단어가 어떤 한 주제에 속할 확률이 디리클레 확률분포를 따른다고 가정함\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nIuNI91m86J"
      },
      "outputs": [],
      "source": [
        "# 말뭉치의 문서들을 통계학적으로 분석하면 두 난수 발생 확률분포의 매개변수들을 구할수 있음\n",
        "# \n",
        "total_corpus_len = 0 \n",
        "for document_text in sms.text:\n",
        "  total_corpus_len += len(casual_tokenize(document_text))\n",
        "mean_document_len = total_corpus_len / len(sms) \n",
        "round(mean_document_len) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al6GIgsz8Yc4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7cqSDEk8YgI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1_PwL3y8YvS"
      },
      "source": [
        "# ch05. 신경망 첫걸음 ; 퍼셉트론과 역전파 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osdTflD18dmK",
        "outputId": "4afb2f7d-0f4e-4da3-9ee4-43583ef9697b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6740000000000002"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "example_input = [ 1,0.2, 0.1, 0.05, 0.2]\n",
        "example_weight = [ 0.2, 0.12 , 0.4, 0.6, 0.9]\n",
        "input_vector = np.array(example_input) \n",
        "weights = np.array(example_weight) \n",
        "bias_weight = 0.2\n",
        "activation_level  =  np.dot(input_vector, weights) + (bias_weight*1) \n",
        "activation_level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrVg_A3sfz9C"
      },
      "outputs": [],
      "source": [
        "threshold = 0.5 \n",
        "if activation_level >= threshold:\n",
        "  perceptron_output =1 \n",
        "else:\n",
        "  perceptron_output = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12r2njHCf_nw",
        "outputId": "bde2c8f6-9a65-490b-d2d1-6c09a09548d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perceptron_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvyfCrmTgBT4"
      },
      "outputs": [],
      "source": [
        "expected_output = 0\n",
        "new_weights = []\n",
        "for i, x in enumerate(example_input):\n",
        "  new_weights.append(weights[i] + (expected_output - perceptron_output) *x )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GmgLsJjhGky"
      },
      "outputs": [],
      "source": [
        "weigths = np.array(new_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9U-PugKhIh2",
        "outputId": "57febfac-6934-407b-9e61-6d022b2079bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.2, 0.12, 0.4, 0.6, 0.9]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1s3XHaHhNC6",
        "outputId": "5cef137a-9f84-4016-b97c-18ae5b30de7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.8 , -0.08,  0.3 ,  0.55,  0.7 ])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weigths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVJUWAemjuuW",
        "outputId": "f5d94678-73c0-4b51-cfd8-e18f3039ebf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4.45731813e-04, 9.69636414e-05])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_data = [[0,0], [0,1], [1,0], [1,1]]\n",
        "expected_results = [0,1,1,1]\n",
        "actavation_threshold = 0.5\n",
        "from random import random\n",
        "import numpy as  np\n",
        "weights = np.random.random(2) / 1000\n",
        "weights "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbTzPe2ihNoC"
      },
      "outputs": [],
      "source": [
        "bias_weight = np.random.random() / 1000\n",
        "bias_weight\n",
        "activation_threshold = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCkZGbAhkDXM",
        "outputId": "626f3ba1-f13c-4ab9-90b4-602b167359ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicted : 0\n",
            "expected: 0\n",
            "\n",
            "predicted : 0\n",
            "expected: 1\n",
            "\n",
            "predicted : 0\n",
            "expected: 1\n",
            "\n",
            "predicted : 0\n",
            "expected: 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 퍼셉트론 무작위 추측\n",
        "for idx, sample in enumerate(sample_data):\n",
        "  input_vector = np.array(sample) \n",
        "  activation_level = np.dot(input_vector , weights) + (bias_weight * 1) \n",
        "  if activation_level > activation_threshold: \n",
        "    perceptron_output = 1\n",
        "  else:\n",
        "    perceptron_output = 0\n",
        "  print('predicted : {}'.format(perceptron_output))\n",
        "  print('expected: {}'.format(expected_results[idx]))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiI6yn87kkkZ",
        "outputId": "cda94b5c-15ab-4852-8096-59c7ef5a1e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 correct answers output of 4, for iteration 0\n",
            "3 correct answers output of 4, for iteration 1\n",
            "4 correct answers output of 4, for iteration 2\n",
            "4 correct answers output of 4, for iteration 3\n",
            "4 correct answers output of 4, for iteration 4\n"
          ]
        }
      ],
      "source": [
        "# 퍼셉트론 학습\n",
        "for iteration_num in range(5):\n",
        "  correct_answer = 0\n",
        "  for idx, sample in enumerate(sample_data):\n",
        "    input_vector = np.array(sample) \n",
        "    weights = np.array(weights)\n",
        "    activation_level = np.dot(input_vector, weights) + (bias_weight*1) \n",
        "    if activation_level > activation_threshold :\n",
        "      perceptron_output= 1\n",
        "    else:\n",
        "      perceptron_output= 0\n",
        "    if perceptron_output == expected_results[idx]:\n",
        "      correct_answer += 1 \n",
        "    new_weights = []\n",
        "    for i , x in enumerate(sample):\n",
        "      new_weights.append(weights[i] + (expected_results[idx] - perceptron_output) * x) \n",
        "    bias_weight = bias_weight + ((expected_results[idx] - perceptron_output) * 1) \n",
        "    weights = np.array(new_weights)\n",
        "  print('{} correct answers output of 4, for iteration {}'.format(correct_answer, iteration_num)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og8-t9z4lFAG"
      },
      "outputs": [],
      "source": [
        "# 퍼셉트론의 본질적인 결함 존재 : 선형분리가 안되면 모형은 절대 수렴하지않음 by 민스키 패퍼트\n",
        "# 퍼셉트론은 비선형 방정식이나 비선형 관계를 배우지 못함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSK3mfX9pVi0"
      },
      "outputs": [],
      "source": [
        "# XOR 신경망 구현\n",
        "import numpy as np\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Activation \n",
        "# from keras.optimizers import *\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "x_train =  np.array([[0,0],[0,1],[1,0],[1,1]]) \n",
        "y_train = np.array([[0],[1],[1],[0]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4l3dY9d0Kzz",
        "outputId": "45e2bd5f-3287-4cfd-bf5b-e30958085a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                30        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "num_neurons = 10 \n",
        "model.add(Dense(num_neurons, input_dim=2))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjd2unxH0oVy",
        "outputId": "618ca822-aa76-4e60-ae3e-b473570d8699"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "sgd=SGD(lr=0.1)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLkvf2wU0vnJ",
        "outputId": "0ec713e5-f570-4143-fd46-639bce50dd50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.49723122],\n",
              "       [0.58899856],\n",
              "       [0.5473949 ]], dtype=float32)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(x_train)  # 무작위 weights 라서 이상한 답얻게됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKAuz6sl1Ce2",
        "outputId": "05b19b72-6987-4b07-cb2c-b52b8f015d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3064 - accuracy: 1.0000\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3048 - accuracy: 1.0000\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3033 - accuracy: 1.0000\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3017 - accuracy: 1.0000\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3002 - accuracy: 1.0000\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2987 - accuracy: 1.0000\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 1.0000\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 1.0000\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 1.0000\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2926 - accuracy: 1.0000\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2911 - accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2896 - accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2881 - accuracy: 1.0000\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2866 - accuracy: 1.0000\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2851 - accuracy: 1.0000\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2836 - accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2822 - accuracy: 1.0000\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2807 - accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2793 - accuracy: 1.0000\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2778 - accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2764 - accuracy: 1.0000\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2749 - accuracy: 1.0000\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2735 - accuracy: 1.0000\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2721 - accuracy: 1.0000\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2706 - accuracy: 1.0000\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2692 - accuracy: 1.0000\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2678 - accuracy: 1.0000\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2664 - accuracy: 1.0000\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2650 - accuracy: 1.0000\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 1.0000\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2622 - accuracy: 1.0000\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2609 - accuracy: 1.0000\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2595 - accuracy: 1.0000\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2581 - accuracy: 1.0000\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2568 - accuracy: 1.0000\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2554 - accuracy: 1.0000\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2541 - accuracy: 1.0000\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2527 - accuracy: 1.0000\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2514 - accuracy: 1.0000\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2501 - accuracy: 1.0000\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2487 - accuracy: 1.0000\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2474 - accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2461 - accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2448 - accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2435 - accuracy: 1.0000\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2422 - accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2410 - accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2397 - accuracy: 1.0000\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2384 - accuracy: 1.0000\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2371 - accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2359 - accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2346 - accuracy: 1.0000\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2334 - accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2322 - accuracy: 1.0000\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2309 - accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2297 - accuracy: 1.0000\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2285 - accuracy: 1.0000\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2261 - accuracy: 1.0000\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2249 - accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2237 - accuracy: 1.0000\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2225 - accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2213 - accuracy: 1.0000\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2202 - accuracy: 1.0000\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2190 - accuracy: 1.0000\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2178 - accuracy: 1.0000\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2167 - accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2156 - accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2144 - accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2133 - accuracy: 1.0000\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2122 - accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2110 - accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2099 - accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2088 - accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2066 - accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2055 - accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2045 - accuracy: 1.0000\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2034 - accuracy: 1.0000\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2023 - accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2013 - accuracy: 1.0000\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2002 - accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1992 - accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1981 - accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1971 - accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1961 - accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1950 - accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1940 - accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1920 - accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1910 - accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1900 - accuracy: 1.0000\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1890 - accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1880 - accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1871 - accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1861 - accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1851 - accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1842 - accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1832 - accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1823 - accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1813 - accuracy: 1.0000\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1804 - accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1795 - accuracy: 1.0000\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1776 - accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1767 - accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1758 - accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1749 - accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1740 - accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1731 - accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1723 - accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1714 - accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1705 - accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1697 - accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1688 - accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1679 - accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1654 - accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1646 - accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1638 - accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1629 - accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1621 - accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1613 - accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1605 - accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1597 - accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1589 - accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1581 - accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1573 - accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1565 - accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1558 - accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1550 - accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1535 - accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1527 - accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1512 - accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1505 - accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1497 - accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1490 - accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1483 - accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1476 - accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1469 - accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1461 - accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1454 - accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1447 - accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1440 - accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1433 - accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1426 - accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1420 - accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1413 - accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1399 - accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1393 - accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1379 - accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1373 - accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1360 - accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1341 - accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1335 - accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1328 - accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1322 - accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1316 - accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1310 - accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1304 - accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1298 - accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1286 - accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1280 - accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1268 - accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1262 - accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1256 - accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1251 - accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1245 - accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1239 - accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1234 - accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1228 - accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1223 - accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1212 - accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1206 - accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1201 - accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1195 - accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1185 - accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1179 - accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1174 - accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1169 - accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1159 - accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1154 - accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1148 - accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1143 - accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1138 - accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1128 - accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1124 - accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1119 - accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1114 - accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1109 - accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1099 - accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1085 - accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1081 - accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1076 - accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1072 - accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1067 - accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1053 - accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1040 - accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1036 - accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1032 - accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1023 - accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1019 - accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1010 - accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0994 - accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0990 - accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0982 - accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0978 - accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0974 - accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0970 - accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0966 - accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0962 - accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0958 - accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0950 - accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0947 - accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0943 - accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0939 - accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0932 - accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0928 - accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0924 - accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0906 - accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0903 - accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0896 - accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0875 - accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0869 - accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0852 - accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0849 - accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0840 - accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0780 - accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0750 - accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0748 - accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0745 - accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0735 - accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0732 - accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0727 - accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0725 - accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0717 - accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0710 - accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0708 - accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0696 - accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0691 - accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0680 - accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0662 - accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0650 - accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0641 - accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0637 - accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0621 - accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0619 - accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0618 - accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0616 - accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0614 - accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0593 - accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0592 - accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0586 - accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0581 - accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0579 - accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0572 - accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0571 - accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0569 - accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0564 - accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0562 - accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0559 - accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0551 - accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0550 - accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0548 - accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0537 - accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0531 - accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0527 - accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0514 - accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0511 - accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0503 - accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0496 - accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0491 - accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0484 - accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0477 - accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0475 - accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0473 - accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0470 - accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0460 - accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0452 - accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0443 - accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0434 - accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0406 - accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0394 - accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0389 - accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0375 - accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0370 - accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0366 - accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0342 - accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0336 - accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0329 - accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0329 - accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0324 - accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0311 - accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0286 - accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f25d8712690>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs= 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-XREuuO1rbU",
        "outputId": "eda877a6-a839-4c85-a7d7-846705b61c2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00824752],\n",
              "       [0.98045707],\n",
              "       [0.98018956],\n",
              "       [0.02366048]], dtype=float32)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "godtk_0y2a0C",
        "outputId": "6526fdae-4cd1-496a-cb07-1f120f2078b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.00824752]\n",
            " [0.98045707]\n",
            " [0.98018956]\n",
            " [0.02366048]]\n"
          ]
        }
      ],
      "source": [
        "# 오류 발생 predicted = model.predict_classes(token_list, verbose=0) \n",
        "# 오류 해결 y_prob = model.predict(token_list, verbose=0) predicted = y_prob.argmax(axis=-1)\n",
        "\n",
        "y_prob = model.predict(x_train, verbose=0) \n",
        "\n",
        "print(y_prob)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2lBrGBTFnkO"
      },
      "outputs": [],
      "source": [
        "model.predict_classes(x_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdo0fi5C2ClC"
      },
      "outputs": [],
      "source": [
        "import h5py \n",
        "model_structure = model.to_json()\n",
        "with open('basic_model.json', \"w\") as jsonfile:\n",
        "  jsonfile.write(model_structure) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvfshYuf4AlP"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"basic_weights.h5\") # 훈련된 가중치는 반드시 따로 저장, 앞에서는 그냥 신경망의 구조만 저장함\n",
        "# 신경망 구조로 신경망 인슨턴스를 다시 생성한 후 이 가중치를 인스턴스에 적재해야함\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bRKghnrGXa_"
      },
      "outputs": [],
      "source": [
        "# 더 많은 연구주제가 존재함\n",
        "# 활성화 함수, 오차의 반영정도를 결정하는 학습속도, momentum사용, drop out, regularization 등\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTSOK4l0HVLr"
      },
      "outputs": [],
      "source": [
        "# 정규화: 스타일 있는 입력\n",
        "# 심층 학습 뿐만 아니라 다른 기계학습모델에서도 정규화가 중요함\n",
        "input_vec = [2, 275000] \n",
        "# 원 데이터의 담긴정보는 유지하면서도 수치들을 연전파 알고리즘에 적합한 형태로 정규화하는 기법이 흔히 쓰임\n",
        "# 자연어 처리에서는 그리 걱정할 필요가 없다. tf-idf나 원핫 부호화 word2vec은 이미 정규화된 자류이기 때문임\n",
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP0D_1ras2ZJ"
      },
      "source": [
        "# ch06.단어벡터를 이용한 추론 : word2vec "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrIAdqNx4Jv2"
      },
      "outputs": [],
      "source": [
        "# 이전 장들에서는 단어 주변의 문맥을 그냥 무시함, 주어진 단어 앞과 뒤에 있는 단어들을 고려하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUuLKp_h2Uh1"
      },
      "outputs": [],
      "source": [
        "# 단어벡터는 단어의 의미를 나타내는 수치벡터실수 밀집 벡터, 이 밀집 벡터를 단어의 의미에 관한 질의와 논리적 추론에 사용할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcJFNq4b2JYr"
      },
      "outputs": [],
      "source": [
        "from nlpia.book.examples.ch06_nessvectors import * \n",
        "from nlpia.data.loaders import get_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cruHVWo_BloJ"
      },
      "outputs": [],
      "source": [
        "# nesscevtor('Marie_Curie').round(2) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ65l0Rmx-av"
      },
      "outputs": [],
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors \n",
        "word_vectors = KeyedVectors.load_word2vec_format('/content/gdrive/MyDrive/dataset/word2vec/GoogleNews-vectors-negative300.bin', binary= True, limit = 200000)  # 20만개만 저장함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7R6iZFyx-eY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1dc401-351c-4365-fca6-7572ac517109"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cook', 0.6973531246185303),\n",
              " ('sweet_potatoes', 0.6600280404090881),\n",
              " ('vegetables', 0.6513738632202148),\n",
              " ('onions', 0.6512383222579956),\n",
              " ('baking', 0.6481684446334839)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# gensim.keyedvectors.most_similar() 메서드는 주어진 단어벡터와 가장 가까운 단어벡터를 효율적으로 찾아줌\n",
        "word_vectors.most_similar(positive = ['cooking', 'potatoes'], topn = 5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB8IT5Kux-hB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "1e582d48-a6ab-4911-b06c-ec697e472c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'computer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# gensim 라이브러리는 무관한 단어들을 찾는 수단도 제공함 : doesnt_match() \n",
        "word_vectors.doesnt_match(\"potatoes milk cake computer\".split()) \n",
        "# 주어진 단어들에서 다른것들과 거리가 가장 먼 단어 하나를 선택해서 돌려준다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3zeGyz2dv3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5225a7f2-1303-4789-a8f8-0e42f113aba4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071), ('monarch', 0.6189674139022827)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "word_vectors.most_similar(positive=['king','woman'], negative=['man'], topn=2) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gensim 라이브러리는 단어의 유사도를 계산하는 수단도 제공함\n",
        "word_vectors.similarity('princess','queen') \n",
        "word_vectors['phone'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgKUK2lnT-XQ",
        "outputId": "7b84292c-1865-4736-9ce6-125dddbfa709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01446533, -0.12792969, -0.11572266, -0.22167969, -0.07373047,\n",
              "       -0.05981445, -0.10009766, -0.06884766,  0.14941406,  0.10107422,\n",
              "       -0.03076172, -0.03271484, -0.03125   , -0.10791016,  0.12158203,\n",
              "        0.16015625,  0.19335938,  0.0065918 , -0.15429688,  0.03710938,\n",
              "        0.22753906,  0.1953125 ,  0.08300781,  0.03686523, -0.02148438,\n",
              "        0.01483154, -0.21289062,  0.16015625,  0.29101562, -0.03149414,\n",
              "       -0.05883789,  0.04418945, -0.11767578, -0.12597656,  0.08447266,\n",
              "       -0.10791016, -0.11279297,  0.17871094,  0.04467773,  0.17675781,\n",
              "       -0.17089844, -0.02160645, -0.00061417, -0.17480469, -0.04760742,\n",
              "        0.06835938, -0.0546875 ,  0.04467773, -0.19628906, -0.18554688,\n",
              "       -0.10839844, -0.06030273,  0.11474609,  0.08544922,  0.05859375,\n",
              "        0.23925781, -0.07080078,  0.11816406, -0.11132812,  0.08300781,\n",
              "       -0.04394531,  0.00970459, -0.1484375 ,  0.265625  , -0.13769531,\n",
              "        0.23535156, -0.19824219,  0.31445312,  0.02734375,  0.16894531,\n",
              "        0.20898438, -0.0480957 ,  0.16015625, -0.00147247, -0.13085938,\n",
              "       -0.01312256,  0.07763672,  0.22851562,  0.13867188, -0.2578125 ,\n",
              "        0.06176758,  0.03955078,  0.13867188,  0.08154297,  0.00210571,\n",
              "       -0.05297852,  0.03222656,  0.02148438, -0.21582031,  0.30664062,\n",
              "       -0.05761719,  0.02722168, -0.28320312, -0.4140625 ,  0.01745605,\n",
              "        0.04101562,  0.00352478,  0.11279297,  0.046875  , -0.09960938,\n",
              "       -0.18945312, -0.24707031,  0.10058594,  0.35546875,  0.15625   ,\n",
              "        0.02319336,  0.125     , -0.12402344,  0.13378906,  0.17578125,\n",
              "        0.06494141, -0.10644531,  0.00714111, -0.40234375,  0.01989746,\n",
              "        0.11376953, -0.10644531, -0.19921875,  0.29492188,  0.15527344,\n",
              "       -0.13574219,  0.16601562, -0.18457031,  0.28125   ,  0.16992188,\n",
              "       -0.04345703, -0.203125  ,  0.02380371,  0.00268555,  0.125     ,\n",
              "       -0.14550781, -0.24121094, -0.125     , -0.12304688, -0.01251221,\n",
              "       -0.203125  ,  0.11132812,  0.04858398, -0.02246094, -0.19238281,\n",
              "        0.00221252, -0.13378906, -0.11035156,  0.1796875 ,  0.14648438,\n",
              "        0.11914062, -0.05419922, -0.3046875 , -0.14257812, -0.0019455 ,\n",
              "        0.296875  ,  0.34179688, -0.06396484, -0.00958252,  0.15527344,\n",
              "       -0.06494141, -0.12792969,  0.04736328,  0.00686646,  0.07910156,\n",
              "       -0.31445312,  0.15039062, -0.00558472, -0.00854492, -0.19726562,\n",
              "        0.0456543 , -0.0859375 , -0.3125    , -0.04931641, -0.17480469,\n",
              "        0.23632812,  0.0189209 , -0.01470947, -0.23632812, -0.48828125,\n",
              "       -0.09667969,  0.26953125,  0.2265625 , -0.33007812,  0.01855469,\n",
              "       -0.15332031, -0.13769531, -0.24316406,  0.12109375,  0.43945312,\n",
              "        0.05078125, -0.01574707,  0.14550781, -0.27148438,  0.05249023,\n",
              "       -0.12060547, -0.10742188, -0.22070312,  0.11132812,  0.00765991,\n",
              "        0.234375  , -0.2734375 ,  0.00512695, -0.01708984,  0.02258301,\n",
              "       -0.01031494,  0.19433594,  0.07226562,  0.02185059,  0.00915527,\n",
              "        0.15722656, -0.01733398, -0.01928711, -0.08837891,  0.01269531,\n",
              "        0.04125977, -0.05615234, -0.08105469, -0.40625   ,  0.04882812,\n",
              "        0.15136719, -0.06030273, -0.10791016, -0.3125    ,  0.00247192,\n",
              "        0.08007812,  0.203125  , -0.08789062,  0.06640625,  0.03417969,\n",
              "        0.20898438, -0.29101562,  0.20703125, -0.23730469, -0.05517578,\n",
              "        0.05737305, -0.13769531, -0.34960938, -0.20214844,  0.13671875,\n",
              "       -0.28710938,  0.00592041, -0.21289062, -0.25585938,  0.01397705,\n",
              "        0.3203125 , -0.01123047, -0.08544922, -0.16210938,  0.22558594,\n",
              "        0.05126953,  0.21386719, -0.00552368,  0.05932617, -0.06396484,\n",
              "       -0.04003906,  0.21191406,  0.12255859, -0.02954102,  0.18554688,\n",
              "        0.07421875,  0.20605469, -0.40429688, -0.05761719, -0.09521484,\n",
              "       -0.00830078, -0.14257812, -0.22265625, -0.22363281, -0.16601562,\n",
              "        0.29492188, -0.01190186, -0.11132812, -0.08642578, -0.19140625,\n",
              "        0.01818848,  0.17675781,  0.04077148, -0.2734375 , -0.00708008,\n",
              "       -0.09472656,  0.32421875,  0.05322266,  0.046875  ,  0.11376953,\n",
              "        0.15722656,  0.06201172,  0.07275391, -0.09179688, -0.09521484,\n",
              "       -0.10839844,  0.07470703,  0.10742188, -0.02856445,  0.16015625,\n",
              "       -0.07910156,  0.15722656, -0.06152344, -0.17480469,  0.08007812,\n",
              "       -0.13671875, -0.18359375, -0.05200195, -0.00585938, -0.15625   ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfazPz5gdwGu"
      },
      "outputs": [],
      "source": [
        "# 나만의 단어벡터 모형만들기 \n",
        "# domain specific 모델 / 파이썬으로 독자적인 word2vec모형을 훈련하는 방법\n",
        "from gensim.models.word2vec import Word2Vec  \n",
        "\n",
        "num_features = 300 \n",
        "min_word_count = 3 \n",
        "num_workers = 2  \n",
        "window_size= 6    # 문맥 구간 크기\n",
        "subsampling = 1e-3   #  부표집 문턱값"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_list = [['to','provide','early','childhood','special',' education','services','to','eligible','children','and','their','families'],\n",
        "              ['essential','job','functions'],\n",
        "              ['participate',' as',' a','transdisciplinary','team','member','to','complete','educational','assessments','for']]"
      ],
      "metadata": {
        "id": "9BKsmRkSUg5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iwqZ41NdwKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cf33a8-124d-468e-81df-ed0d2609d87f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-16 17:03:12,318 WARNING:gensim.models.base_any2vec:1386:      _log_train_end under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ],
      "source": [
        "model = Word2Vec(token_list, workers = num_workers, size= num_features, \n",
        "                 min_count = min_word_count, window=window_size, sample = subsampling) \n",
        "\n",
        "model.init_sims(replace=True) \n",
        "model_name= 'my_domain_specific_word2vec_model'\n",
        "model.save(model_name) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EacXBO7wdwMt"
      },
      "outputs": [],
      "source": [
        "# 저장된 word2vec모형의 적재 및 사용\n",
        "from gensim.models.word2vec import Word2Vec \n",
        "model_name = 'my_domain_specific_word2vec_model' \n",
        "model = Word2Vec.load(model_name) \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpia.data.loaders import get_data"
      ],
      "metadata": {
        "id": "QsmsCfF2XwdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 2)\n",
        "ud_300D = get_data('cities_us_worvectord')"
      ],
      "metadata": {
        "id": "Z8IM9xYEmsr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doc2vec\n",
        "import multiprocessing\n",
        "num_cores = multiprocessing.cpu_count() ; num_cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3I-XbOHXBcC",
        "outputId": "a935919c-6651-4699-8f7f-69f906cd164f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import TaggedDocumnet, Doc2Vec\n",
        "from gensim.utils import simple_preprocess  \n",
        "corpus = ['this is the first document', \n",
        "          'another document...']\n",
        "\n",
        "training_corpus = []\n",
        "for i, text in enumerate(corpus): \n",
        "  tagged_doc = TaggedDocument(simple_process(text), [i]) \n",
        "  training_corpus.append(tagged_doc) \n",
        "\n",
        "model = Doc2Vec(size=100, min_count=2 , workers = num_cores, iter=10) \n",
        "model.build_vocab(training_corpus) \n",
        "model.train(training_corpus, total_examples = model.corpus_count, epochs= model.iter) \n"
      ],
      "metadata": {
        "id": "TB2zbSKqXXPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.infer_vector(simple_preprocess('this is a completely unseen document'), steps=10) "
      ],
      "metadata": {
        "id": "7lU7-BRPYYWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "lT8xXPnSYphN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "az-xXqq3IhrF",
        "oJ2mGbXGQBah",
        "BEHGHmDHhs20"
      ],
      "machine_shape": "hm",
      "name": "자연어처리인액션.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNneJoCSSmnHk7gTbREtPsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}